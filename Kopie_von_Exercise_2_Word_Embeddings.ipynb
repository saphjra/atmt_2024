{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saphjra/atmt_2024/blob/main/Kopie_von_Exercise_2_Word_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gALCagMSOnRz"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Source: [link](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html#exercise-computing-word-embeddings-continuous-bag-of-words)\n",
        "\n",
        "# Word Embeddings: Encoding Lexical Semantics\n",
        "\n",
        "Word embeddings are dense vectors of real numbers, one per word in your\n",
        "vocabulary. In NLP, it is almost always the case that your features are\n",
        "words! But how should you represent a word in a computer? You could\n",
        "store its ascii character representation, but that only tells you what\n",
        "the word *is*, it doesn't say much about what it *means* (you might be\n",
        "able to derive its part of speech from its affixes, or properties from\n",
        "its capitalization, but not much). Even more, in what sense could you\n",
        "combine these representations? We often want dense outputs from our\n",
        "neural networks, where the inputs are $|V|$ dimensional, where\n",
        "$V$ is our vocabulary, but often the outputs are only a few\n",
        "dimensional (if we are only predicting a handful of labels, for\n",
        "instance). How do we get from a massive dimensional space to a smaller\n",
        "dimensional space?\n",
        "\n",
        "How about instead of ascii representations, we use a one-hot encoding?\n",
        "That is, we represent the word $w$ by\n",
        "\n",
        "\\begin{align}\\overbrace{\\left[ 0, 0, \\dots, 1, \\dots, 0, 0 \\right]}^\\text{|V| elements}\\end{align}\n",
        "\n",
        "where the 1 is in a location unique to $w$. Any other word will\n",
        "have a 1 in some other location, and a 0 everywhere else.\n",
        "\n",
        "There is an enormous drawback to this representation, besides just how\n",
        "huge it is. It basically treats all words as independent entities with\n",
        "no relation to each other. What we really want is some notion of\n",
        "*similarity* between words. Why? Let's see an example.\n",
        "\n",
        "Suppose we are building a language model. Suppose we have seen the\n",
        "sentences\n",
        "\n",
        "* The mathematician ran to the store.\n",
        "* The physicist ran to the store.\n",
        "* The mathematician solved the open problem.\n",
        "\n",
        "in our training data. Now suppose we get a new sentence never before\n",
        "seen in our training data:\n",
        "\n",
        "* The physicist solved the open problem.\n",
        "\n",
        "Our language model might do OK on this sentence, but wouldn't it be much\n",
        "better if we could use the following two facts:\n",
        "\n",
        "* We have seen  mathematician and physicist in the same role in a sentence. Somehow they\n",
        "  have a semantic relation.\n",
        "* We have seen mathematician in the same role  in this new unseen sentence\n",
        "  as we are now seeing physicist.\n",
        "\n",
        "and then infer that physicist is actually a good fit in the new unseen\n",
        "sentence? This is what we mean by a notion of similarity: we mean\n",
        "*semantic similarity*, not simply having similar orthographic\n",
        "representations. It is a technique to combat the sparsity of linguistic\n",
        "data, by connecting the dots between what we have seen and what we\n",
        "haven't. This example of course relies on a fundamental linguistic\n",
        "assumption: that words appearing in similar contexts are related to each\n",
        "other semantically. This is called the `distributional\n",
        "hypothesis <https://en.wikipedia.org/wiki/Distributional_semantics>`__.\n",
        "\n",
        "\n",
        "# Getting Dense Word Embeddings\n",
        "\n",
        "How can we solve this problem? That is, how could we actually encode\n",
        "semantic similarity in words? Maybe we think up some semantic\n",
        "attributes. For example, we see that both mathematicians and physicists\n",
        "can run, so maybe we give these words a high score for the \"is able to\n",
        "run\" semantic attribute. Think of some other attributes, and imagine\n",
        "what you might score some common words on those attributes.\n",
        "\n",
        "If each attribute is a dimension, then we might give each word a vector,\n",
        "like this:\n",
        "\n",
        "\\begin{align}q_\\text{mathematician} = \\left[ \\overbrace{2.3}^\\text{can run},\n",
        "   \\overbrace{9.4}^\\text{likes coffee}, \\overbrace{-5.5}^\\text{majored in Physics}, \\dots \\right]\\end{align}\n",
        "\n",
        "\\begin{align}q_\\text{physicist} = \\left[ \\overbrace{2.5}^\\text{can run},\n",
        "   \\overbrace{9.1}^\\text{likes coffee}, \\overbrace{6.4}^\\text{majored in Physics}, \\dots \\right]\\end{align}\n",
        "\n",
        "Then we can get a measure of similarity between these words by doing:\n",
        "\n",
        "\\begin{align}\\text{Similarity}(\\text{physicist}, \\text{mathematician}) = q_\\text{physicist} \\cdot q_\\text{mathematician}\\end{align}\n",
        "\n",
        "Although it is more common to normalize by the lengths:\n",
        "\n",
        "\\begin{align}\\text{Similarity}(\\text{physicist}, \\text{mathematician}) = \\frac{q_\\text{physicist} \\cdot q_\\text{mathematician}}\n",
        "   {\\| q_\\text{\\physicist} \\| \\| q_\\text{mathematician} \\|} = \\cos (\\phi)\\end{align}\n",
        "\n",
        "Where $\\phi$ is the angle between the two vectors. That way,\n",
        "extremely similar words (words whose embeddings point in the same\n",
        "direction) will have similarity 1. Extremely dissimilar words should\n",
        "have similarity -1.\n",
        "\n",
        "\n",
        "You can think of the sparse one-hot vectors from the beginning of this\n",
        "section as a special case of these new vectors we have defined, where\n",
        "each word basically has similarity 0, and we gave each word some unique\n",
        "semantic attribute. These new vectors are *dense*, which is to say their\n",
        "entries are (typically) non-zero.\n",
        "\n",
        "But these new vectors are a big pain: you could think of thousands of\n",
        "different semantic attributes that might be relevant to determining\n",
        "similarity, and how on earth would you set the values of the different\n",
        "attributes? Central to the idea of deep learning is that the neural\n",
        "network learns representations of the features, rather than requiring\n",
        "the programmer to design them herself. So why not just let the word\n",
        "embeddings be parameters in our model, and then be updated during\n",
        "training? This is exactly what we will do. We will have some *latent\n",
        "semantic attributes* that the network can, in principle, learn. Note\n",
        "that the word embeddings will probably not be interpretable. That is,\n",
        "although with our hand-crafted vectors above we can see that\n",
        "mathematicians and physicists are similar in that they both like coffee,\n",
        "if we allow a neural network to learn the embeddings and see that both\n",
        "mathematicians and physicists have a large value in the second\n",
        "dimension, it is not clear what that means. They are similar in some\n",
        "latent semantic dimension, but this probably has no interpretation to\n",
        "us.\n",
        "\n",
        "\n",
        "In summary, **word embeddings are a representation of the *semantics* of\n",
        "a word, efficiently encoding semantic information that might be relevant\n",
        "to the task at hand**. You can embed other things too: part of speech\n",
        "tags, parse trees, anything! The idea of feature embeddings is central\n",
        "to the field.\n",
        "\n",
        "\n",
        "# Word Embeddings in Pytorch\n",
        "\n",
        "Before we get to a worked example and an exercise, a few quick notes\n",
        "about how to use embeddings in Pytorch and in deep learning programming\n",
        "in general. Similar to how we defined a unique index for each word when\n",
        "making one-hot vectors, we also need to define an index for each word\n",
        "when using embeddings. These will be keys into a lookup table. That is,\n",
        "embeddings are stored as a $|V| \\times D$ matrix, where $D$\n",
        "is the dimensionality of the embeddings, such that the word assigned\n",
        "index $i$ has its embedding stored in the $i$'th row of the\n",
        "matrix. In all of my code, the mapping from words to indices is a\n",
        "dictionary named word\\_to\\_ix.\n",
        "\n",
        "The module that allows you to use embeddings is torch.nn.Embedding,\n",
        "which takes two arguments: the vocabulary size, and the dimensionality\n",
        "of the embeddings.\n",
        "\n",
        "To index into this table, you must use torch.LongTensor (since the\n",
        "indices are integers, not floats).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jgHDDrKlO35U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Author: Robert Guthrie\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "torch.manual_seed(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_Q2GVH0OwvH",
        "outputId": "567aa46a-d697-4a51-8cfc-ad945b7aa3bb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7d1333fe4e90>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# An Example: N-Gram Language Modeling\n",
        "\n",
        "Recall that in an n-gram language model, given a sequence of words\n",
        "$w$, we want to compute\n",
        "\n",
        "\\begin{align}P(w_i | w_{i-1}, w_{i-2}, \\dots, w_{i-n+1} )\\end{align}\n",
        "\n",
        "Where $w_i$ is the ith word of the sequence.\n",
        "\n",
        "In this example, we will compute the loss function on some training\n",
        "examples and update the parameters with backpropagation."
      ],
      "metadata": {
        "id": "l3ecRemdPstX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise: Computing Word Embeddings: Continuous Bag-of-Words\n",
        "\n",
        "The Continuous Bag-of-Words model (CBOW) is frequently used in NLP deep\n",
        "learning. It is a model that tries to predict words given the context of\n",
        "a few words before and a few words after the target word. This is\n",
        "distinct from language modeling, since CBOW is not sequential and does\n",
        "not have to be probabilistic. Typcially, CBOW is used to quickly train\n",
        "word embeddings, and these embeddings are used to initialize the\n",
        "embeddings of some more complicated model. Usually, this is referred to\n",
        "as *pretraining embeddings*. It almost always helps performance a couple\n",
        "of percent.\n",
        "\n",
        "The CBOW model is as follows. Given a target word $w_i$ and an\n",
        "$N$ context window on each side, $w_{i-1}, \\dots, w_{i-N}$\n",
        "and $w_{i+1}, \\dots, w_{i+N}$, referring to all context words\n",
        "collectively as $C$, CBOW tries to minimize\n",
        "\n",
        "\\begin{align}-\\log p(w_i | C) = -\\log \\text{Softmax}(A(\\sum_{w \\in C} q_w) + b)\\end{align}\n",
        "\n",
        "where $q_w$ is the embedding for word $w$.\n"
      ],
      "metadata": {
        "id": "7fV7zUnlz7xp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise Layout\n",
        "### 1. <u>Training CBOW Embeddings</u>\n",
        "1.1) Implement a CBOW Model by completing ```class CBOW(nn.Module)``` and train it on ```raw_text```.    \n",
        "\n",
        "1.2) Load Datasets ```tripadvisor_hotel_reviews_reduced.csv``` and ```scifi_reduced.txt```.     \n",
        "\n",
        "1.3) Decide preprocessing steps by completing the function ```def custom_preprocess()```. Describe your decisions. Note that it's your choice to create different preprocessing functions for hotel reviews and scifi datasets or use the same preprocessing function.             \n",
        "\n",
        "1.4) Train CBOW2 with a context width of 2 (in both directions) for the Hotel Reviews dataset.   \n",
        "\n",
        "1.5) Train CBOW5 with a context width of 5 (in both directions) for the Hotel Reviews dataset. Are predictions made by the model sensitive towards the context size?\n",
        "     \n",
        "1.6) Train CBOW2 with a context width of 2 (in both directions) for the Sci-Fi story dataset.  \n",
        "\n",
        "\n",
        "### 2. <u>Test your Embeddings</u>\n",
        "Note - Do the following for CBOW2, and optionally for CBOW5\n",
        "\n",
        "2.1) For the hotel reviews dataset, choose 3 nouns, 3 verbs, and 3 adjectives. Make sure that some nouns/verbs/adjectives occur frequently in the corpus and that others are rare. For each of the 9 chosen words, retrieve the 5 closest words according to your trained CBOW2 model. List them in your report and comment on the performance of your model: do the neighbours the model provides make sense? Discuss.   \n",
        "\n",
        "2.2) Do the same for Sci-Fi dataset.   \n",
        "\n",
        "2.3) How does the quality of the hotel review-based embeddings compare with the Sci-fi-based embeddings? Elaborate.   \n",
        "\n",
        "2.4) Choose 2 words and retrieve their 5 closest neighbours according to hotel review-based embeddings and the Sci-fi-based embeddings. Do they have different neighbours? If yes, can you reason why?    \n",
        "\n",
        "2.5) What are the differences between CBOW2 and CBOW5 ? Can you \"describe\" them?   \n"
      ],
      "metadata": {
        "id": "Pj_2_qqM7Md_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tips\n",
        "\n",
        "1. Switch from CPU to a GPU instance after you have confirmed that your training procedure is working correctly.\n",
        "2. You can always save your intermediate results (embeddings, preprocessed dataset, model, etc.) in your google drive via colab\n"
      ],
      "metadata": {
        "id": "Xvo1QvEf-iT2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 1.1 Create a CBOW Model by completing ```class CBOW(nn.Module)``` and test it on ```raw_text```\n",
        "Implement CBOW in Pytorch by filling in the class below. Some\n",
        "tips:\n",
        "\n",
        "* Think about which parameters you need to define.\n",
        "* Make sure you know what shape each operation expects. Use .view() if you need to\n",
        "  reshape."
      ],
      "metadata": {
        "id": "vfG8j2JiRMly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Load Datasets"
      ],
      "metadata": {
        "id": "9NbVpFkR77uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Load Datasets tripadvisor_hotel_reviews_reduced.csv and scifi_reduced.txt\n",
        "\n",
        "!gdown 1foE1JuZJeu5E_4qVge9kExzhvF32teuF # For Hotel Reviews\n",
        "!gdown 13IWXrTjGTrfCd9l7dScZVO8ZvMicPU75 # For Scifi-Text"
      ],
      "metadata": {
        "id": "i4XpJnxV79rK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3469affa-0bb2-462b-e937-c14a8ce07b1e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1foE1JuZJeu5E_4qVge9kExzhvF32teuF\n",
            "To: /content/tripadvisor_hotel_reviews_reduced.csv\n",
            "100% 7.36M/7.36M [00:00<00:00, 39.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13IWXrTjGTrfCd9l7dScZVO8ZvMicPU75\n",
            "To: /content/scifi_reduced.txt\n",
            "100% 43.1M/43.1M [00:00<00:00, 66.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Preprocess Datasets\n",
        "### ðŸ—’â“ Describe your decisions for preprocessing the datasets"
      ],
      "metadata": {
        "id": "F9AUsLd78JVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('tripadvisor_hotel_reviews_reduced.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "q8fBwCdGAvrd",
        "outputId": "5a086b4f-605b-4a87-d0e3-75def8c78ee1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Review  Rating\n",
              "0  fantastic service large hotel caters business ...       5\n",
              "1  great hotel modern hotel good location, locate...       4\n",
              "2  3 star plus glasgowjust got 30th november 4 da...       4\n",
              "3  nice stayed hotel nov 19-23. great little bout...       4\n",
              "4  great place wonderful hotel ideally located me...       5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ce749ab-9558-405c-a17c-cfa7b5b5f326\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fantastic service large hotel caters business ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>great hotel modern hotel good location, locate...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3 star plus glasgowjust got 30th november 4 da...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nice stayed hotel nov 19-23. great little bout...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great place wonderful hotel ideally located me...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ce749ab-9558-405c-a17c-cfa7b5b5f326')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9ce749ab-9558-405c-a17c-cfa7b5b5f326 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9ce749ab-9558-405c-a17c-cfa7b5b5f326');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8fb01ed1-63de-4a84-b72a-6ce3b20805e8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8fb01ed1-63de-4a84-b72a-6ce3b20805e8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8fb01ed1-63de-4a84-b72a-6ce3b20805e8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"Review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          \"enjoyed stay punta cana princess, stayed punta cana princess july 18-25. husband 30 27 went couple late twenties/early thirties, husband inclusive adults resort, really great time things disappointing, 1 desserts- dessert tried buffet ala carte restaurants not good, 2 drinks- reviews read site heard people say drinks not consistently cold agree, order nice tropical drink like pina colada example nice cold slushy like like drinking pina colada juice liquid not cold/icy, think pina colada daiquiri think nice icy cool refreshing drink did not, not happy things actually return punta cana princess, positives resort check in- no problem check, nice greeted cool towel glass yummy tropical punch, rooms got luggage, room- room great stayed 5107. perfect location second floor loved building close pool, room big queen beds little sitting area tv fridge, bathroom nice size loved double sinks great cause husband space ready, ac worked really really actually got pretty cold room day rest time stayed plenty cool turning ac just having ceiling fan, food- thought food really good, caribe buffet twice, night wednesday asian buffet definitely eat liked, ate domnican buffet night monday really good, music playing ate just nice little taste dominican culture, rest nights ate ala carte restaurants, tried il pilon domincan food il bacio italian food la cava fancy retaurant tex mex restaurant forget enjoyed food, la cava nice lobster, came lobster tails really good second overcooked, tex mex restaurant got super hot restaurant sat right near kitchen, husband went talk guest services right away manager came thermostat checking ac, pretty happy took care quickly, meal really good loved margaritas gave guacamole chips, staff- staff incredibly friendly, anamacion staff hostess buffet bartenders met greeted ola, happy help, noticed people reviewed resort said staff unfriendly, wondering just language barrier, not really able speak spanish really tried did feel n't connected staff guests speak fluent spanish, n't think not friendly just think harder connect people not share language, feel like tried talk staff tried talk, ask, beach- beautiful actually did not spend time, did activities beach like ping pong pilates really just liked pool, pool- loved pool, huge nice pool bar day nice palapa sit spot near pool, lots activities pool did aerobicos times little silly fun played pool volleyball, cleanliness- resort maintained daily people work clean debris beach working maintaining gardens resort, overall really enjoyed stay punta cana princess, not happy consistency cold drinks average desserts wonderful nice spacious room good food friendly staff beautiful beach pool,  \",\n          \"captivating stayed dauphine march 2003 mardi gras passed delighted quiet close action french quarter, absolutely gorgeous room street main hotel overlooking captivating courtyard, room just beautiful loved brick walls huge comfortable bed french doors jet tub, felt like princess room clean inviting, hotel exceeded expectations online stay heartbeat, fact fully intend just spring,  \",\n          \"great location hotel calzaiuoli good hotel prime florence location, easy walking distance main attractions blocks duomo uffizi gallery.the breakfast room spacious food offerings average, decor nice, lift relatively large, beds comfortable.there downside hotel, door locks old-fashioned keys fine, inside room no way prevent hotel staff key entering room, no not disturb signs provided, hotel chambermaid entered room twice 4 night stay room,  \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Complete the preprocessing function and apply it to the datasets\n",
        "import re\n",
        "def custom_preprocess(df, col):\n",
        "    def tokenize(text):\n",
        "    # Convert to lowercase and split by non-alphabetic characters, very minor proprocessing steps, we could add more. However the dataset, seemed to be already preprocessed\n",
        "      tokens = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "      return tokens\n",
        "\n",
        "\n",
        "    df_preproccessed = df[col].apply(tokenize)\n",
        "\n",
        "    vocab_set = set(token for tokens in df_preproccessed for token in tokens)\n",
        "    return df_preproccessed, vocab_set\n",
        "\n"
      ],
      "metadata": {
        "id": "9AEF16-v9Erc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pre, vocab = custom_preprocess(df, 'Review')\n",
        "df_pre.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-dbrnpWnkUm",
        "outputId": "8cf8aba3-dff7-4f4f-d274-42ea6a8e303c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Series name: Review\n",
            "Non-Null Count  Dtype \n",
            "--------------  ----- \n",
            "10000 non-null  object\n",
            "dtypes: object(1)\n",
            "memory usage: 78.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vocab_and_data(df, col, context_size=2):\n",
        "    # By deriving a set from `raw_text`, we deduplicate the array\n",
        "    df, vocab = custom_preprocess(df, col)\n",
        "    word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "    data = []\n",
        "    for j in range(len(df)):\n",
        "      raw_text = df[j]\n",
        "      # print(raw_text)\n",
        "      for i in range(context_size, len(raw_text) - context_size):\n",
        "          context = raw_text[i - context_size:i] + raw_text[i + 1:i + context_size + 1]\n",
        "          target = raw_text[i]\n",
        "          data.append((context, target))\n",
        "    return data, word_to_ix, vocab\n"
      ],
      "metadata": {
        "id": "TlNwOJRyCJm6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, word_to_ix, vocab = create_vocab_and_data(df, 'Review')\n",
        "print(data[0:5])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3HxW1icrm6R",
        "outputId": "bfb46cee-7502-4b11-ab53-78d7d9f9ed6e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['fantastic', 'service', 'hotel', 'caters'], 'large'), (['service', 'large', 'caters', 'business'], 'hotel'), (['large', 'hotel', 'business', 'corporates'], 'caters'), (['hotel', 'caters', 'corporates', 'serve'], 'business'), (['caters', 'business', 'serve', 'provided'], 'corporates')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(int(len(data)*0.9))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqFQFG-34wdk",
        "outputId": "1b273c4f-b0fc-4741-c7e4-1be557b8098d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "946944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data, word_to_ix, vocab = create_vocab_and_data(df, 'Review', context_size=5)\n",
        "print(data[0:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RKZV9Y2zgcD",
        "outputId": "32a4f2fa-bcf7-4e4f-dd4c-b40e0557c198"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['fantastic', 'service', 'large', 'hotel', 'caters', 'corporates', 'serve', 'provided', 'better', 'wife'], 'business'), (['service', 'large', 'hotel', 'caters', 'business', 'serve', 'provided', 'better', 'wife', 'experienced'], 'corporates'), (['large', 'hotel', 'caters', 'business', 'corporates', 'provided', 'better', 'wife', 'experienced', 'nothing'], 'serve'), (['hotel', 'caters', 'business', 'corporates', 'serve', 'better', 'wife', 'experienced', 'nothing', 'short'], 'provided'), (['caters', 'business', 'corporates', 'serve', 'provided', 'wife', 'experienced', 'nothing', 'short', 'world'], 'better')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_context_vector(context, word_to_ix):\n",
        "\n",
        "    idxs = [word_to_ix[w] for w in context] if type(context)==list  else [word_to_ix[context]]\n",
        "\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "\n",
        "print(make_context_vector(data[0][0], word_to_ix))  # example\n",
        "print(make_context_vector(data[0][1], word_to_ix))  # example\n",
        "data[0][1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "QZt2SqCOUqH_",
        "outputId": "61876eef-be59-48cd-9026-0a726d9cb326"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([17667, 16493, 18955,  4637])\n",
            "tensor([21993])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'large'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_to_tensor(data, word_to_ix):\n",
        "    data_tensor_context = []\n",
        "    data_tensor_target  = []\n",
        "    for context, target in data:\n",
        "        context_idxs = make_context_vector(context, word_to_ix)\n",
        "        target_idx = word_to_ix[target]\n",
        "        data_tensor_context.append(context_idxs)\n",
        "        data_tensor_target.append(target_idx)\n",
        "    data_tensor_context = torch.stack(data_tensor_context)\n",
        "    data_tensor_target = torch.tensor(data_tensor_target, dtype=torch.long)\n",
        "    return data_tensor_context, data_tensor_target.unsqueeze(1)\n"
      ],
      "metadata": {
        "id": "wK_EZmA4WR5b"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data_to_tensor(data[:10], word_to_ix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIw6NA-MWw8Q",
        "outputId": "bb65d748-e56f-41cc-8ae8-8bc3d3090123"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[17667, 16493, 18955,  4637],\n",
              "         [16493, 21993,  4637, 20623],\n",
              "         [21993, 18955, 20623, 29567],\n",
              "         [18955,  4637, 29567, 28517],\n",
              "         [ 4637, 20623, 28517, 33122],\n",
              "         [20623, 29567, 33122, 13291],\n",
              "         [29567, 28517, 13291, 21399],\n",
              "         [28517, 33122, 21399, 33994],\n",
              "         [33122, 13291, 33994, 36446],\n",
              "         [13291, 21399, 36446, 32184]]),\n",
              " tensor([[21993],\n",
              "         [18955],\n",
              "         [ 4637],\n",
              "         [20623],\n",
              "         [29567],\n",
              "         [28517],\n",
              "         [33122],\n",
              "         [13291],\n",
              "         [21399],\n",
              "         [33994]]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_index= int(len(data)*0.9)\n",
        "\n",
        "train_X, train_Y = data_to_tensor(data[:split_index], word_to_ix)\n",
        "test_X, test_Y = data_to_tensor(data[split_index:], word_to_ix)\n",
        "print(train_X.shape)\n",
        "print(train_Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQxqHaDqZCrq",
        "outputId": "48de27b8-9714-43bc-832e-2410ce85c42d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([946944, 4])\n",
            "torch.Size([946944, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_X.shape)\n",
        "print(test_Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyFreSWh3z4T",
        "outputId": "264e52b0-bdd8-43bb-b038-ff1dfbdf27b2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([105216, 4])\n",
            "torch.Size([105216, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X4-L2sY38cy",
        "outputId": "fb7eb78a-9402-4ddb-cd9e-283bce177b78"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1052160"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import IterableDataset, DataLoader\n",
        "class MyDataset(IterableDataset):\n",
        "    def __init__(self, data_X, data_y):\n",
        "        assert len(data_X) == len(data_y)\n",
        "        self.data_X = data_X.to(device)\n",
        "        self.data_y = data_y.to(device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_X)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for i in range(len(self.data_X)):\n",
        "            yield (self.data_X[i], self.data_y[i])"
      ],
      "metadata": {
        "id": "Pf9EbocHZwXE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "N8At7UQnanrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "train_set = MyDataset(train_X, train_Y)\n",
        "test_set = MyDataset(test_X, test_Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xHPAULfZxxd",
        "outputId": "830a58aa-304b-4213-cf37-81f6c418b692"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class CBOW(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, context_size):\n",
        "        super(CBOW, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(context_size * 2* embedding_dim, hidden_dim)     # multipy with two because you have a left anfd a right ontext\n",
        "        self.linear2 = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embeddings(inputs).view((inputs.shape[0], -1))\n",
        "        out = F.relu(self.linear1(embeds))\n",
        "        out = self.linear2(out)\n",
        "        log_probs = F.log_softmax(out, dim=-1)\n",
        "        return log_probs\n",
        "\n",
        "# create your model and train.  here are some functions to help you make\n",
        "# the data ready for use by your module\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eMOoKGjMkxKX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def eval(model, test_loader)\n",
        "  predictions = []\n",
        "  true_labels = []\n",
        "  model.eval()  # without dropout and alike not really necessary\n",
        "  with torch.no_grad():  # disable gradient computation, since it is only needed when backward() is called\n",
        "      for test_X, test_y in test_loader:\n",
        "          pred_y = model(test_X)\n",
        "          #print(pred_y, test_y)\n",
        "          batch_preds = [x.item() for x in torch.argmax(pred_y, dim=-1)]\n",
        "          predictions.extend(batch_preds)\n",
        "          true_labels.extend([y.item() for y in test_y.squeeze()])\n",
        "\n",
        "\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  acc = accuracy_score(true_labels, predictions)\n",
        "  acc\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u0CNZkd0hfYv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "f973dada-baa0-48e1-e3ac-a775b14ca5bd"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-17.2027, -17.1444, -19.4640,  ..., -18.6364, -18.2556, -19.3207],\n",
            "        [-18.8358, -23.2521, -20.8849,  ..., -22.8250, -22.3099, -19.3059],\n",
            "        [-20.1133, -22.4892, -19.2174,  ..., -21.8385, -20.6431, -20.5586],\n",
            "        ...,\n",
            "        [-17.9041, -19.0858, -16.3741,  ..., -17.3103, -13.8947, -16.8426],\n",
            "        [-23.5336, -19.5310, -20.1699,  ..., -22.0300, -19.6643, -21.8681],\n",
            "        [-20.8341, -16.8419, -18.0029,  ..., -20.2550, -16.8591, -16.8116]]) tensor([[  561],\n",
            "        [ 2606],\n",
            "        [ 9803],\n",
            "        [11225],\n",
            "        [12235],\n",
            "        [28621],\n",
            "        [16350],\n",
            "        [35104],\n",
            "        [34938],\n",
            "        [ 5735],\n",
            "        [35104],\n",
            "        [32594],\n",
            "        [ 9859],\n",
            "        [29580],\n",
            "        [ 9859],\n",
            "        [18670]])\n",
            "tensor([[-17.2301, -18.9866, -15.7950,  ..., -19.0685, -18.4993, -17.7286],\n",
            "        [-21.3038, -20.3481, -20.2360,  ..., -21.5439, -18.8984, -18.5081],\n",
            "        [-21.5107, -23.6949, -20.3636,  ..., -25.1956, -20.6841, -20.8851],\n",
            "        ...,\n",
            "        [-26.5692, -25.8688, -21.7860,  ..., -26.7425, -21.5749, -21.2530],\n",
            "        [-33.1820, -35.9453, -34.7395,  ..., -35.8579, -32.7851, -34.5458],\n",
            "        [-23.7943, -24.2835, -23.9005,  ..., -21.8426, -21.2141, -23.6045]]) tensor([[35918],\n",
            "        [ 5859],\n",
            "        [26952],\n",
            "        [28485],\n",
            "        [ 1806],\n",
            "        [31776],\n",
            "        [23065],\n",
            "        [23300],\n",
            "        [29454],\n",
            "        [14262],\n",
            "        [23546],\n",
            "        [15383],\n",
            "        [26856],\n",
            "        [13425],\n",
            "        [ 4908],\n",
            "        [ 3286]])\n",
            "tensor([[-26.3324, -24.3146, -26.4658,  ..., -26.1656, -26.8559, -22.7325],\n",
            "        [-15.8239, -18.7373, -16.2180,  ..., -20.6841, -19.2474, -16.4867],\n",
            "        [-17.2423, -19.5032, -18.5884,  ..., -19.5073, -18.9972, -19.5036],\n",
            "        ...,\n",
            "        [-17.1554, -18.9040, -17.8423,  ..., -18.9666, -18.2105, -17.2363],\n",
            "        [-19.1561, -21.7216, -18.5702,  ..., -20.1031, -18.9158, -18.2353],\n",
            "        [-19.4818, -19.5138, -20.1333,  ..., -22.6088, -18.5941, -17.9258]]) tensor([[19196],\n",
            "        [26748],\n",
            "        [20868],\n",
            "        [14740],\n",
            "        [25154],\n",
            "        [13096],\n",
            "        [23261],\n",
            "        [ 9816],\n",
            "        [23594],\n",
            "        [ 2434],\n",
            "        [30245],\n",
            "        [ 9471],\n",
            "        [  562],\n",
            "        [23243],\n",
            "        [12199],\n",
            "        [15383]])\n",
            "tensor([[-17.6229, -22.2909, -20.4034,  ..., -21.9857, -17.7484, -17.8712],\n",
            "        [-20.6250, -24.4340, -20.7801,  ..., -26.4907, -23.9264, -22.4730],\n",
            "        [-22.3925, -18.7103, -18.5082,  ..., -19.5571, -19.9310, -19.2794],\n",
            "        ...,\n",
            "        [-25.8892, -25.6040, -23.0853,  ..., -26.1454, -24.8168, -24.5513],\n",
            "        [-23.5950, -24.2492, -24.5875,  ..., -26.8538, -23.0532, -23.9477],\n",
            "        [-24.1877, -26.1196, -25.1068,  ..., -23.5659, -23.9634, -23.3518]]) tensor([[25076],\n",
            "        [ 9440],\n",
            "        [32885],\n",
            "        [20951],\n",
            "        [13783],\n",
            "        [15383],\n",
            "        [ 3655],\n",
            "        [35233],\n",
            "        [ 9551],\n",
            "        [ 2046],\n",
            "        [21089],\n",
            "        [ 9803],\n",
            "        [17746],\n",
            "        [21230],\n",
            "        [ 2410],\n",
            "        [ 2255]])\n",
            "tensor([[-18.2791, -20.7484, -20.9402,  ..., -20.7918, -21.0266, -19.5807],\n",
            "        [-18.1281, -21.4334, -19.5208,  ..., -20.2072, -18.2716, -18.5839],\n",
            "        [-22.8532, -26.6140, -23.8438,  ..., -26.8147, -24.5092, -27.6584],\n",
            "        ...,\n",
            "        [-19.8750, -20.9109, -17.5037,  ..., -19.7200, -18.3764, -21.0418],\n",
            "        [-20.5969, -21.4564, -20.9720,  ..., -24.4619, -21.2328, -22.5991],\n",
            "        [-24.7654, -23.7948, -21.2778,  ..., -24.6817, -19.9780, -22.0027]]) tensor([[33090],\n",
            "        [19927],\n",
            "        [10361],\n",
            "        [35031],\n",
            "        [ 2827],\n",
            "        [16274],\n",
            "        [27786],\n",
            "        [23963],\n",
            "        [26905],\n",
            "        [ 9471],\n",
            "        [12842],\n",
            "        [27515],\n",
            "        [11247],\n",
            "        [10176],\n",
            "        [ 8414],\n",
            "        [29661]])\n",
            "tensor([[-19.1004, -19.9702, -22.6558,  ..., -24.0056, -20.5574, -21.1588],\n",
            "        [-24.2892, -28.6417, -24.2548,  ..., -24.3560, -23.1840, -25.9547],\n",
            "        [-34.4345, -38.0835, -34.8052,  ..., -37.8405, -33.2842, -35.5124],\n",
            "        ...,\n",
            "        [-22.5835, -24.3736, -21.7203,  ..., -24.9726, -20.3513, -22.3681],\n",
            "        [-22.2567, -23.0296, -21.3775,  ..., -25.7455, -22.2453, -20.4405],\n",
            "        [-35.1640, -33.5413, -30.5835,  ..., -36.0650, -34.0554, -31.2722]]) tensor([[33816],\n",
            "        [14259],\n",
            "        [ 4703],\n",
            "        [11857],\n",
            "        [27786],\n",
            "        [ 8124],\n",
            "        [   75],\n",
            "        [20268],\n",
            "        [27515],\n",
            "        [ 8229],\n",
            "        [ 1324],\n",
            "        [20756],\n",
            "        [33694],\n",
            "        [27515],\n",
            "        [31495],\n",
            "        [11004]])\n",
            "tensor([[-19.2575, -19.4003, -21.9340,  ..., -19.9610, -20.9049, -18.1513],\n",
            "        [-22.1195, -22.4237, -21.4756,  ..., -24.1917, -19.4647, -21.2553],\n",
            "        [-35.3997, -36.8291, -32.0793,  ..., -33.9368, -29.3538, -32.2476],\n",
            "        ...,\n",
            "        [-22.9521, -24.4296, -23.5247,  ..., -22.7075, -22.9782, -25.5614],\n",
            "        [-23.3445, -22.2535, -22.9153,  ..., -24.0140, -23.4482, -26.4604],\n",
            "        [-19.5069, -18.0547, -19.4563,  ..., -17.5510, -16.9853, -18.0565]]) tensor([[33971],\n",
            "        [29892],\n",
            "        [24323],\n",
            "        [   45],\n",
            "        [ 4583],\n",
            "        [21230],\n",
            "        [ 7969],\n",
            "        [22789],\n",
            "        [ 8463],\n",
            "        [  995],\n",
            "        [35554],\n",
            "        [31644],\n",
            "        [22704],\n",
            "        [28581],\n",
            "        [ 7026],\n",
            "        [28283]])\n",
            "tensor([[-22.6297, -23.4612, -18.9985,  ..., -24.9793, -20.0165, -20.3425],\n",
            "        [-21.2680, -22.1392, -18.2241,  ..., -21.3942, -19.2890, -18.0914],\n",
            "        [-19.2474, -17.8526, -19.3188,  ..., -20.9212, -20.8945, -20.6722],\n",
            "        ...,\n",
            "        [-21.7609, -21.8010, -24.4927,  ..., -20.6186, -20.4338, -21.0443],\n",
            "        [-18.0430, -18.9382, -17.0625,  ..., -20.4671, -17.6026, -17.1926],\n",
            "        [-26.3262, -25.7117, -24.0248,  ..., -27.7685, -26.0929, -24.5195]]) tensor([[ 9803],\n",
            "        [ 4160],\n",
            "        [21334],\n",
            "        [ 5534],\n",
            "        [23458],\n",
            "        [21904],\n",
            "        [23300],\n",
            "        [24452],\n",
            "        [  484],\n",
            "        [35554],\n",
            "        [ 3669],\n",
            "        [15178],\n",
            "        [31946],\n",
            "        [ 5446],\n",
            "        [ 7187],\n",
            "        [33729]])\n",
            "tensor([[-19.6976, -19.8681, -18.3489,  ..., -18.5800, -16.9173, -18.0310],\n",
            "        [-15.6909, -17.4618, -19.9834,  ..., -19.1071, -16.6782, -18.6847],\n",
            "        [-27.6356, -27.8013, -26.1408,  ..., -27.3137, -25.8566, -25.2905],\n",
            "        ...,\n",
            "        [-25.3042, -26.4333, -26.8866,  ..., -27.6223, -25.8957, -27.5812],\n",
            "        [-18.8226, -16.0940, -15.8509,  ..., -17.3994, -17.5279, -16.7772],\n",
            "        [-19.9279, -22.4050, -20.0987,  ..., -24.1204, -22.7545, -24.5169]]) tensor([[17953],\n",
            "        [27697],\n",
            "        [32587],\n",
            "        [36732],\n",
            "        [32940],\n",
            "        [22038],\n",
            "        [ 1052],\n",
            "        [  949],\n",
            "        [29060],\n",
            "        [17211],\n",
            "        [36281],\n",
            "        [21214],\n",
            "        [ 1731],\n",
            "        [24258],\n",
            "        [  216],\n",
            "        [  736]])\n",
            "tensor([[-18.6300, -19.2143, -17.8496,  ..., -22.3397, -18.2935, -19.7696],\n",
            "        [-19.2529, -21.8235, -23.6906,  ..., -23.6824, -21.2629, -21.8452],\n",
            "        [-22.2109, -24.3573, -23.5004,  ..., -24.5496, -24.6149, -24.1953],\n",
            "        ...,\n",
            "        [-16.5606, -18.8035, -17.9506,  ..., -19.3476, -16.6629, -16.9378],\n",
            "        [-23.0386, -23.7827, -23.9934,  ..., -27.7572, -23.4595, -25.4978],\n",
            "        [-19.0266, -20.5732, -18.3756,  ..., -21.7862, -18.4939, -17.8912]]) tensor([[29580],\n",
            "        [35319],\n",
            "        [18406],\n",
            "        [13830],\n",
            "        [ 1887],\n",
            "        [30766],\n",
            "        [33522],\n",
            "        [ 8148],\n",
            "        [10746],\n",
            "        [ 2305],\n",
            "        [23546],\n",
            "        [13497],\n",
            "        [11902],\n",
            "        [ 7721],\n",
            "        [35161],\n",
            "        [25737]])\n",
            "tensor([[-24.9138, -24.2540, -26.4514,  ..., -28.3147, -25.4941, -24.8454],\n",
            "        [-19.8875, -20.1024, -19.9799,  ..., -21.9443, -22.0993, -21.6311],\n",
            "        [-21.4829, -23.0297, -22.5749,  ..., -22.8978, -20.4090, -23.9752],\n",
            "        ...,\n",
            "        [-14.1964, -18.2073, -14.4081,  ..., -17.8622, -14.9854, -15.6980],\n",
            "        [-22.0607, -23.7851, -25.1094,  ..., -25.6024, -24.2698, -22.8733],\n",
            "        [-22.0120, -21.9693, -21.1386,  ..., -21.5756, -19.0801, -20.5959]]) tensor([[22997],\n",
            "        [23546],\n",
            "        [31352],\n",
            "        [14401],\n",
            "        [31248],\n",
            "        [28607],\n",
            "        [29928],\n",
            "        [ 3815],\n",
            "        [34821],\n",
            "        [36742],\n",
            "        [ 3983],\n",
            "        [11941],\n",
            "        [23367],\n",
            "        [20284],\n",
            "        [ 4614],\n",
            "        [11225]])\n",
            "tensor([[-20.4200, -23.5689, -19.9479,  ..., -23.1440, -18.7452, -17.4966],\n",
            "        [-24.9936, -24.2968, -23.5503,  ..., -27.4952, -22.8696, -22.3878],\n",
            "        [-20.5847, -22.6405, -21.5428,  ..., -24.1972, -21.1068, -20.5307],\n",
            "        ...,\n",
            "        [-17.5521, -19.6467, -16.0862,  ..., -19.7250, -16.8757, -17.1489],\n",
            "        [-19.2801, -18.3465, -17.3856,  ..., -20.7950, -16.4707, -17.8064],\n",
            "        [-16.8597, -19.6645, -16.5676,  ..., -20.7341, -17.3982, -17.9348]]) tensor([[ 5277],\n",
            "        [22411],\n",
            "        [21089],\n",
            "        [22038],\n",
            "        [  887],\n",
            "        [23546],\n",
            "        [36742],\n",
            "        [  887],\n",
            "        [29766],\n",
            "        [17211],\n",
            "        [36281],\n",
            "        [21214],\n",
            "        [ 1731],\n",
            "        [ 1991],\n",
            "        [17211],\n",
            "        [ 6780]])\n",
            "tensor([[-21.7224, -26.6075, -23.3279,  ..., -25.4119, -24.8757, -21.9260],\n",
            "        [-26.7987, -30.5084, -30.0891,  ..., -31.7419, -28.5151, -26.1751],\n",
            "        [-15.8306, -20.9547, -18.1495,  ..., -17.3983, -16.3943, -16.9644],\n",
            "        ...,\n",
            "        [-19.0489, -19.0086, -19.7283,  ..., -20.9243, -20.5740, -19.0892],\n",
            "        [-20.7599, -23.7994, -22.1902,  ..., -23.3875, -24.0510, -19.4003],\n",
            "        [-15.4363, -17.8658, -15.0212,  ..., -16.1025, -17.9512, -18.0699]]) tensor([[ 2085],\n",
            "        [23546],\n",
            "        [ 9802],\n",
            "        [12222],\n",
            "        [16486],\n",
            "        [30344],\n",
            "        [11902],\n",
            "        [32863],\n",
            "        [ 1788],\n",
            "        [29679],\n",
            "        [19153],\n",
            "        [11004],\n",
            "        [22789],\n",
            "        [14401],\n",
            "        [26592],\n",
            "        [24971]])\n",
            "tensor([[-20.9137, -23.0798, -20.6960,  ..., -23.3096, -20.7818, -21.3880],\n",
            "        [-24.9019, -25.4556, -23.5184,  ..., -26.4799, -26.1447, -27.2319],\n",
            "        [-20.4442, -20.3644, -21.0443,  ..., -24.6870, -20.4702, -20.1489],\n",
            "        ...,\n",
            "        [-21.4350, -19.4314, -19.0384,  ..., -18.9285, -18.2570, -17.7777],\n",
            "        [-21.8027, -22.8100, -23.2934,  ..., -20.9924, -21.6359, -22.2035],\n",
            "        [-19.1116, -16.3125, -17.0739,  ..., -18.5740, -17.6864, -17.7268]]) tensor([[13277],\n",
            "        [ 2531],\n",
            "        [30392],\n",
            "        [23156],\n",
            "        [ 4915],\n",
            "        [33486],\n",
            "        [21104],\n",
            "        [11247],\n",
            "        [ 9477],\n",
            "        [10836],\n",
            "        [ 2082],\n",
            "        [ 1887],\n",
            "        [35104],\n",
            "        [11902],\n",
            "        [ 5977],\n",
            "        [12049]])\n",
            "tensor([[-16.7505, -17.5032, -14.5767,  ..., -18.2762, -15.7983, -15.5715],\n",
            "        [-17.4523, -18.5900, -15.8202,  ..., -21.3824, -18.6132, -17.3911],\n",
            "        [-19.9951, -17.0576, -16.9411,  ..., -21.2181, -18.0074, -20.8262],\n",
            "        ...,\n",
            "        [-20.9740, -23.7963, -21.7485,  ..., -22.4416, -21.9554, -21.1660],\n",
            "        [-19.3893, -17.6707, -17.8000,  ..., -17.3829, -19.1814, -19.5451],\n",
            "        [-20.5829, -19.8414, -18.9962,  ..., -22.5318, -18.8832, -18.6656]]) tensor([[ 3669],\n",
            "        [23300],\n",
            "        [26547],\n",
            "        [21089],\n",
            "        [33090],\n",
            "        [12049],\n",
            "        [ 9803],\n",
            "        [23546],\n",
            "        [16350],\n",
            "        [ 1887],\n",
            "        [12713],\n",
            "        [23268],\n",
            "        [11486],\n",
            "        [24422],\n",
            "        [15383],\n",
            "        [23546]])\n",
            "tensor([[-22.1593, -26.7744, -25.1758,  ..., -27.6453, -24.9328, -26.1897],\n",
            "        [-18.3980, -19.8647, -19.6319,  ..., -20.1231, -18.5716, -20.7148],\n",
            "        [-23.2975, -25.5330, -23.0524,  ..., -23.4401, -26.1676, -24.4283],\n",
            "        ...,\n",
            "        [-18.7158, -18.5926, -19.5037,  ..., -21.6056, -20.8220, -18.7950],\n",
            "        [-20.2540, -21.4015, -21.2336,  ..., -19.2910, -20.7013, -22.5297],\n",
            "        [-14.4528, -15.8383, -15.0740,  ..., -15.5031, -15.2736, -15.1575]]) tensor([[13971],\n",
            "        [ 2410],\n",
            "        [ 3585],\n",
            "        [29184],\n",
            "        [15383],\n",
            "        [17413],\n",
            "        [20951],\n",
            "        [21035],\n",
            "        [16350],\n",
            "        [12591],\n",
            "        [ 7955],\n",
            "        [ 6438],\n",
            "        [26400],\n",
            "        [ 1887],\n",
            "        [32671],\n",
            "        [  736]])\n",
            "tensor([[-17.2879, -19.3295, -19.2705,  ..., -22.8865, -19.8423, -20.7449],\n",
            "        [-22.2853, -23.2556, -22.0335,  ..., -22.9904, -16.6772, -19.0929],\n",
            "        [-26.9876, -25.5009, -23.5631,  ..., -25.8219, -23.9818, -23.0117],\n",
            "        ...,\n",
            "        [-18.2114, -21.1750, -18.7173,  ..., -20.4837, -19.5432, -19.8052],\n",
            "        [-19.5534, -22.3735, -22.0873,  ..., -23.7558, -20.8826, -20.0438],\n",
            "        [-16.8616, -16.2175, -14.8309,  ..., -17.3796, -16.4171, -14.6916]]) tensor([[ 1887],\n",
            "        [ 9803],\n",
            "        [17082],\n",
            "        [11004],\n",
            "        [36799],\n",
            "        [20951],\n",
            "        [29760],\n",
            "        [ 3669],\n",
            "        [22836],\n",
            "        [25088],\n",
            "        [36281],\n",
            "        [21214],\n",
            "        [26196],\n",
            "        [ 7679],\n",
            "        [11902],\n",
            "        [23458]])\n",
            "tensor([[-23.5954, -24.2033, -21.5887,  ..., -27.1036, -22.4834, -26.9577],\n",
            "        [-16.8693, -20.1188, -20.2933,  ..., -20.0602, -18.2836, -19.6548],\n",
            "        [-21.7204, -22.4173, -18.4988,  ..., -24.3951, -20.6171, -20.8781],\n",
            "        ...,\n",
            "        [-27.9843, -28.8547, -27.7203,  ..., -31.6298, -28.5102, -29.0420],\n",
            "        [-22.1723, -22.6939, -21.5607,  ..., -22.9039, -23.3763, -22.2256],\n",
            "        [-27.0970, -27.0182, -27.0114,  ..., -29.3550, -26.6889, -29.3411]]) tensor([[13101],\n",
            "        [30257],\n",
            "        [ 1887],\n",
            "        [18338],\n",
            "        [26936],\n",
            "        [17211],\n",
            "        [36281],\n",
            "        [21214],\n",
            "        [26760],\n",
            "        [ 8148],\n",
            "        [21650],\n",
            "        [26164],\n",
            "        [  503],\n",
            "        [ 2454],\n",
            "        [29580],\n",
            "        [11902]])\n",
            "tensor([[-21.3508, -18.6384, -18.6735,  ..., -19.5576, -20.4837, -20.7528],\n",
            "        [-23.5429, -23.7446, -24.3321,  ..., -24.3455, -22.4877, -26.8327],\n",
            "        [-21.2536, -21.7618, -21.1945,  ..., -27.8646, -21.4730, -20.1848],\n",
            "        ...,\n",
            "        [-21.3882, -21.3474, -21.6232,  ..., -22.1649, -21.5794, -20.7194],\n",
            "        [-17.1551, -20.4575, -18.2199,  ..., -20.2114, -16.7754, -19.9584],\n",
            "        [-22.7596, -26.6874, -22.9271,  ..., -27.0687, -22.0731, -23.1567]]) tensor([[32627],\n",
            "        [33726],\n",
            "        [21604],\n",
            "        [19262],\n",
            "        [30405],\n",
            "        [ 7523],\n",
            "        [33893],\n",
            "        [25868],\n",
            "        [ 8148],\n",
            "        [32632],\n",
            "        [18170],\n",
            "        [  736],\n",
            "        [22571],\n",
            "        [  216],\n",
            "        [ 3747],\n",
            "        [36799]])\n",
            "tensor([[-16.2025, -17.5735, -17.1121,  ..., -17.8862, -15.4005, -17.3697],\n",
            "        [-21.9590, -21.1555, -20.9934,  ..., -23.6716, -20.8932, -21.4087],\n",
            "        [-19.7463, -19.3512, -20.5528,  ..., -19.2271, -18.5344, -17.5274],\n",
            "        ...,\n",
            "        [-21.2876, -20.6299, -22.5441,  ..., -23.4012, -22.6392, -23.7033],\n",
            "        [-17.0080, -20.2274, -20.2929,  ..., -17.8571, -19.8107, -18.9846],\n",
            "        [-16.3311, -17.4350, -16.7211,  ..., -17.4831, -20.3780, -16.1312]]) tensor([[18196],\n",
            "        [13753],\n",
            "        [ 2454],\n",
            "        [ 2255],\n",
            "        [21993],\n",
            "        [  957],\n",
            "        [ 4532],\n",
            "        [31352],\n",
            "        [  957],\n",
            "        [11486],\n",
            "        [23367],\n",
            "        [22492],\n",
            "        [  503],\n",
            "        [ 2368],\n",
            "        [33057],\n",
            "        [ 7955]])\n",
            "tensor([[-21.3445, -21.5875, -21.8303,  ..., -21.2500, -19.1611, -20.9903],\n",
            "        [-21.5593, -18.8949, -19.5410,  ..., -20.7956, -18.1064, -19.8883],\n",
            "        [-21.5223, -24.0163, -20.9244,  ..., -23.8744, -20.8920, -19.3301],\n",
            "        ...,\n",
            "        [-17.5300, -17.0754, -17.1323,  ..., -16.7608, -16.9785, -16.4029],\n",
            "        [-23.9538, -23.3238, -19.8434,  ..., -21.5294, -22.4144, -20.6129],\n",
            "        [-24.0727, -22.4444, -25.0414,  ..., -24.1597, -22.0074, -21.6219]]) tensor([[22571],\n",
            "        [31375],\n",
            "        [23144],\n",
            "        [18737],\n",
            "        [ 4001],\n",
            "        [11374],\n",
            "        [28852],\n",
            "        [14529],\n",
            "        [20750],\n",
            "        [10555],\n",
            "        [ 1887],\n",
            "        [29167],\n",
            "        [ 4160],\n",
            "        [11749],\n",
            "        [33324],\n",
            "        [ 4124]])\n",
            "tensor([[-21.4620, -18.4743, -19.6125,  ..., -20.1520, -21.7207, -20.2356],\n",
            "        [-34.1223, -33.0941, -30.7466,  ..., -30.8842, -32.8216, -29.7707],\n",
            "        [-22.7723, -25.6521, -21.3291,  ..., -24.1068, -23.0086, -22.3759],\n",
            "        ...,\n",
            "        [-16.9917, -17.6389, -15.8315,  ..., -16.4338, -18.3842, -15.4695],\n",
            "        [-21.3210, -24.1221, -23.9191,  ..., -25.9021, -23.1271, -23.2259],\n",
            "        [-17.1173, -17.2539, -17.7727,  ..., -17.6138, -19.0083, -20.0288]]) tensor([[22877],\n",
            "        [26257],\n",
            "        [ 4899],\n",
            "        [24491],\n",
            "        [21882],\n",
            "        [ 9788],\n",
            "        [34616],\n",
            "        [17832],\n",
            "        [28035],\n",
            "        [ 8594],\n",
            "        [33793],\n",
            "        [31090],\n",
            "        [34616],\n",
            "        [31889],\n",
            "        [14809],\n",
            "        [27515]])\n",
            "tensor([[-20.5685, -21.5965, -21.9269,  ..., -24.3507, -23.3549, -20.1564],\n",
            "        [-22.4387, -22.3657, -22.5797,  ..., -22.3578, -23.5690, -23.7081],\n",
            "        [-20.7372, -21.4380, -18.6768,  ..., -20.5409, -19.6757, -19.4131],\n",
            "        ...,\n",
            "        [-20.5804, -22.7096, -21.4998,  ..., -23.4061, -20.0172, -21.5371],\n",
            "        [-19.1557, -19.2087, -16.2579,  ..., -18.1744, -16.3689, -15.7274],\n",
            "        [-17.0383, -17.5723, -17.0480,  ..., -17.0148, -17.1427, -18.0645]]) tensor([[ 1887],\n",
            "        [ 9803],\n",
            "        [10176],\n",
            "        [25858],\n",
            "        [  801],\n",
            "        [29661],\n",
            "        [34616],\n",
            "        [34077],\n",
            "        [ 7679],\n",
            "        [12700],\n",
            "        [16261],\n",
            "        [36281],\n",
            "        [21214],\n",
            "        [18170],\n",
            "        [ 2305],\n",
            "        [14733]])\n",
            "tensor([[-30.8491, -28.8491, -24.6789,  ..., -27.8218, -25.3092, -29.3163],\n",
            "        [-27.4007, -29.2279, -26.5729,  ..., -29.7753, -25.7381, -27.3680],\n",
            "        [-20.9167, -20.8423, -20.5096,  ..., -19.7826, -21.1786, -21.9601],\n",
            "        ...,\n",
            "        [-18.6210, -18.2883, -17.3761,  ..., -17.3739, -16.6824, -16.6744],\n",
            "        [-18.2015, -20.2459, -17.2673,  ..., -17.3962, -17.4017, -16.5093],\n",
            "        [-24.5535, -25.9596, -23.3679,  ..., -26.6216, -24.0668, -23.3044]]) tensor([[33949],\n",
            "        [32902],\n",
            "        [ 9803],\n",
            "        [11902],\n",
            "        [ 3669],\n",
            "        [36348],\n",
            "        [ 8463],\n",
            "        [14741],\n",
            "        [29580],\n",
            "        [34413],\n",
            "        [14160],\n",
            "        [17306],\n",
            "        [ 1887],\n",
            "        [ 7127],\n",
            "        [ 8463],\n",
            "        [14741]])\n",
            "tensor([[-23.7808, -22.8124, -22.3414,  ..., -24.4634, -24.6784, -23.6726],\n",
            "        [-19.4272, -20.7561, -21.5258,  ..., -22.6660, -20.0246, -16.2109],\n",
            "        [-16.8922, -21.5332, -18.9607,  ..., -23.2388, -16.9451, -20.2703],\n",
            "        ...,\n",
            "        [-25.1445, -23.6693, -22.4550,  ..., -24.1738, -22.4361, -23.9997],\n",
            "        [-16.5760, -15.1542, -17.4947,  ..., -17.4712, -17.8618, -18.0971],\n",
            "        [-25.0319, -26.2850, -23.6232,  ..., -25.3035, -26.1315, -22.6925]]) tensor([[ 1276],\n",
            "        [ 8459],\n",
            "        [31522],\n",
            "        [29580],\n",
            "        [34413],\n",
            "        [14160],\n",
            "        [ 6520],\n",
            "        [ 2305],\n",
            "        [ 5903],\n",
            "        [24491],\n",
            "        [28899],\n",
            "        [25671],\n",
            "        [ 8903],\n",
            "        [21379],\n",
            "        [14756],\n",
            "        [32587]])\n",
            "tensor([[-23.5973, -28.1496, -24.7524,  ..., -28.1275, -26.0203, -23.9411],\n",
            "        [-16.1601, -17.5601, -16.8900,  ..., -15.9452, -15.0864, -14.7693],\n",
            "        [-19.8327, -22.0910, -20.5434,  ..., -25.5004, -19.6872, -18.3980],\n",
            "        ...,\n",
            "        [-23.7778, -25.2425, -24.2409,  ..., -25.7821, -26.2351, -25.0861],\n",
            "        [-23.2713, -26.8743, -24.1742,  ..., -26.4249, -24.6373, -24.0367],\n",
            "        [-19.8945, -18.8456, -21.4925,  ..., -19.5897, -16.8191, -17.9317]]) tensor([[ 9007],\n",
            "        [ 7671],\n",
            "        [ 2255],\n",
            "        [ 9045],\n",
            "        [10842],\n",
            "        [ 1176],\n",
            "        [25671],\n",
            "        [35053],\n",
            "        [  297],\n",
            "        [16350],\n",
            "        [ 2255],\n",
            "        [21993],\n",
            "        [12217],\n",
            "        [33057],\n",
            "        [32397],\n",
            "        [27084]])\n",
            "tensor([[-19.3307, -21.4976, -18.5237,  ..., -22.6023, -20.2418, -18.6882],\n",
            "        [-23.0579, -24.5713, -23.2632,  ..., -26.1397, -22.1968, -21.0702],\n",
            "        [-22.0078, -22.7163, -23.0140,  ..., -22.9963, -20.7969, -20.1835],\n",
            "        ...,\n",
            "        [-19.7275, -18.9706, -20.5044,  ..., -19.2914, -20.5736, -20.1477],\n",
            "        [-16.4054, -17.7030, -17.3138,  ..., -16.8260, -17.9783, -19.3290],\n",
            "        [-16.6339, -19.1599, -16.5171,  ..., -17.5889, -16.6433, -16.9334]]) tensor([[36348],\n",
            "        [ 3669],\n",
            "        [ 2368],\n",
            "        [26650],\n",
            "        [13186],\n",
            "        [21993],\n",
            "        [11437],\n",
            "        [30215],\n",
            "        [21260],\n",
            "        [26400],\n",
            "        [26650],\n",
            "        [ 2368],\n",
            "        [23546],\n",
            "        [ 1887],\n",
            "        [27084],\n",
            "        [11902]])\n",
            "tensor([[-18.9519, -16.8457, -21.2373,  ..., -19.3682, -18.1724, -17.9466],\n",
            "        [-22.4437, -20.9193, -20.6287,  ..., -20.0416, -21.5497, -22.7799],\n",
            "        [-17.3945, -19.5768, -17.3002,  ..., -18.1635, -16.9458, -17.1911],\n",
            "        ...,\n",
            "        [-17.2900, -20.5527, -19.6155,  ..., -18.4880, -17.9037, -18.3849],\n",
            "        [-20.6480, -21.7013, -21.8978,  ..., -21.0059, -24.0180, -22.2723],\n",
            "        [-13.8173, -16.5890, -14.5184,  ..., -16.8965, -14.0103, -16.7850]]) tensor([[ 1099],\n",
            "        [ 9656],\n",
            "        [13186],\n",
            "        [ 9402],\n",
            "        [ 8869],\n",
            "        [21379],\n",
            "        [21089],\n",
            "        [22038],\n",
            "        [  887],\n",
            "        [ 2255],\n",
            "        [35104],\n",
            "        [23635],\n",
            "        [17499],\n",
            "        [18797],\n",
            "        [ 4089],\n",
            "        [ 8940]])\n",
            "tensor([[-18.8203, -19.0321, -18.3255,  ..., -18.3103, -18.2748, -15.2851],\n",
            "        [-15.7430, -15.0113, -16.0383,  ..., -15.1429, -15.5761, -15.6051],\n",
            "        [-15.5479, -17.1922, -16.3158,  ..., -16.0802, -14.0509, -16.7109],\n",
            "        ...,\n",
            "        [-35.8398, -35.3564, -33.6928,  ..., -35.1321, -31.9606, -35.3384],\n",
            "        [-15.6409, -15.6043, -15.1082,  ..., -17.1260, -16.4516, -16.1438],\n",
            "        [-22.8043, -19.8639, -20.1273,  ..., -21.9813, -21.5562, -22.1818]]) tensor([[11902],\n",
            "        [19054],\n",
            "        [14809],\n",
            "        [34762],\n",
            "        [ 3669],\n",
            "        [22704],\n",
            "        [33763],\n",
            "        [ 3669],\n",
            "        [11902],\n",
            "        [27515],\n",
            "        [23069],\n",
            "        [ 3669],\n",
            "        [  752],\n",
            "        [ 8940],\n",
            "        [ 7969],\n",
            "        [28041]])\n",
            "tensor([[-21.8876, -20.6973, -21.5453,  ..., -22.1119, -17.9358, -19.5963],\n",
            "        [-18.1607, -18.5456, -21.2988,  ..., -20.6681, -18.1746, -19.5314],\n",
            "        [-23.2351, -20.4838, -17.8354,  ..., -19.5911, -21.3875, -21.3859],\n",
            "        ...,\n",
            "        [-17.4584, -21.1271, -19.3382,  ..., -22.5374, -20.0527, -21.4342],\n",
            "        [-21.5267, -26.5164, -21.0484,  ..., -25.2864, -25.8245, -23.5714],\n",
            "        [-24.4361, -24.3334, -27.6657,  ..., -29.8893, -26.4065, -24.5820]]) tensor([[11902],\n",
            "        [17413],\n",
            "        [36348],\n",
            "        [13186],\n",
            "        [24861],\n",
            "        [ 1887],\n",
            "        [ 9402],\n",
            "        [17413],\n",
            "        [14809],\n",
            "        [25854],\n",
            "        [35175],\n",
            "        [33694],\n",
            "        [11437],\n",
            "        [ 1720],\n",
            "        [11902],\n",
            "        [ 1218]])\n",
            "tensor([[-19.5328, -21.2700, -22.8919,  ..., -22.7198, -19.1783, -19.8849],\n",
            "        [-17.4241, -18.7187, -19.3241,  ..., -17.4720, -18.7550, -18.3260],\n",
            "        [-16.7805, -20.0634, -19.3785,  ..., -19.4297, -20.0277, -19.0070],\n",
            "        ...,\n",
            "        [-19.1378, -22.7761, -22.7652,  ..., -23.1060, -20.4440, -18.5213],\n",
            "        [-22.2184, -21.8075, -23.8487,  ..., -25.3131, -20.9752, -21.9127],\n",
            "        [-23.8506, -26.8928, -24.5188,  ..., -28.1024, -25.4214, -25.2100]]) tensor([[20319],\n",
            "        [19367],\n",
            "        [19550],\n",
            "        [24491],\n",
            "        [ 1887],\n",
            "        [22345],\n",
            "        [24491],\n",
            "        [20489],\n",
            "        [14807],\n",
            "        [16269],\n",
            "        [25239],\n",
            "        [ 8560],\n",
            "        [26623],\n",
            "        [19478],\n",
            "        [ 5857],\n",
            "        [27665]])\n",
            "tensor([[-30.5373, -29.9966, -27.8187,  ..., -31.4439, -27.4386, -24.7588],\n",
            "        [-26.5665, -24.7155, -24.0734,  ..., -24.8361, -22.4803, -22.5918],\n",
            "        [-20.3355, -17.5297, -18.1816,  ..., -17.8876, -16.9454, -18.5134],\n",
            "        ...,\n",
            "        [-18.5423, -20.0796, -20.5663,  ..., -23.0244, -16.7702, -21.5431],\n",
            "        [-23.0588, -24.0413, -22.5848,  ..., -26.0038, -23.7400, -22.9305],\n",
            "        [-21.4219, -23.3037, -21.7458,  ..., -20.5080, -19.0262, -19.9749]]) tensor([[30845],\n",
            "        [29074],\n",
            "        [35554],\n",
            "        [28379],\n",
            "        [35669],\n",
            "        [33692],\n",
            "        [ 9039],\n",
            "        [12794],\n",
            "        [ 1847],\n",
            "        [ 9070],\n",
            "        [ 1887],\n",
            "        [31906],\n",
            "        [ 5001],\n",
            "        [25241],\n",
            "        [ 9471],\n",
            "        [20951]])\n",
            "tensor([[-21.2164, -21.6684, -22.6384,  ..., -25.4647, -21.1831, -18.0762],\n",
            "        [-23.5557, -26.5528, -24.5002,  ..., -24.8018, -21.2078, -25.0039],\n",
            "        [-30.0723, -30.5547, -29.5083,  ..., -31.8012, -28.7900, -28.7724],\n",
            "        ...,\n",
            "        [-18.5627, -22.2659, -23.0087,  ..., -22.5881, -21.9752, -22.3335],\n",
            "        [-17.9188, -18.9894, -16.8050,  ..., -19.2855, -18.9586, -15.1876],\n",
            "        [-19.4121, -20.1734, -19.7954,  ..., -21.8190, -20.0200, -21.6666]]) tensor([[ 6626],\n",
            "        [24447],\n",
            "        [  426],\n",
            "        [ 9471],\n",
            "        [ 9880],\n",
            "        [ 9070],\n",
            "        [21238],\n",
            "        [24174],\n",
            "        [ 1887],\n",
            "        [29994],\n",
            "        [ 1887],\n",
            "        [30264],\n",
            "        [ 5001],\n",
            "        [32193],\n",
            "        [33304],\n",
            "        [27084]])\n",
            "tensor([[-16.9032, -18.3746, -20.1783,  ..., -20.2395, -17.2703, -16.7328],\n",
            "        [-23.6335, -22.2767, -20.1920,  ..., -20.9369, -22.3200, -19.4190],\n",
            "        [-17.9262, -19.8023, -18.4030,  ..., -19.0122, -18.4447, -16.9777],\n",
            "        ...,\n",
            "        [-18.2433, -17.5022, -17.4454,  ..., -18.6955, -16.9124, -18.4362],\n",
            "        [-19.4709, -22.0731, -22.4595,  ..., -21.5956, -20.1877, -17.7404],\n",
            "        [-16.6288, -15.6522, -15.3510,  ..., -17.3217, -16.9637, -14.1156]]) tensor([[17413],\n",
            "        [10383],\n",
            "        [ 2606],\n",
            "        [29994],\n",
            "        [31352],\n",
            "        [35104],\n",
            "        [29994],\n",
            "        [29994],\n",
            "        [33793],\n",
            "        [ 2628],\n",
            "        [   45],\n",
            "        [36732],\n",
            "        [29598],\n",
            "        [ 7691],\n",
            "        [11085],\n",
            "        [25241]])\n",
            "tensor([[-20.4435, -20.0536, -16.9177,  ..., -20.0642, -18.7570, -16.6034],\n",
            "        [-24.7410, -25.3706, -21.4401,  ..., -25.5211, -22.5904, -24.2288],\n",
            "        [-21.5741, -20.0480, -18.4123,  ..., -21.4659, -19.2363, -18.0433],\n",
            "        ...,\n",
            "        [-32.8136, -33.4004, -32.0921,  ..., -37.6079, -36.2162, -36.7797],\n",
            "        [-25.1795, -30.0477, -28.3445,  ..., -28.3879, -26.4159, -26.5705],\n",
            "        [-20.2026, -20.7057, -23.3935,  ..., -21.5793, -22.0493, -19.3379]]) tensor([[29928],\n",
            "        [23300],\n",
            "        [ 7019],\n",
            "        [ 6395],\n",
            "        [ 4983],\n",
            "        [ 4002],\n",
            "        [14401],\n",
            "        [ 8276],\n",
            "        [ 1887],\n",
            "        [18762],\n",
            "        [34938],\n",
            "        [25239],\n",
            "        [18138],\n",
            "        [19730],\n",
            "        [25310],\n",
            "        [12187]])\n",
            "tensor([[-14.5084, -15.1656, -14.2261,  ..., -15.3395, -14.8409, -14.8781],\n",
            "        [-17.0803, -18.5328, -19.8114,  ..., -19.7865, -17.1329, -19.1891],\n",
            "        [-24.2350, -26.9624, -24.5577,  ..., -23.9646, -27.6582, -23.9144],\n",
            "        ...,\n",
            "        [-16.2394, -19.1540, -17.3743,  ..., -19.9059, -17.8385, -20.9807],\n",
            "        [-21.1242, -21.9019, -22.0349,  ..., -23.6771, -23.8786, -23.2981],\n",
            "        [-19.2637, -19.0644, -16.9398,  ..., -20.1844, -19.5304, -20.1671]]) tensor([[ 4983],\n",
            "        [33177],\n",
            "        [29598],\n",
            "        [36269],\n",
            "        [14598],\n",
            "        [30759],\n",
            "        [29994],\n",
            "        [16203],\n",
            "        [29598],\n",
            "        [  674],\n",
            "        [ 1887],\n",
            "        [ 4983],\n",
            "        [ 4983],\n",
            "        [26454],\n",
            "        [23300],\n",
            "        [10746]])\n",
            "tensor([[-16.3795, -16.0295, -16.8097,  ..., -18.0388, -17.3557, -15.4323],\n",
            "        [-17.8562, -17.6162, -17.7226,  ..., -17.5504, -18.1332, -18.4457],\n",
            "        [-14.9557, -16.7727, -16.0610,  ..., -15.9735, -17.5669, -15.8768],\n",
            "        ...,\n",
            "        [-16.7792, -17.1729, -17.7786,  ..., -18.5259, -18.7421, -18.7544],\n",
            "        [-22.8083, -20.9751, -18.7394,  ..., -22.2025, -18.6222, -22.2616],\n",
            "        [-25.9317, -23.3989, -23.1171,  ..., -26.4110, -23.3554, -25.5439]]) tensor([[ 1433],\n",
            "        [12156],\n",
            "        [29542],\n",
            "        [16544],\n",
            "        [ 2255],\n",
            "        [15386],\n",
            "        [34472],\n",
            "        [33694],\n",
            "        [31017],\n",
            "        [ 5967],\n",
            "        [35104],\n",
            "        [12794],\n",
            "        [24971],\n",
            "        [23800],\n",
            "        [23800],\n",
            "        [ 8276]])\n",
            "tensor([[-19.5564, -18.5214, -21.0230,  ..., -19.0968, -17.3564, -21.9146],\n",
            "        [-23.5955, -27.2857, -25.7815,  ..., -27.4971, -25.8321, -24.1165],\n",
            "        [-15.3427, -17.7956, -15.9159,  ..., -16.3033, -15.9512, -16.1674],\n",
            "        ...,\n",
            "        [-23.2078, -20.5821, -20.8934,  ..., -24.9839, -21.9820, -21.2712],\n",
            "        [-17.4543, -17.8024, -17.4596,  ..., -21.2878, -19.2820, -14.5331],\n",
            "        [-26.3685, -28.7101, -24.7750,  ..., -27.4499, -25.1061, -24.9858]]) tensor([[ 3638],\n",
            "        [27018],\n",
            "        [24971],\n",
            "        [ 6013],\n",
            "        [ 7572],\n",
            "        [ 1887],\n",
            "        [18338],\n",
            "        [34010],\n",
            "        [ 6013],\n",
            "        [20951],\n",
            "        [ 8276],\n",
            "        [  319],\n",
            "        [35393],\n",
            "        [35562],\n",
            "        [ 6395],\n",
            "        [27635]])\n",
            "tensor([[-21.3282, -21.9232, -20.7140,  ..., -21.9764, -20.6928, -20.8794],\n",
            "        [-27.6809, -25.3708, -26.8042,  ..., -27.2267, -24.1073, -26.2405],\n",
            "        [-22.3614, -19.3376, -18.2972,  ..., -20.8941, -22.7439, -18.0878],\n",
            "        ...,\n",
            "        [-15.6462, -17.1745, -16.7054,  ..., -18.1324, -15.6371, -14.4653],\n",
            "        [-21.4757, -21.2499, -20.4797,  ..., -22.4475, -22.4102, -22.4904],\n",
            "        [-16.6070, -17.7054, -16.6835,  ..., -16.6477, -16.8761, -16.4052]]) tensor([[35393],\n",
            "        [35562],\n",
            "        [ 8973],\n",
            "        [ 6013],\n",
            "        [25182],\n",
            "        [ 9803],\n",
            "        [ 4160],\n",
            "        [ 9803],\n",
            "        [  752],\n",
            "        [13211],\n",
            "        [30007],\n",
            "        [22873],\n",
            "        [ 9794],\n",
            "        [17702],\n",
            "        [23635],\n",
            "        [26354]])\n",
            "tensor([[-19.7218, -21.2014, -20.7393,  ..., -21.8264, -21.9093, -20.7454],\n",
            "        [-18.8517, -21.1958, -19.7128,  ..., -21.5676, -21.6693, -17.8081],\n",
            "        [-16.1537, -17.2439, -17.7446,  ..., -18.3033, -16.0021, -15.5877],\n",
            "        ...,\n",
            "        [-28.1539, -26.2792, -24.1732,  ..., -29.0093, -26.7375, -23.7867],\n",
            "        [-20.7902, -24.2498, -23.1126,  ..., -24.8682, -22.4685, -21.4165],\n",
            "        [-19.7184, -23.1402, -22.6896,  ..., -22.3637, -22.0648, -21.1369]]) tensor([[ 3267],\n",
            "        [28147],\n",
            "        [24971],\n",
            "        [11902],\n",
            "        [21089],\n",
            "        [ 3724],\n",
            "        [24661],\n",
            "        [15529],\n",
            "        [23548],\n",
            "        [28265],\n",
            "        [32597],\n",
            "        [29580],\n",
            "        [14262],\n",
            "        [19257],\n",
            "        [35194],\n",
            "        [33726]])\n",
            "tensor([[-19.4017, -23.2458, -21.5120,  ..., -19.8026, -20.0378, -19.2128],\n",
            "        [-23.7129, -23.0882, -22.2023,  ..., -21.5967, -23.3129, -21.0896],\n",
            "        [-32.3435, -30.6735, -28.3655,  ..., -28.4284, -30.4596, -27.6614],\n",
            "        ...,\n",
            "        [-19.5472, -20.2450, -19.1662,  ..., -19.9625, -17.4614, -18.7159],\n",
            "        [-17.0130, -18.6160, -18.7337,  ..., -18.2864, -16.3473, -18.2993],\n",
            "        [-20.8141, -21.9649, -20.1332,  ..., -22.9467, -19.9884, -18.8311]]) tensor([[20561],\n",
            "        [13982],\n",
            "        [24769],\n",
            "        [ 2305],\n",
            "        [ 3669],\n",
            "        [19890],\n",
            "        [23061],\n",
            "        [ 2255],\n",
            "        [ 4005],\n",
            "        [20284],\n",
            "        [21796],\n",
            "        [31352],\n",
            "        [11486],\n",
            "        [11760],\n",
            "        [31168],\n",
            "        [ 2478]])\n",
            "tensor([[-26.4809, -25.9364, -24.7587,  ..., -26.2535, -25.0277, -20.6257],\n",
            "        [-18.6114, -20.9560, -21.7331,  ..., -21.2284, -21.5669, -21.8419],\n",
            "        [-21.8739, -20.6759, -19.6743,  ..., -20.5076, -21.7536, -20.1341],\n",
            "        ...,\n",
            "        [-21.5693, -22.0986, -21.8614,  ..., -20.9618, -20.0979, -18.9645],\n",
            "        [-18.0114, -19.1185, -17.2030,  ..., -18.0033, -16.6083, -14.9230],\n",
            "        [-20.2226, -22.9227, -19.2307,  ..., -21.8363, -21.0197, -21.5969]]) tensor([[10479],\n",
            "        [31480],\n",
            "        [13139],\n",
            "        [ 9803],\n",
            "        [ 2255],\n",
            "        [ 8466],\n",
            "        [21993],\n",
            "        [21230],\n",
            "        [20027],\n",
            "        [ 7987],\n",
            "        [12049],\n",
            "        [33828],\n",
            "        [35967],\n",
            "        [ 7326],\n",
            "        [ 5772],\n",
            "        [23300]])\n",
            "tensor([[-21.7811, -18.8603, -17.1117,  ..., -19.4201, -17.5380, -19.8540],\n",
            "        [-22.8516, -21.2662, -20.6175,  ..., -21.7329, -21.5773, -20.3074],\n",
            "        [-23.8536, -24.3850, -23.2946,  ..., -27.2568, -22.2556, -20.7320],\n",
            "        ...,\n",
            "        [-18.7697, -19.3987, -19.0809,  ..., -19.6816, -19.0975, -18.5036],\n",
            "        [-18.2832, -17.0099, -18.4498,  ..., -19.3295, -17.9543, -19.2918],\n",
            "        [-20.7857, -21.1885, -18.6391,  ..., -22.1587, -16.6517, -19.5564]]) tensor([[29381],\n",
            "        [ 2327],\n",
            "        [30845],\n",
            "        [ 3854],\n",
            "        [ 4363],\n",
            "        [ 5772],\n",
            "        [ 2628],\n",
            "        [10348],\n",
            "        [23300],\n",
            "        [11902],\n",
            "        [30264],\n",
            "        [36424],\n",
            "        [16544],\n",
            "        [ 1103],\n",
            "        [ 4564],\n",
            "        [16726]])\n",
            "tensor([[-21.2913, -21.2291, -18.5322,  ..., -22.2992, -20.5062, -21.7496],\n",
            "        [-20.5780, -19.7991, -16.5001,  ..., -17.1597, -18.6883, -18.9369],\n",
            "        [-31.3747, -35.7810, -38.1716,  ..., -38.2334, -32.7820, -34.1474],\n",
            "        ...,\n",
            "        [-24.7157, -20.7226, -21.7667,  ..., -26.7971, -20.5328, -22.4442],\n",
            "        [-23.6529, -23.3579, -22.5276,  ..., -26.5165, -22.5461, -20.7940],\n",
            "        [-26.2014, -28.4749, -26.4289,  ..., -29.2327, -26.2942, -26.7014]]) tensor([[17809],\n",
            "        [29892],\n",
            "        [36281],\n",
            "        [21214],\n",
            "        [17746],\n",
            "        [29746],\n",
            "        [11902],\n",
            "        [36281],\n",
            "        [21214],\n",
            "        [19257],\n",
            "        [35194],\n",
            "        [ 4723],\n",
            "        [ 4536],\n",
            "        [14262],\n",
            "        [19257],\n",
            "        [35194]])\n",
            "tensor([[-24.7288, -26.7426, -23.2957,  ..., -29.5109, -24.0810, -25.0525],\n",
            "        [-19.2185, -19.5414, -17.3820,  ..., -18.8706, -18.4435, -18.5228],\n",
            "        [-29.2757, -30.7843, -31.5234,  ..., -33.6907, -29.4009, -30.9082],\n",
            "        ...,\n",
            "        [-19.4864, -17.4053, -19.6606,  ..., -20.6649, -19.5768, -20.0237],\n",
            "        [-20.3444, -19.7002, -19.3085,  ..., -20.1247, -22.0526, -20.4142],\n",
            "        [-25.5046, -26.3686, -25.9776,  ..., -22.6856, -23.9515, -24.6795]]) tensor([[35967],\n",
            "        [ 8594],\n",
            "        [36281],\n",
            "        [21214],\n",
            "        [30264],\n",
            "        [11611],\n",
            "        [30264],\n",
            "        [25761],\n",
            "        [ 8940],\n",
            "        [28041],\n",
            "        [ 9289],\n",
            "        [11902],\n",
            "        [35967],\n",
            "        [21575],\n",
            "        [23546],\n",
            "        [23061]])\n",
            "tensor([[-19.5231, -21.6792, -20.3143,  ..., -22.2498, -19.1033, -25.4416],\n",
            "        [-23.0426, -21.9635, -21.8097,  ..., -23.7609, -21.1367, -19.4801],\n",
            "        [-22.7803, -22.3946, -22.9392,  ..., -23.7579, -22.1072, -20.6595],\n",
            "        ...,\n",
            "        [-23.6682, -25.3929, -22.5078,  ..., -26.5176, -22.4507, -23.7171],\n",
            "        [-22.1691, -23.4486, -22.2356,  ..., -25.7559, -23.4251, -25.5560],\n",
            "        [-15.5010, -18.6541, -16.0469,  ..., -18.2878, -15.4477, -17.6557]]) tensor([[  957],\n",
            "        [31017],\n",
            "        [32626],\n",
            "        [29930],\n",
            "        [ 3433],\n",
            "        [ 9661],\n",
            "        [11756],\n",
            "        [12700],\n",
            "        [25977],\n",
            "        [20324],\n",
            "        [  850],\n",
            "        [29892],\n",
            "        [36273],\n",
            "        [ 9289],\n",
            "        [36866],\n",
            "        [29892]])\n",
            "tensor([[-22.4207, -21.9722, -21.5168,  ..., -19.8511, -19.3959, -20.5454],\n",
            "        [-23.3707, -25.1659, -24.4472,  ..., -29.2031, -26.2970, -23.9180],\n",
            "        [-17.4430, -21.4463, -21.7539,  ..., -24.9099, -20.6015, -19.8257],\n",
            "        ...,\n",
            "        [-22.0980, -23.4834, -19.8892,  ..., -24.9627, -22.3692, -22.4870],\n",
            "        [-24.9764, -24.2345, -22.5320,  ..., -24.8542, -22.0625, -24.2777],\n",
            "        [-21.0966, -21.5234, -21.4813,  ..., -20.1112, -21.2932, -17.9643]]) tensor([[21808],\n",
            "        [17811],\n",
            "        [30845],\n",
            "        [ 3854],\n",
            "        [24936],\n",
            "        [23546],\n",
            "        [24911],\n",
            "        [ 2181],\n",
            "        [  736],\n",
            "        [ 9803],\n",
            "        [11902],\n",
            "        [34010],\n",
            "        [32039],\n",
            "        [31545],\n",
            "        [21067],\n",
            "        [  930]])\n",
            "tensor([[-19.4836, -17.1458, -19.5506,  ..., -19.3610, -17.4291, -18.6684],\n",
            "        [-20.3830, -20.0458, -19.0128,  ..., -20.3065, -18.1188, -16.4151],\n",
            "        [-20.7685, -19.7027, -20.0845,  ..., -18.7153, -16.8899, -16.3082],\n",
            "        ...,\n",
            "        [-19.5539, -17.2398, -15.9096,  ..., -17.9194, -17.5221, -18.3493],\n",
            "        [-35.8053, -36.2407, -37.9294,  ..., -39.2994, -35.2159, -35.6264],\n",
            "        [-29.7820, -30.9048, -28.9435,  ..., -32.2086, -28.0510, -29.9997]]) tensor([[33316],\n",
            "        [25677],\n",
            "        [32337],\n",
            "        [28615],\n",
            "        [33971],\n",
            "        [14401],\n",
            "        [26145],\n",
            "        [26282],\n",
            "        [34010],\n",
            "        [16486],\n",
            "        [22704],\n",
            "        [10410],\n",
            "        [ 9154],\n",
            "        [ 3570],\n",
            "        [36281],\n",
            "        [21214]])\n",
            "tensor([[-15.9530, -19.7991, -17.1016,  ..., -18.8853, -16.4732, -19.2488],\n",
            "        [-16.6262, -17.4743, -14.7975,  ..., -18.2056, -17.4257, -15.6306],\n",
            "        [-17.5217, -16.9394, -18.8304,  ..., -16.6426, -15.8223, -17.6442],\n",
            "        ...,\n",
            "        [-35.9508, -37.3166, -35.0393,  ..., -42.7099, -36.0085, -39.0960],\n",
            "        [-29.9796, -34.6107, -31.7907,  ..., -36.4361, -29.6395, -31.1887],\n",
            "        [-22.1480, -25.5701, -22.2671,  ..., -23.9282, -20.0929, -21.9037]]) tensor([[12199],\n",
            "        [ 4385],\n",
            "        [34022],\n",
            "        [22877],\n",
            "        [11902],\n",
            "        [17480],\n",
            "        [36388],\n",
            "        [21089],\n",
            "        [29598],\n",
            "        [16350],\n",
            "        [11902],\n",
            "        [12049],\n",
            "        [22593],\n",
            "        [36281],\n",
            "        [21214],\n",
            "        [ 7341]])\n",
            "tensor([[-22.2344, -21.5413, -20.7720,  ..., -22.1742, -23.3828, -22.6497],\n",
            "        [-20.1240, -21.4609, -21.2712,  ..., -22.9875, -20.4112, -20.1952],\n",
            "        [-20.7667, -20.8107, -22.2637,  ..., -22.9254, -20.3408, -20.3866],\n",
            "        ...,\n",
            "        [-20.3576, -20.2018, -17.4536,  ..., -21.3221, -20.9847, -20.5439],\n",
            "        [-18.5747, -18.9619, -18.9010,  ..., -20.8022, -18.9375, -21.2717],\n",
            "        [-21.0729, -24.5510, -23.0489,  ..., -24.7598, -23.2851, -23.1305]]) tensor([[11538],\n",
            "        [26354],\n",
            "        [  661],\n",
            "        [11611],\n",
            "        [12049],\n",
            "        [ 7341],\n",
            "        [27737],\n",
            "        [18138],\n",
            "        [19543],\n",
            "        [35967],\n",
            "        [13615],\n",
            "        [16350],\n",
            "        [25239],\n",
            "        [11263],\n",
            "        [ 1433],\n",
            "        [12199]])\n",
            "tensor([[-16.5457, -20.1304, -16.7428,  ..., -21.2594, -18.2095, -17.6461],\n",
            "        [-19.1578, -19.4222, -19.5318,  ..., -20.3498, -17.3583, -17.4789],\n",
            "        [-21.1411, -22.3983, -21.5952,  ..., -22.8992, -18.8134, -22.1428],\n",
            "        ...,\n",
            "        [-22.8621, -26.7818, -22.5210,  ..., -23.4791, -26.1787, -25.9299],\n",
            "        [-14.5278, -18.0314, -17.4173,  ..., -19.8526, -18.2153, -15.6789],\n",
            "        [-27.7531, -27.6880, -27.7279,  ..., -26.8857, -27.8624, -26.4958]]) tensor([[32782],\n",
            "        [16870],\n",
            "        [35554],\n",
            "        [ 1045],\n",
            "        [29892],\n",
            "        [28852],\n",
            "        [30423],\n",
            "        [ 3046],\n",
            "        [12075],\n",
            "        [35686],\n",
            "        [ 2255],\n",
            "        [31776],\n",
            "        [25854],\n",
            "        [17506],\n",
            "        [ 8695],\n",
            "        [ 3669]])\n",
            "tensor([[-22.6147, -24.0047, -21.5773,  ..., -24.4012, -21.9583, -22.5707],\n",
            "        [-17.6847, -16.7732, -19.6986,  ..., -19.5696, -19.6201, -18.2448],\n",
            "        [-24.0202, -25.7602, -23.8805,  ..., -26.0183, -23.4818, -24.1164],\n",
            "        ...,\n",
            "        [-20.2998, -23.1412, -19.5669,  ..., -24.3299, -19.7128, -19.4424],\n",
            "        [-23.0362, -23.4168, -19.7960,  ..., -19.9456, -18.8047, -20.3730],\n",
            "        [-18.1566, -22.2764, -21.7998,  ..., -23.3492, -19.7665, -20.0240]]) tensor([[24971],\n",
            "        [ 1065],\n",
            "        [ 3669],\n",
            "        [ 9070],\n",
            "        [26354],\n",
            "        [27494],\n",
            "        [ 1788],\n",
            "        [18099],\n",
            "        [35611],\n",
            "        [11790],\n",
            "        [30264],\n",
            "        [31203],\n",
            "        [23876],\n",
            "        [15880],\n",
            "        [ 8653],\n",
            "        [27248]])\n",
            "tensor([[-27.8450, -28.1706, -28.5337,  ..., -24.1765, -24.7184, -26.8569],\n",
            "        [-16.4091, -18.1137, -19.0163,  ..., -18.4544, -15.9758, -16.5541],\n",
            "        [-19.3119, -21.0730, -19.4819,  ..., -21.5732, -19.1841, -17.6226],\n",
            "        ...,\n",
            "        [-20.9274, -22.1690, -17.2359,  ..., -20.9884, -19.8423, -20.2027],\n",
            "        [-26.4856, -27.9498, -27.4104,  ..., -28.0091, -26.3534, -25.3938],\n",
            "        [-22.1952, -23.8085, -20.2675,  ..., -20.3626, -21.5625, -18.7917]]) tensor([[29598],\n",
            "        [35104],\n",
            "        [ 5418],\n",
            "        [ 7297],\n",
            "        [30768],\n",
            "        [29598],\n",
            "        [ 7828],\n",
            "        [ 6777],\n",
            "        [  426],\n",
            "        [12591],\n",
            "        [30486],\n",
            "        [32391],\n",
            "        [ 8653],\n",
            "        [15880],\n",
            "        [22345],\n",
            "        [15880]])\n",
            "tensor([[-19.6874, -22.2708, -21.0899,  ..., -23.2033, -22.8496, -21.5408],\n",
            "        [-30.1845, -31.3756, -34.6307,  ..., -33.5320, -28.9353, -32.7674],\n",
            "        [-20.6791, -26.8291, -22.6132,  ..., -26.7486, -23.5761, -21.7848],\n",
            "        ...,\n",
            "        [-19.1450, -18.7401, -19.0871,  ..., -20.7107, -16.4619, -17.9079],\n",
            "        [-16.6588, -14.3007, -14.1102,  ..., -15.9366, -14.6924, -13.2720],\n",
            "        [-18.7082, -20.4518, -18.0187,  ..., -21.3006, -17.0521, -17.2312]]) tensor([[36160],\n",
            "        [ 2606],\n",
            "        [34907],\n",
            "        [18737],\n",
            "        [ 9508],\n",
            "        [ 1276],\n",
            "        [ 8176],\n",
            "        [ 2993],\n",
            "        [22543],\n",
            "        [ 2683],\n",
            "        [ 4311],\n",
            "        [ 4160],\n",
            "        [20563],\n",
            "        [ 1738],\n",
            "        [  887],\n",
            "        [ 2068]])\n",
            "tensor([[-15.9852, -19.2605, -17.0371,  ..., -20.1738, -17.4464, -16.8046],\n",
            "        [-17.3034, -16.6987, -17.8067,  ..., -18.4505, -17.6944, -18.0933],\n",
            "        [-15.0036, -15.6853, -15.4163,  ..., -15.0486, -15.5223, -15.1446],\n",
            "        ...,\n",
            "        [-22.9347, -22.2427, -22.5625,  ..., -21.5248, -20.5458, -19.5319],\n",
            "        [-15.9644, -19.3912, -16.8211,  ..., -19.3945, -17.0192, -17.5780],\n",
            "        [-21.0215, -21.3239, -19.6939,  ..., -21.1918, -21.0124, -20.4979]]) tensor([[15272],\n",
            "        [ 4160],\n",
            "        [14529],\n",
            "        [23949],\n",
            "        [29167],\n",
            "        [ 7297],\n",
            "        [26600],\n",
            "        [18170],\n",
            "        [17842],\n",
            "        [35308],\n",
            "        [33057],\n",
            "        [ 9471],\n",
            "        [20570],\n",
            "        [20563],\n",
            "        [ 2255],\n",
            "        [12049]])\n",
            "tensor([[-16.0408, -20.1302, -19.9019,  ..., -21.5813, -18.5968, -19.0161],\n",
            "        [-24.0198, -23.9728, -20.6549,  ..., -27.7897, -23.8636, -21.6791],\n",
            "        [-25.2429, -26.0383, -24.1659,  ..., -28.3845, -24.3769, -23.5091],\n",
            "        ...,\n",
            "        [-28.4455, -30.3392, -29.3074,  ..., -26.5000, -26.0336, -26.2151],\n",
            "        [-18.6919, -18.4783, -19.7099,  ..., -17.5303, -19.0079, -16.4518],\n",
            "        [-19.5351, -20.2369, -17.9680,  ..., -21.7854, -17.9435, -19.3298]]) tensor([[14641],\n",
            "        [17832],\n",
            "        [ 2879],\n",
            "        [16442],\n",
            "        [14217],\n",
            "        [ 8641],\n",
            "        [29580],\n",
            "        [ 2255],\n",
            "        [ 5019],\n",
            "        [26905],\n",
            "        [19917],\n",
            "        [36786],\n",
            "        [ 5813],\n",
            "        [24187],\n",
            "        [32398],\n",
            "        [36726]])\n",
            "tensor([[-23.1240, -22.0689, -21.3632,  ..., -23.4505, -22.3353, -19.8145],\n",
            "        [-16.6916, -17.5093, -17.5894,  ..., -17.0886, -16.5429, -16.3661],\n",
            "        [-19.1097, -19.7872, -15.2844,  ..., -19.0159, -17.8507, -16.7025],\n",
            "        ...,\n",
            "        [-26.3262, -26.1813, -24.3469,  ..., -24.5006, -22.4142, -21.8190],\n",
            "        [-26.6888, -22.8807, -24.4928,  ..., -28.0137, -26.5095, -27.2731],\n",
            "        [-22.4183, -22.8453, -19.5145,  ..., -23.6128, -22.4439, -23.4864]]) tensor([[ 1887],\n",
            "        [23473],\n",
            "        [33897],\n",
            "        [11902],\n",
            "        [29580],\n",
            "        [23300],\n",
            "        [ 5708],\n",
            "        [ 1887],\n",
            "        [23255],\n",
            "        [36281],\n",
            "        [33316],\n",
            "        [22940],\n",
            "        [34465],\n",
            "        [23655],\n",
            "        [13783],\n",
            "        [20667]])\n",
            "tensor([[-24.1112, -26.6962, -24.2816,  ..., -27.6464, -24.0610, -21.9793],\n",
            "        [-25.2222, -25.7185, -22.5046,  ..., -24.4173, -22.2533, -21.1868],\n",
            "        [-27.4132, -26.9899, -26.6011,  ..., -27.7737, -28.8029, -27.2652],\n",
            "        ...,\n",
            "        [-19.3489, -22.8974, -20.7163,  ..., -24.5853, -21.5566, -21.5795],\n",
            "        [-19.2728, -19.4883, -21.4221,  ..., -22.8682, -18.7753, -20.3025],\n",
            "        [-16.6066, -19.1597, -17.3242,  ..., -19.6441, -18.5487, -17.4338]]) tensor([[24174],\n",
            "        [22944],\n",
            "        [22517],\n",
            "        [ 1276],\n",
            "        [34956],\n",
            "        [11902],\n",
            "        [19674],\n",
            "        [20557],\n",
            "        [33316],\n",
            "        [22940],\n",
            "        [23300],\n",
            "        [28485],\n",
            "        [24971],\n",
            "        [33305],\n",
            "        [26571],\n",
            "        [24536]])\n",
            "tensor([[-20.6242, -20.7552, -23.1402,  ..., -20.8779, -19.7525, -19.9338],\n",
            "        [-20.8888, -23.6089, -21.3351,  ..., -23.0198, -19.4977, -22.2620],\n",
            "        [-26.5640, -30.3149, -26.2093,  ..., -28.9510, -27.4149, -27.1440],\n",
            "        ...,\n",
            "        [-21.3363, -21.1124, -20.2950,  ..., -19.6629, -20.2889, -19.1703],\n",
            "        [-24.3450, -24.7240, -22.9902,  ..., -25.2688, -23.0672, -24.7930],\n",
            "        [-19.8562, -20.6678, -19.4652,  ..., -20.9316, -18.3800, -20.2043]]) tensor([[26014],\n",
            "        [32940],\n",
            "        [11902],\n",
            "        [ 3028],\n",
            "        [28146],\n",
            "        [24526],\n",
            "        [29580],\n",
            "        [ 6013],\n",
            "        [ 2255],\n",
            "        [18487],\n",
            "        [34956],\n",
            "        [20182],\n",
            "        [ 9803],\n",
            "        [18092],\n",
            "        [13822],\n",
            "        [32146]])\n",
            "tensor([[-17.0630, -19.7874, -17.7904,  ..., -21.3872, -20.0030, -18.7767],\n",
            "        [-22.5968, -20.1396, -21.7834,  ..., -22.1485, -22.9246, -19.9306],\n",
            "        [-27.4920, -26.8015, -25.3266,  ..., -27.7941, -26.0496, -25.7402],\n",
            "        ...,\n",
            "        [-22.8906, -25.1219, -25.4375,  ..., -25.5924, -22.3457, -20.9342],\n",
            "        [-18.4513, -18.5904, -18.4698,  ..., -19.9763, -21.3699, -19.9629],\n",
            "        [-20.5406, -21.7467, -21.2556,  ..., -19.9010, -19.6172, -21.3193]]) tensor([[ 9661],\n",
            "        [31128],\n",
            "        [11421],\n",
            "        [17413],\n",
            "        [13759],\n",
            "        [23086],\n",
            "        [ 8940],\n",
            "        [ 7969],\n",
            "        [17413],\n",
            "        [26571],\n",
            "        [32902],\n",
            "        [  565],\n",
            "        [19309],\n",
            "        [22944],\n",
            "        [11312],\n",
            "        [ 7127]])\n",
            "tensor([[-18.4589, -17.5187, -20.8924,  ..., -18.6226, -20.0793, -18.6135],\n",
            "        [-19.8535, -22.7053, -17.8654,  ..., -20.8114, -19.7232, -18.7278],\n",
            "        [-22.1034, -21.2321, -21.2371,  ..., -21.6569, -20.3856, -22.6070],\n",
            "        ...,\n",
            "        [-18.8998, -19.0900, -17.1255,  ..., -20.4842, -16.9120, -16.4949],\n",
            "        [-25.3514, -23.5114, -20.4306,  ..., -23.7325, -22.1328, -24.6228],\n",
            "        [-19.8525, -18.9494, -21.2991,  ..., -22.5399, -19.2715, -17.5786]]) tensor([[  801],\n",
            "        [ 9203],\n",
            "        [11902],\n",
            "        [23300],\n",
            "        [ 6348],\n",
            "        [19432],\n",
            "        [10251],\n",
            "        [21786],\n",
            "        [22509],\n",
            "        [24744],\n",
            "        [32632],\n",
            "        [31128],\n",
            "        [11902],\n",
            "        [22940],\n",
            "        [29580],\n",
            "        [16525]])\n",
            "tensor([[-22.9324, -25.1829, -22.5519,  ..., -24.1345, -21.1257, -24.0522],\n",
            "        [-23.6095, -22.5098, -23.2082,  ..., -26.0790, -22.8313, -21.7648],\n",
            "        [-19.7949, -19.5068, -20.5862,  ..., -21.3037, -19.6753, -18.4181],\n",
            "        ...,\n",
            "        [-21.4305, -22.8688, -22.8016,  ..., -21.3677, -20.7705, -20.5930],\n",
            "        [-23.1215, -23.8992, -24.2445,  ..., -24.7033, -22.0644, -24.0013],\n",
            "        [-18.5478, -19.2387, -18.7997,  ..., -22.5078, -19.4413, -18.6120]]) tensor([[35161],\n",
            "        [  736],\n",
            "        [11263],\n",
            "        [10814],\n",
            "        [22940],\n",
            "        [ 7290],\n",
            "        [14809],\n",
            "        [ 9917],\n",
            "        [36281],\n",
            "        [21214],\n",
            "        [ 1138],\n",
            "        [20324],\n",
            "        [ 2410],\n",
            "        [18357],\n",
            "        [22246],\n",
            "        [ 7893]])\n",
            "tensor([[-20.8791, -21.5554, -19.2852,  ..., -24.7012, -19.6947, -18.5660],\n",
            "        [-19.7513, -21.4356, -17.3924,  ..., -23.8259, -19.5445, -19.5053],\n",
            "        [-22.9107, -20.8368, -18.0960,  ..., -25.1662, -21.4876, -18.2162],\n",
            "        ...,\n",
            "        [-33.4984, -35.2297, -32.9549,  ..., -35.2707, -31.3818, -34.0873],\n",
            "        [-23.6316, -20.8843, -20.9255,  ..., -23.1108, -22.1016, -19.1129],\n",
            "        [-16.8606, -19.4976, -17.4753,  ..., -18.2868, -17.2376, -18.5273]]) tensor([[33305],\n",
            "        [15186],\n",
            "        [16525],\n",
            "        [  602],\n",
            "        [23735],\n",
            "        [34010],\n",
            "        [11443],\n",
            "        [34465],\n",
            "        [ 4559],\n",
            "        [14217],\n",
            "        [33726],\n",
            "        [10500],\n",
            "        [23300],\n",
            "        [11902],\n",
            "        [21214],\n",
            "        [18258]])\n",
            "tensor([[-20.3449, -23.7030, -20.7572,  ..., -20.6548, -19.5886, -18.9019],\n",
            "        [-29.5805, -26.2948, -26.9715,  ..., -25.0901, -28.5103, -25.5868],\n",
            "        [-21.1262, -24.1581, -20.8456,  ..., -20.0174, -20.0458, -21.1119],\n",
            "        ...,\n",
            "        [-21.0045, -19.5953, -21.5855,  ..., -19.1539, -19.2637, -18.7759],\n",
            "        [-16.5837, -18.8665, -18.9935,  ..., -20.2625, -16.5815, -18.2680],\n",
            "        [-17.1066, -20.4932, -18.9799,  ..., -22.7888, -17.5509, -19.5046]]) tensor([[15038],\n",
            "        [ 1887],\n",
            "        [15148],\n",
            "        [23061],\n",
            "        [29892],\n",
            "        [27515],\n",
            "        [17811],\n",
            "        [32626],\n",
            "        [18490],\n",
            "        [ 6800],\n",
            "        [19004],\n",
            "        [20756],\n",
            "        [ 2585],\n",
            "        [ 1276],\n",
            "        [12175],\n",
            "        [27515]])\n",
            "tensor([[-22.7696, -22.7215, -23.3908,  ..., -26.7421, -23.7577, -21.8061],\n",
            "        [-16.9778, -19.0044, -18.3585,  ..., -18.6452, -17.7507, -17.3072],\n",
            "        [-25.7723, -27.6839, -28.6857,  ..., -29.3306, -25.3370, -26.5013],\n",
            "        ...,\n",
            "        [-24.2298, -21.6107, -20.5156,  ..., -21.1055, -21.2680, -20.5153],\n",
            "        [-20.0124, -18.5764, -18.4343,  ..., -20.4316, -21.2780, -18.1951],\n",
            "        [-18.4782, -21.7348, -17.4643,  ..., -20.6132, -18.2444, -17.7006]]) tensor([[ 1276],\n",
            "        [32626],\n",
            "        [23565],\n",
            "        [32587],\n",
            "        [18242],\n",
            "        [15656],\n",
            "        [29580],\n",
            "        [14333],\n",
            "        [31017],\n",
            "        [23474],\n",
            "        [34818],\n",
            "        [24628],\n",
            "        [ 8463],\n",
            "        [21038],\n",
            "        [36658],\n",
            "        [ 3222]])\n",
            "tensor([[-23.9251, -26.4604, -23.3999,  ..., -24.7806, -23.2580, -25.5580],\n",
            "        [-23.0141, -21.2463, -25.0389,  ..., -22.0174, -21.9882, -21.5739],\n",
            "        [-24.6321, -23.1983, -21.6248,  ..., -25.0260, -22.2561, -23.5498],\n",
            "        ...,\n",
            "        [-18.0601, -21.8230, -20.9833,  ..., -22.7391, -22.1140, -20.5863],\n",
            "        [-27.2732, -26.3799, -27.2271,  ..., -27.6536, -29.7110, -27.6801],\n",
            "        [-20.0072, -20.3768, -19.4939,  ..., -22.4090, -18.1519, -19.9816]]) tensor([[23061],\n",
            "        [14453],\n",
            "        [36599],\n",
            "        [21993],\n",
            "        [10365],\n",
            "        [ 2368],\n",
            "        [21801],\n",
            "        [17063],\n",
            "        [36658],\n",
            "        [29580],\n",
            "        [12175],\n",
            "        [ 2255],\n",
            "        [ 2368],\n",
            "        [23546],\n",
            "        [17334],\n",
            "        [12633]])\n",
            "tensor([[-25.4748, -26.5427, -27.1780,  ..., -27.1525, -24.6817, -26.0444],\n",
            "        [-30.8935, -31.4276, -27.4755,  ..., -28.2645, -26.8714, -25.9131],\n",
            "        [-23.7893, -24.2808, -22.2462,  ..., -23.5575, -22.7000, -24.4836],\n",
            "        ...,\n",
            "        [-17.4253, -17.4078, -18.3645,  ..., -19.4717, -17.3446, -16.5510],\n",
            "        [-22.6985, -21.0865, -20.3655,  ..., -22.4809, -21.6454, -19.2285],\n",
            "        [-38.2918, -35.1193, -35.5299,  ..., -38.1122, -36.0024, -36.3661]]) tensor([[23546],\n",
            "        [26257],\n",
            "        [31495],\n",
            "        [10365],\n",
            "        [ 2368],\n",
            "        [12633],\n",
            "        [ 2255],\n",
            "        [16350],\n",
            "        [21238],\n",
            "        [13254],\n",
            "        [30111],\n",
            "        [35967],\n",
            "        [ 2368],\n",
            "        [14333],\n",
            "        [ 9803],\n",
            "        [32845]])\n",
            "tensor([[-14.7386, -15.0736, -15.0146,  ..., -16.6425, -15.8967, -16.7214],\n",
            "        [-17.7323, -22.8240, -18.0374,  ..., -21.7799, -20.8932, -19.1332],\n",
            "        [-20.9177, -21.0294, -20.8130,  ..., -21.6591, -20.7735, -19.2337],\n",
            "        ...,\n",
            "        [-22.6313, -22.4904, -23.1743,  ..., -23.7440, -22.0802, -23.2385],\n",
            "        [-16.1056, -17.3802, -17.0232,  ..., -19.6471, -16.4019, -18.2811],\n",
            "        [-20.5504, -20.5832, -21.1320,  ..., -21.6218, -20.2498, -17.7065]]) tensor([[  736],\n",
            "        [18258],\n",
            "        [19761],\n",
            "        [31216],\n",
            "        [26257],\n",
            "        [ 9917],\n",
            "        [14809],\n",
            "        [14756],\n",
            "        [27494],\n",
            "        [18737],\n",
            "        [ 4001],\n",
            "        [35053],\n",
            "        [33722],\n",
            "        [ 5450],\n",
            "        [16350],\n",
            "        [17211]])\n",
            "tensor([[-25.6929, -24.8296, -24.0851,  ..., -27.7803, -26.7215, -24.8348],\n",
            "        [-18.8995, -19.3130, -19.4803,  ..., -18.6892, -20.5761, -18.2009],\n",
            "        [-23.1268, -21.2430, -21.2345,  ..., -21.9693, -23.3953, -23.1746],\n",
            "        ...,\n",
            "        [-17.5433, -18.5138, -18.9342,  ..., -17.9688, -18.7570, -18.2167],\n",
            "        [-22.2759, -21.9879, -21.1209,  ..., -20.0283, -20.1942, -21.9635],\n",
            "        [-19.5552, -19.5764, -18.0389,  ..., -20.7303, -17.8050, -16.7212]]) tensor([[12156],\n",
            "        [18670],\n",
            "        [23061],\n",
            "        [17583],\n",
            "        [36084],\n",
            "        [ 6177],\n",
            "        [32195],\n",
            "        [15656],\n",
            "        [14581],\n",
            "        [ 3384],\n",
            "        [ 5899],\n",
            "        [ 7019],\n",
            "        [12049],\n",
            "        [ 6792],\n",
            "        [28074],\n",
            "        [17464]])\n",
            "tensor([[-23.5783, -24.5795, -22.1713,  ..., -24.7341, -22.4569, -22.6995],\n",
            "        [-22.7189, -22.6925, -22.3919,  ..., -22.7991, -20.2191, -19.3080],\n",
            "        [-19.0421, -22.5470, -18.8510,  ..., -20.8280, -18.1219, -17.5245],\n",
            "        ...,\n",
            "        [-16.5642, -19.3203, -17.4873,  ..., -21.1524, -18.6860, -18.9868],\n",
            "        [-17.4047, -16.2119, -16.6686,  ..., -15.4285, -16.0508, -15.8008],\n",
            "        [-22.8359, -25.0045, -25.8811,  ..., -23.7894, -23.1120, -25.1506]]) tensor([[ 5086],\n",
            "        [28852],\n",
            "        [25231],\n",
            "        [28074],\n",
            "        [17811],\n",
            "        [30845],\n",
            "        [ 6448],\n",
            "        [11004],\n",
            "        [25032],\n",
            "        [33694],\n",
            "        [11443],\n",
            "        [ 1276],\n",
            "        [30845],\n",
            "        [28074],\n",
            "        [ 1887],\n",
            "        [ 2255]])\n",
            "tensor([[-19.9246, -20.8020, -20.0383,  ..., -21.3510, -19.5595, -17.5421],\n",
            "        [-17.4174, -21.7220, -18.0983,  ..., -20.8909, -18.1414, -18.2943],\n",
            "        [-28.8661, -28.4879, -30.6547,  ..., -30.5082, -28.2081, -29.4450],\n",
            "        ...,\n",
            "        [-22.9179, -21.8407, -22.9077,  ..., -23.9549, -22.4480, -19.4103],\n",
            "        [-20.0056, -20.7730, -18.4489,  ..., -19.7628, -17.7314, -16.9670],\n",
            "        [-21.4587, -24.7738, -21.3109,  ..., -22.8839, -21.3410, -22.2025]]) tensor([[34843],\n",
            "        [ 5772],\n",
            "        [ 5899],\n",
            "        [ 7019],\n",
            "        [12049],\n",
            "        [25780],\n",
            "        [17211],\n",
            "        [ 1887],\n",
            "        [14363],\n",
            "        [28074],\n",
            "        [16544],\n",
            "        [14756],\n",
            "        [17583],\n",
            "        [25000],\n",
            "        [25276],\n",
            "        [ 5899]])\n",
            "tensor([[-21.1688, -22.7764, -21.1513,  ..., -21.8768, -21.2783, -20.8937],\n",
            "        [-26.0940, -23.2373, -20.2839,  ..., -22.1375, -22.0869, -20.4903],\n",
            "        [-17.1453, -19.5535, -20.0168,  ..., -20.7397, -20.0200, -20.3709],\n",
            "        ...,\n",
            "        [-17.7235, -20.3402, -20.1919,  ..., -21.2882, -19.7239, -21.4226],\n",
            "        [-20.5940, -19.6782, -21.4763,  ..., -22.9242, -20.6656, -19.6137],\n",
            "        [-32.0151, -30.6039, -29.5736,  ..., -28.4335, -27.4857, -27.3002]]) tensor([[ 7019],\n",
            "        [27367],\n",
            "        [14304],\n",
            "        [ 1788],\n",
            "        [32940],\n",
            "        [33893],\n",
            "        [30264],\n",
            "        [12049],\n",
            "        [31017],\n",
            "        [16761],\n",
            "        [ 2255],\n",
            "        [12049],\n",
            "        [29892],\n",
            "        [ 6072],\n",
            "        [18783],\n",
            "        [14807]])\n",
            "tensor([[-18.5119, -18.8648, -17.3103,  ..., -19.9222, -18.0886, -19.2656],\n",
            "        [-18.2012, -20.4249, -19.2030,  ..., -20.2808, -19.5266, -18.2895],\n",
            "        [-21.3286, -20.0614, -20.6936,  ..., -22.3063, -20.0864, -19.9310],\n",
            "        ...,\n",
            "        [-15.5006, -19.3446, -18.6159,  ..., -20.7492, -17.1421, -19.4745],\n",
            "        [-24.9339, -24.2896, -24.9158,  ..., -24.0534, -22.8758, -24.1916],\n",
            "        [-17.4087, -17.4204, -20.0699,  ..., -17.0797, -18.0625, -17.5971]]) tensor([[36732],\n",
            "        [ 5418],\n",
            "        [ 4005],\n",
            "        [14807],\n",
            "        [36732],\n",
            "        [ 9370],\n",
            "        [34843],\n",
            "        [ 6072],\n",
            "        [ 3516],\n",
            "        [28043],\n",
            "        [ 2628],\n",
            "        [24971],\n",
            "        [24971],\n",
            "        [14756],\n",
            "        [ 1887],\n",
            "        [14733]])\n",
            "tensor([[-20.7609, -19.6448, -19.5406,  ..., -22.4907, -19.6533, -18.2791],\n",
            "        [-22.0966, -20.2469, -18.2304,  ..., -22.3602, -18.9298, -17.8463],\n",
            "        [-22.9271, -26.2631, -22.5242,  ..., -25.1749, -24.1213, -24.6897],\n",
            "        ...,\n",
            "        [-34.7533, -37.0693, -35.7952,  ..., -36.0884, -33.6837, -36.5270],\n",
            "        [-20.9527, -23.3757, -21.9187,  ..., -22.1332, -19.4980, -21.8853],\n",
            "        [-23.8808, -23.3978, -19.9241,  ..., -23.7654, -21.8408, -25.8590]]) tensor([[29437],\n",
            "        [12700],\n",
            "        [22492],\n",
            "        [17480],\n",
            "        [ 7721],\n",
            "        [22492],\n",
            "        [24491],\n",
            "        [17480],\n",
            "        [29613],\n",
            "        [31621],\n",
            "        [31495],\n",
            "        [18170],\n",
            "        [36281],\n",
            "        [21214],\n",
            "        [11263],\n",
            "        [33274]])\n",
            "tensor([[-23.3518, -22.5673, -20.9891,  ..., -26.4600, -20.5708, -20.9383],\n",
            "        [-19.9212, -19.6517, -17.8941,  ..., -20.3932, -19.2052, -21.5161],\n",
            "        [-22.9782, -28.6883, -23.2913,  ..., -29.3059, -24.5216, -25.5446],\n",
            "        ...,\n",
            "        [-21.3597, -23.5700, -23.6200,  ..., -22.6936, -19.0909, -23.3742],\n",
            "        [-20.9721, -20.2702, -19.8978,  ..., -21.0485, -22.8366, -21.4265],\n",
            "        [-17.2111, -17.1459, -17.2464,  ..., -18.5740, -17.4625, -16.7898]]) tensor([[18797],\n",
            "        [ 7702],\n",
            "        [10365],\n",
            "        [ 2368],\n",
            "        [13254],\n",
            "        [ 2255],\n",
            "        [ 2368],\n",
            "        [11902],\n",
            "        [11676],\n",
            "        [25854],\n",
            "        [35180],\n",
            "        [25141],\n",
            "        [23546],\n",
            "        [23949],\n",
            "        [ 7721],\n",
            "        [31352]])\n",
            "tensor([[-16.7289, -17.2211, -18.9048,  ..., -17.9478, -16.3588, -15.9565],\n",
            "        [-25.3969, -25.2310, -24.5166,  ..., -24.6966, -23.0600, -25.9236],\n",
            "        [-27.4742, -25.7652, -26.1120,  ..., -26.8176, -25.4662, -24.1767],\n",
            "        ...,\n",
            "        [-26.7858, -23.0046, -22.3304,  ..., -27.3503, -24.4277, -24.7378],\n",
            "        [-21.9116, -20.1652, -18.4770,  ..., -20.6098, -19.6348, -19.8125],\n",
            "        [-30.2288, -32.1298, -30.5593,  ..., -33.5698, -28.5136, -29.6596]]) tensor([[23300],\n",
            "        [33828],\n",
            "        [11902],\n",
            "        [ 5782],\n",
            "        [ 9917],\n",
            "        [14809],\n",
            "        [24323],\n",
            "        [36732],\n",
            "        [21230],\n",
            "        [26845],\n",
            "        [14809],\n",
            "        [14108],\n",
            "        [32587],\n",
            "        [ 6822],\n",
            "        [24861],\n",
            "        [36281]])\n",
            "tensor([[-30.0639, -31.5532, -29.9552,  ..., -33.3989, -29.4684, -29.4407],\n",
            "        [-19.2304, -22.3438, -17.5508,  ..., -20.8045, -18.7003, -19.2102],\n",
            "        [-23.2140, -22.4860, -21.2925,  ..., -23.9430, -25.1908, -22.6232],\n",
            "        ...,\n",
            "        [-14.3108, -17.0056, -17.6209,  ..., -17.7836, -14.8741, -16.3608],\n",
            "        [-19.8408, -23.1321, -20.1690,  ..., -22.1050, -18.6127, -22.6855],\n",
            "        [-25.0690, -26.7949, -26.3300,  ..., -28.0992, -25.6431, -25.8318]]) tensor([[21214],\n",
            "        [31225],\n",
            "        [ 3638],\n",
            "        [31225],\n",
            "        [27652],\n",
            "        [ 3638],\n",
            "        [22789],\n",
            "        [31225],\n",
            "        [33828],\n",
            "        [ 9380],\n",
            "        [34010],\n",
            "        [19539],\n",
            "        [16486],\n",
            "        [25141],\n",
            "        [ 9803],\n",
            "        [25032]])\n",
            "tensor([[-30.3565, -29.6316, -30.1755,  ..., -29.5904, -30.4908, -30.3350],\n",
            "        [-19.7577, -21.9054, -21.3914,  ..., -22.3587, -20.9469, -22.1196],\n",
            "        [-24.6101, -23.1269, -23.2318,  ..., -24.6823, -21.5862, -18.8128],\n",
            "        ...,\n",
            "        [-16.7055, -18.5296, -16.9111,  ..., -18.9333, -17.1812, -16.2158],\n",
            "        [-27.1919, -32.1565, -27.8540,  ..., -29.4529, -26.8850, -25.3318],\n",
            "        [-23.1547, -24.6656, -24.8472,  ..., -25.2450, -24.9919, -25.3171]]) tensor([[12199],\n",
            "        [ 6438],\n",
            "        [14108],\n",
            "        [ 1488],\n",
            "        [26845],\n",
            "        [ 8175],\n",
            "        [ 6180],\n",
            "        [  504],\n",
            "        [ 2811],\n",
            "        [24923],\n",
            "        [13945],\n",
            "        [ 6448],\n",
            "        [ 6448],\n",
            "        [25854],\n",
            "        [10417],\n",
            "        [27248]])\n",
            "tensor([[-18.3649, -20.9983, -16.8472,  ..., -19.0617, -19.8988, -19.5942],\n",
            "        [-18.1826, -19.5021, -19.3536,  ..., -16.5972, -16.3051, -17.6647],\n",
            "        [-17.9882, -19.6742, -19.8049,  ..., -20.7960, -20.3467, -19.4278],\n",
            "        ...,\n",
            "        [-20.7946, -22.1854, -19.2212,  ..., -22.0641, -21.7341, -19.4269],\n",
            "        [-21.3406, -23.5415, -21.4778,  ..., -22.1229, -20.5909, -19.9636],\n",
            "        [-22.7388, -20.9857, -20.6721,  ..., -21.4143, -20.6792, -18.1692]]) tensor([[27690],\n",
            "        [11902],\n",
            "        [32229],\n",
            "        [30760],\n",
            "        [24323],\n",
            "        [ 6822],\n",
            "        [14108],\n",
            "        [29875],\n",
            "        [26845],\n",
            "        [12199],\n",
            "        [ 6438],\n",
            "        [32762],\n",
            "        [33519],\n",
            "        [34125],\n",
            "        [ 2186],\n",
            "        [21631]])\n",
            "tensor([[-20.8815, -23.6892, -20.9416,  ..., -23.2533, -21.6446, -20.0298],\n",
            "        [-25.8782, -27.2023, -24.3474,  ..., -27.9269, -25.9249, -23.7998],\n",
            "        [-20.1676, -23.1558, -22.5540,  ..., -22.0363, -22.6981, -22.8776],\n",
            "        ...,\n",
            "        [-18.7639, -20.3001, -18.9751,  ..., -20.0184, -17.6336, -20.6666],\n",
            "        [-19.0834, -19.4643, -18.7624,  ..., -20.6356, -18.6557, -18.3446],\n",
            "        [-19.1559, -19.4679, -20.8049,  ..., -19.2644, -17.5647, -19.9873]]) tensor([[ 4583],\n",
            "        [30946],\n",
            "        [13304],\n",
            "        [16897],\n",
            "        [34907],\n",
            "        [31256],\n",
            "        [32706],\n",
            "        [24491],\n",
            "        [ 4931],\n",
            "        [32940],\n",
            "        [ 5603],\n",
            "        [32940],\n",
            "        [ 6822],\n",
            "        [27339],\n",
            "        [11855],\n",
            "        [18170]])\n",
            "tensor([[-26.2545, -26.4394, -24.9352,  ..., -26.6192, -26.0959, -27.3135],\n",
            "        [-24.5178, -27.2106, -27.0234,  ..., -31.4037, -24.7710, -28.3933],\n",
            "        [-31.0575, -34.0143, -35.8964,  ..., -31.8671, -30.4463, -32.5986],\n",
            "        ...,\n",
            "        [-24.6396, -25.4359, -22.6551,  ..., -24.0704, -24.0273, -24.4496],\n",
            "        [-22.3915, -22.8601, -24.3224,  ..., -24.0246, -23.0936, -22.5057],\n",
            "        [-17.5475, -20.5284, -17.4397,  ..., -19.6689, -18.9441, -19.0426]]) tensor([[17211],\n",
            "        [36281],\n",
            "        [21214],\n",
            "        [ 9902],\n",
            "        [23271],\n",
            "        [26253],\n",
            "        [17211],\n",
            "        [36281],\n",
            "        [21214],\n",
            "        [ 1433],\n",
            "        [12309],\n",
            "        [ 2691],\n",
            "        [34848],\n",
            "        [20951],\n",
            "        [11676],\n",
            "        [22816]])\n",
            "tensor([[-28.2694, -27.8424, -26.8190,  ..., -29.6653, -26.6116, -22.7777],\n",
            "        [-19.9317, -22.4261, -17.4075,  ..., -19.0884, -19.7989, -18.4173],\n",
            "        [-19.8409, -21.1795, -19.9983,  ..., -22.3340, -21.8439, -20.5232],\n",
            "        ...,\n",
            "        [-21.6873, -23.3689, -21.2318,  ..., -19.9353, -19.9477, -19.9951],\n",
            "        [-26.5060, -27.5546, -25.1214,  ..., -26.3053, -25.1061, -26.9311],\n",
            "        [-20.9250, -19.3613, -20.5558,  ..., -19.2878, -19.3772, -19.2874]]) tensor([[31017],\n",
            "        [32626],\n",
            "        [29892],\n",
            "        [25141],\n",
            "        [ 9803],\n",
            "        [25032],\n",
            "        [31375],\n",
            "        [13753],\n",
            "        [25032],\n",
            "        [28160],\n",
            "        [ 6800],\n",
            "        [11676],\n",
            "        [36708],\n",
            "        [24762],\n",
            "        [ 8276],\n",
            "        [16062]])\n",
            "tensor([[-23.6704, -28.2457, -22.1972,  ..., -25.1726, -22.5997, -26.3316],\n",
            "        [-22.0184, -24.8064, -21.9425,  ..., -24.7684, -23.3912, -23.1853],\n",
            "        [-23.9496, -21.8765, -21.6130,  ..., -21.3197, -22.4020, -21.7139],\n",
            "        ...,\n",
            "        [-17.5749, -19.0168, -16.9732,  ..., -21.9364, -18.8516, -18.7208],\n",
            "        [-15.3684, -16.9511, -14.3042,  ..., -17.2255, -16.2240, -17.3964],\n",
            "        [-18.2501, -20.8407, -20.8166,  ..., -17.8827, -18.2423, -18.5013]]) tensor([[ 4540],\n",
            "        [ 8276],\n",
            "        [24187],\n",
            "        [22944],\n",
            "        [22944],\n",
            "        [ 6822],\n",
            "        [33694],\n",
            "        [35040],\n",
            "        [24594],\n",
            "        [10461],\n",
            "        [25032],\n",
            "        [26196],\n",
            "        [ 6924],\n",
            "        [10461],\n",
            "        [15103],\n",
            "        [22944]])\n",
            "tensor([[-20.8554, -22.2987, -22.0916,  ..., -20.9695, -23.3588, -21.8953],\n",
            "        [-17.5389, -22.0099, -19.9966,  ..., -23.2082, -19.8057, -18.9742],\n",
            "        [-29.8763, -31.0927, -28.2026,  ..., -32.0150, -25.6255, -29.5434],\n",
            "        ...,\n",
            "        [-18.6714, -16.2718, -16.4405,  ..., -17.5176, -18.2402, -16.2829],\n",
            "        [-20.2568, -21.0139, -19.4126,  ..., -22.8234, -20.1375, -22.3995],\n",
            "        [-20.9675, -20.8556, -21.7289,  ..., -23.8901, -21.4809, -20.0772]]) tensor([[17811],\n",
            "        [ 6822],\n",
            "        [ 7381],\n",
            "        [ 6871],\n",
            "        [ 3638],\n",
            "        [31225],\n",
            "        [25254],\n",
            "        [22944],\n",
            "        [ 6822],\n",
            "        [  801],\n",
            "        [ 7702],\n",
            "        [ 7702],\n",
            "        [30007],\n",
            "        [ 3669],\n",
            "        [  736],\n",
            "        [29580]])\n",
            "tensor([[-20.7923, -21.0635, -23.0067,  ..., -24.8998, -19.7783, -22.0058],\n",
            "        [-18.7182, -17.2233, -17.3215,  ..., -18.6321, -19.2139, -17.5414],\n",
            "        [-18.4942, -19.1841, -18.3081,  ..., -19.8570, -19.7861, -19.8533],\n",
            "        ...,\n",
            "        [-20.5633, -22.0814, -22.1568,  ..., -21.1738, -19.5431, -21.9359],\n",
            "        [-22.1577, -21.2592, -21.3967,  ..., -25.6477, -22.1079, -21.4803],\n",
            "        [-22.1601, -22.1222, -23.1725,  ..., -25.7332, -21.6202, -22.3024]]) tensor([[ 2255],\n",
            "        [21063],\n",
            "        [10826],\n",
            "        [33726],\n",
            "        [ 3993],\n",
            "        [35083],\n",
            "        [32174],\n",
            "        [11760],\n",
            "        [29580],\n",
            "        [29074],\n",
            "        [24236],\n",
            "        [18170],\n",
            "        [15103],\n",
            "        [25241],\n",
            "        [15918],\n",
            "        [35918]])\n",
            "tensor([[-17.6992, -21.3145, -18.9825,  ..., -23.3592, -17.6992, -20.2493],\n",
            "        [-17.3996, -21.3079, -18.3398,  ..., -20.2371, -17.4177, -17.8450],\n",
            "        [-18.5585, -21.7403, -20.3367,  ..., -22.5521, -17.5274, -17.3905],\n",
            "        ...,\n",
            "        [-19.1347, -21.3246, -21.8116,  ..., -23.0228, -20.9815, -18.0920],\n",
            "        [-27.3493, -27.8146, -26.4562,  ..., -30.5240, -26.3114, -28.9030],\n",
            "        [-21.1153, -19.9906, -22.1579,  ..., -23.3160, -20.1678, -21.9077]]) tensor([[24236],\n",
            "        [ 3668],\n",
            "        [ 2255],\n",
            "        [ 2255],\n",
            "        [19951],\n",
            "        [ 2368],\n",
            "        [ 2410],\n",
            "        [26397],\n",
            "        [17211],\n",
            "        [ 1887],\n",
            "        [35060],\n",
            "        [ 9124],\n",
            "        [11902],\n",
            "        [ 9007],\n",
            "        [19785],\n",
            "        [21298]])\n",
            "tensor([[-21.1337, -20.4789, -26.2287,  ..., -19.5689, -23.0196, -22.3806],\n",
            "        [-23.6704, -25.5293, -23.8045,  ..., -27.1327, -22.4282, -23.3997],\n",
            "        [-25.2739, -21.5917, -20.3046,  ..., -23.5669, -21.9821, -21.0904],\n",
            "        ...,\n",
            "        [-23.0832, -22.7385, -21.3533,  ..., -22.1002, -23.4796, -22.3482],\n",
            "        [-19.2515, -20.7349, -20.2699,  ..., -21.4185, -19.3096, -16.8522],\n",
            "        [-22.6531, -22.2520, -20.4494,  ..., -22.4947, -20.1984, -19.7373]]) tensor([[ 6836],\n",
            "        [15176],\n",
            "        [ 1887],\n",
            "        [ 9124],\n",
            "        [ 5703],\n",
            "        [36117],\n",
            "        [23546],\n",
            "        [12370],\n",
            "        [29161],\n",
            "        [18666],\n",
            "        [25076],\n",
            "        [ 8940],\n",
            "        [ 2255],\n",
            "        [ 5639],\n",
            "        [ 7061],\n",
            "        [ 3669]])\n",
            "tensor([[-23.6859, -20.1711, -21.0459,  ..., -22.6386, -22.9324, -20.4338],\n",
            "        [-20.7604, -21.8139, -18.9280,  ..., -22.0960, -20.3758, -20.4800],\n",
            "        [-23.9333, -24.0762, -24.3572,  ..., -25.6852, -23.2616, -25.5754],\n",
            "        ...,\n",
            "        [-25.0461, -26.8996, -23.5635,  ..., -26.3090, -25.5636, -23.0146],\n",
            "        [-24.0270, -25.8438, -24.6451,  ..., -25.5699, -23.6716, -23.2544],\n",
            "        [-22.9700, -20.4304, -21.0292,  ..., -22.7402, -22.5648, -19.5022]]) tensor([[21904],\n",
            "        [ 8641],\n",
            "        [23970],\n",
            "        [13193],\n",
            "        [26397],\n",
            "        [ 3539],\n",
            "        [ 1887],\n",
            "        [30264],\n",
            "        [ 8940],\n",
            "        [ 2255],\n",
            "        [15383],\n",
            "        [34101],\n",
            "        [32354],\n",
            "        [13635],\n",
            "        [27215],\n",
            "        [15341]])\n",
            "tensor([[-23.1684, -24.3548, -23.1004,  ..., -23.5709, -23.3604, -25.3111],\n",
            "        [-18.8881, -20.4696, -17.2131,  ..., -18.1682, -18.2902, -18.2646],\n",
            "        [-29.2494, -30.7822, -30.1874,  ..., -33.3689, -29.1888, -27.6883],\n",
            "        ...,\n",
            "        [-16.1058, -18.9238, -18.2729,  ..., -21.8515, -19.5417, -21.7717],\n",
            "        [-22.1947, -25.1531, -22.6518,  ..., -27.0773, -19.2557, -21.2636],\n",
            "        [-19.4276, -15.8711, -16.9985,  ..., -17.9466, -18.3000, -15.1110]]) tensor([[21993],\n",
            "        [  957],\n",
            "        [15383],\n",
            "        [22257],\n",
            "        [34721],\n",
            "        [30534],\n",
            "        [21993],\n",
            "        [22168],\n",
            "        [32885],\n",
            "        [21089],\n",
            "        [  887],\n",
            "        [ 2255],\n",
            "        [33127],\n",
            "        [31889],\n",
            "        [11902],\n",
            "        [ 5735]])\n",
            "tensor([[-25.5045, -22.4539, -19.9822,  ..., -23.5131, -20.6973, -23.3479],\n",
            "        [-26.9517, -26.7384, -27.0200,  ..., -27.8488, -25.5875, -25.5738],\n",
            "        [-19.9432, -18.7828, -15.6476,  ..., -20.4689, -18.7660, -17.8637],\n",
            "        ...,\n",
            "        [-23.1035, -21.6235, -22.1962,  ..., -24.8068, -21.8425, -21.2125],\n",
            "        [-20.9859, -20.6371, -19.6045,  ..., -19.4380, -20.9318, -19.2756],\n",
            "        [-22.6519, -22.0758, -21.6509,  ..., -25.4768, -22.0443, -22.8469]]) tensor([[ 9089],\n",
            "        [ 6893],\n",
            "        [  168],\n",
            "        [ 8176],\n",
            "        [27515],\n",
            "        [ 4703],\n",
            "        [34821],\n",
            "        [ 4703],\n",
            "        [ 6516],\n",
            "        [ 6086],\n",
            "        [21993],\n",
            "        [18771],\n",
            "        [15035],\n",
            "        [27515],\n",
            "        [31946],\n",
            "        [  736]])\n",
            "tensor([[-19.8427, -21.1753, -17.4527,  ..., -21.1099, -18.1662, -18.0942],\n",
            "        [-21.0164, -19.3361, -18.2544,  ..., -19.9438, -19.1844, -19.2538],\n",
            "        [-27.0744, -25.0653, -28.5167,  ..., -25.7307, -25.1670, -26.2201],\n",
            "        ...,\n",
            "        [-24.4635, -25.9612, -27.1782,  ..., -27.2417, -21.6297, -24.9682],\n",
            "        [-23.1780, -24.4341, -26.2522,  ..., -24.8777, -21.1095, -22.7384],\n",
            "        [-24.4537, -25.8987, -25.1843,  ..., -28.1072, -22.8915, -23.1026]]) tensor([[11676],\n",
            "        [ 9917],\n",
            "        [22789],\n",
            "        [34010],\n",
            "        [36732],\n",
            "        [30814],\n",
            "        [12222],\n",
            "        [29081],\n",
            "        [25854],\n",
            "        [21230],\n",
            "        [14707],\n",
            "        [22704],\n",
            "        [ 6871],\n",
            "        [ 9714],\n",
            "        [34010],\n",
            "        [11443]])\n",
            "tensor([[-18.7228, -22.8993, -21.1406,  ..., -22.1308, -17.4824, -18.8057],\n",
            "        [-19.4953, -18.1567, -16.9459,  ..., -17.7507, -17.7533, -16.5266],\n",
            "        [-18.7521, -16.4096, -14.7461,  ..., -17.4429, -17.8929, -17.9626],\n",
            "        ...,\n",
            "        [-27.2329, -28.3366, -27.8519,  ..., -28.6178, -25.2433, -25.7579],\n",
            "        [-21.4679, -18.5644, -21.6164,  ..., -22.6333, -21.7859, -19.9733],\n",
            "        [-26.6753, -29.4681, -26.2957,  ..., -30.6782, -26.1306, -28.3326]]) tensor([[28485],\n",
            "        [ 9440],\n",
            "        [17811],\n",
            "        [23061],\n",
            "        [18170],\n",
            "        [ 7545],\n",
            "        [27928],\n",
            "        [ 1801],\n",
            "        [14108],\n",
            "        [ 2041],\n",
            "        [ 6566],\n",
            "        [33079],\n",
            "        [16442],\n",
            "        [11902],\n",
            "        [13971],\n",
            "        [ 9794]])\n",
            "tensor([[-24.2738, -23.3043, -21.7864,  ..., -22.2714, -23.6258, -22.9251],\n",
            "        [-23.9337, -24.4741, -25.2286,  ..., -26.9169, -24.0091, -25.4174],\n",
            "        [-27.2183, -28.4493, -28.0786,  ..., -26.6558, -27.5332, -28.3133],\n",
            "        ...,\n",
            "        [-22.2959, -22.2224, -21.2429,  ..., -24.1456, -19.9092, -21.4591],\n",
            "        [-23.7871, -23.7462, -20.8423,  ..., -22.6313, -19.6256, -21.1577],\n",
            "        [-18.6171, -18.9141, -17.9135,  ..., -21.3766, -17.9859, -19.3276]]) tensor([[ 6275],\n",
            "        [35967],\n",
            "        [35686],\n",
            "        [26397],\n",
            "        [ 9902],\n",
            "        [ 1738],\n",
            "        [17413],\n",
            "        [14535],\n",
            "        [36799],\n",
            "        [35031],\n",
            "        [ 2368],\n",
            "        [35104],\n",
            "        [31352],\n",
            "        [35031],\n",
            "        [ 4411],\n",
            "        [ 6275]])\n",
            "tensor([[-21.4883, -22.0407, -21.7715,  ..., -24.0467, -19.5080, -20.3758],\n",
            "        [-21.1670, -22.5133, -24.0410,  ..., -22.6805, -19.6973, -24.8145],\n",
            "        [-23.7975, -25.9730, -24.0651,  ..., -27.5116, -24.4379, -23.7393],\n",
            "        ...,\n",
            "        [-33.7860, -33.3262, -32.9293,  ..., -32.0084, -31.7842, -33.3123],\n",
            "        [-20.0701, -23.6960, -21.5920,  ..., -23.5481, -20.4321, -22.5292],\n",
            "        [-19.7415, -20.6493, -20.9525,  ..., -20.9575, -17.6606, -19.8907]]) tensor([[ 5972],\n",
            "        [ 5237],\n",
            "        [34616],\n",
            "        [12486],\n",
            "        [30729],\n",
            "        [ 9471],\n",
            "        [21737],\n",
            "        [23061],\n",
            "        [10860],\n",
            "        [13052],\n",
            "        [21561],\n",
            "        [35104],\n",
            "        [21628],\n",
            "        [ 1728],\n",
            "        [35104],\n",
            "        [ 2549]])\n",
            "tensor([[-18.8349, -22.7480, -20.5588,  ..., -21.4762, -21.1630, -22.2870],\n",
            "        [-17.5025, -21.5931, -20.9557,  ..., -20.6307, -19.3315, -16.1296],\n",
            "        [-22.1315, -20.1764, -18.3032,  ..., -18.3122, -21.4013, -19.8884],\n",
            "        ...,\n",
            "        [-30.3415, -33.7165, -32.1718,  ..., -34.1474, -32.6565, -31.0281],\n",
            "        [-19.5300, -19.8302, -20.0893,  ..., -21.8899, -21.2131, -21.2286],\n",
            "        [-17.8060, -16.6897, -18.4033,  ..., -18.2033, -18.4400, -17.9019]]) tensor([[16350],\n",
            "        [ 9440],\n",
            "        [  403],\n",
            "        [ 3088],\n",
            "        [17413],\n",
            "        [34010],\n",
            "        [ 6778],\n",
            "        [ 2255],\n",
            "        [21319],\n",
            "        [17583],\n",
            "        [21379],\n",
            "        [17211],\n",
            "        [ 6924],\n",
            "        [11112],\n",
            "        [12049],\n",
            "        [ 3996]])\n",
            "tensor([[-19.2209, -19.5053, -18.6433,  ..., -22.4121, -20.0750, -19.1304],\n",
            "        [-17.8104, -20.9056, -19.8240,  ..., -19.9718, -18.9375, -17.4017],\n",
            "        [-20.5001, -21.0696, -21.9478,  ..., -19.9958, -18.8435, -19.5772],\n",
            "        ...,\n",
            "        [-21.8434, -19.4126, -19.3343,  ..., -20.8382, -19.0891, -19.1538],\n",
            "        [-25.8034, -23.0088, -22.8778,  ..., -23.5068, -23.4364, -23.3695],\n",
            "        [-22.2134, -25.7258, -23.2682,  ..., -24.5054, -21.9380, -21.3973]]) tensor([[36097],\n",
            "        [13542],\n",
            "        [ 3827],\n",
            "        [19653],\n",
            "        [12049],\n",
            "        [27928],\n",
            "        [30593],\n",
            "        [11112],\n",
            "        [12049],\n",
            "        [26368],\n",
            "        [14813],\n",
            "        [18569],\n",
            "        [21298],\n",
            "        [ 9440],\n",
            "        [ 9665],\n",
            "        [26368]])\n",
            "tensor([[-16.8748, -20.0594, -20.5213,  ..., -18.9047, -19.4584, -18.1568],\n",
            "        [-29.9635, -27.4372, -28.7395,  ..., -29.8475, -27.0524, -28.0831],\n",
            "        [-16.6338, -17.8048, -16.3116,  ..., -17.2017, -15.1107, -13.3630],\n",
            "        ...,\n",
            "        [-19.1639, -22.5654, -18.4243,  ..., -21.5953, -19.2378, -17.7979],\n",
            "        [-23.8968, -22.9385, -21.8444,  ..., -23.4679, -20.2603, -21.5109],\n",
            "        [-22.4496, -23.3822, -20.5845,  ..., -24.6201, -21.6804, -22.3178]]) tensor([[ 2252],\n",
            "        [18170],\n",
            "        [11112],\n",
            "        [12049],\n",
            "        [24179],\n",
            "        [21089],\n",
            "        [  887],\n",
            "        [11786],\n",
            "        [29437],\n",
            "        [ 7499],\n",
            "        [34053],\n",
            "        [36529],\n",
            "        [14948],\n",
            "        [26143],\n",
            "        [24901],\n",
            "        [ 9227]])\n",
            "tensor([[-28.4621, -29.2242, -27.1512,  ..., -29.1727, -25.9535, -27.6973],\n",
            "        [-22.7924, -25.8521, -23.9026,  ..., -27.6002, -23.8822, -24.7038],\n",
            "        [-16.3877, -15.5192, -14.8908,  ..., -17.4335, -15.3253, -14.7298],\n",
            "        ...,\n",
            "        [-27.8716, -26.8717, -30.5587,  ..., -30.5364, -26.7333, -27.8202],\n",
            "        [-21.6350, -20.0997, -22.4149,  ..., -22.2336, -19.9333, -21.1399],\n",
            "        [-26.0713, -28.3032, -31.0816,  ..., -25.4762, -27.6875, -28.3209]]) tensor([[26096],\n",
            "        [30534],\n",
            "        [17809],\n",
            "        [ 9252],\n",
            "        [15272],\n",
            "        [17583],\n",
            "        [36084],\n",
            "        [ 9329],\n",
            "        [36084],\n",
            "        [27232],\n",
            "        [23144],\n",
            "        [24323],\n",
            "        [36732],\n",
            "        [15101],\n",
            "        [26095],\n",
            "        [ 5603]])\n",
            "tensor([[-20.3902, -22.4290, -22.6784,  ..., -23.1595, -20.4477, -22.2076],\n",
            "        [-21.7902, -23.2715, -19.0240,  ..., -23.6361, -21.3311, -19.4973],\n",
            "        [-16.1835, -19.6968, -16.9360,  ..., -18.0034, -16.9258, -17.8878],\n",
            "        ...,\n",
            "        [-21.9348, -24.3378, -24.5460,  ..., -25.7072, -19.1899, -22.0533],\n",
            "        [-16.7360, -16.3556, -15.9536,  ..., -16.3233, -16.2034, -13.8762],\n",
            "        [-26.3120, -28.6996, -23.7713,  ..., -30.2531, -25.7392, -26.8146]]) tensor([[35104],\n",
            "        [36117],\n",
            "        [ 8709],\n",
            "        [ 7499],\n",
            "        [ 5209],\n",
            "        [ 3353],\n",
            "        [ 2255],\n",
            "        [10125],\n",
            "        [24523],\n",
            "        [10444],\n",
            "        [17211],\n",
            "        [28427],\n",
            "        [12318],\n",
            "        [24567],\n",
            "        [ 1437],\n",
            "        [ 1103]])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-1356efff86eb>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# disable gradient computation, since it is only needed when backward() is called\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mbatch_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-e3a69391771e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifSSFzN2o9Sr",
        "outputId": "fe04cc99-067e-4290-8275-3a5cf2403d68"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(36872, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader(df, col, BATCH_SIZE=16):\n",
        "    \"\"\"wrapper function to create all the necessary data\"\"\"\n",
        "    data, word_to_ix, vocab = create_vocab_and_data(df, col, context_size=CONTEXT_SIZE)\n",
        "    # data = data[:100]\n",
        "    split_index= int(len(data)*0.9)\n",
        "    train_X, train_Y = data_to_tensor(data[:split_index], word_to_ix)\n",
        "    test_X, test_Y = data_to_tensor(data[split_index:], word_to_ix)\n",
        "    print(train_X.shape)\n",
        "    print(train_Y.shape)\n",
        "    train_set = MyDataset(train_X, train_Y)\n",
        "    test_set = MyDataset(test_X, test_Y)\n",
        "    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE)\n",
        "    test_loader = DataLoader(test_set, batch_size=BATCH_SIZE)\n",
        "    return train_loader, test_loader, vocab, word_to_ix"
      ],
      "metadata": {
        "id": "fKMe-VIUo9Tp"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainig_loop(model, train_loader, optimizer, loss_func, num_epochs, device):\n",
        "    \"\"\"wrapper function for training for better reusability\"\"\"\n",
        "    model.train()\n",
        "    num_batches = len(train_loader)\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "      for batch_num, (inputs, y_true) in enumerate(train_loader, 1):\n",
        "          optimizer.zero_grad()\n",
        "          #print(inputs.shape, y_true.shape, len(vocab), y_true.squeeze().shape)\n",
        "          y_pred = model(inputs)\n",
        "          loss = loss_func(y_pred, y_true.squeeze())\n",
        "          loss_batch = loss.item()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          print(f'Epoch [{epoch}/{num_epochs}], batch: [{batch_num}/{num_batches}, loss: {loss_batch:.4f}]')\n",
        "\n"
      ],
      "metadata": {
        "id": "74Z51LMB3Mg9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 Train CBOW2 with a context width of 2 (in both directions) for the Hotel Reviews dataset."
      ],
      "metadata": {
        "id": "5UEHh3zP9nUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONTEXT_SIZE = 2\n",
        "train_loader, test_loader, vocab, word_to_ix = create_dataloader(df, 'Review')"
      ],
      "metadata": {
        "id": "vHVDR0bq-Cqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77cadb42-1df8-4dd3-c0ff-8359cda9c6d2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([946944, 4])\n",
            "torch.Size([946944, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.5 Train CBOW5 with a context width of 5 (in both directions) for the Hotel Reviews dataset.  \n",
        "\n",
        "ðŸ—’â“ Are predictions made by the model sensitive towards the context size?"
      ],
      "metadata": {
        "id": "qn7teyu7987m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 50\n",
        "HIDDEN_DIM = 128\n",
        "model = CBOW(len(vocab), EMBEDDING_DIM, HIDDEN_DIM, CONTEXT_SIZE)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.95)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "num_epochs = 15\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "model.to(device)\n",
        "trainig_loop(model, train_loader, optimizer, loss_func, num_epochs, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSQ4Uvlr07Xc",
        "outputId": "2d5f4b79-f978-46d1-cf45-527a8e4cc4f2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch [15/15], batch: [54185/59184, loss: 5.7920]\n",
            "Epoch [15/15], batch: [54186/59184, loss: 5.0464]\n",
            "Epoch [15/15], batch: [54187/59184, loss: 6.2469]\n",
            "Epoch [15/15], batch: [54188/59184, loss: 4.6945]\n",
            "Epoch [15/15], batch: [54189/59184, loss: 6.6810]\n",
            "Epoch [15/15], batch: [54190/59184, loss: 6.1569]\n",
            "Epoch [15/15], batch: [54191/59184, loss: 7.2224]\n",
            "Epoch [15/15], batch: [54192/59184, loss: 6.6309]\n",
            "Epoch [15/15], batch: [54193/59184, loss: 4.9717]\n",
            "Epoch [15/15], batch: [54194/59184, loss: 5.4086]\n",
            "Epoch [15/15], batch: [54195/59184, loss: 3.6946]\n",
            "Epoch [15/15], batch: [54196/59184, loss: 4.2784]\n",
            "Epoch [15/15], batch: [54197/59184, loss: 4.6246]\n",
            "Epoch [15/15], batch: [54198/59184, loss: 4.7868]\n",
            "Epoch [15/15], batch: [54199/59184, loss: 3.4591]\n",
            "Epoch [15/15], batch: [54200/59184, loss: 5.6802]\n",
            "Epoch [15/15], batch: [54201/59184, loss: 5.7426]\n",
            "Epoch [15/15], batch: [54202/59184, loss: 5.9998]\n",
            "Epoch [15/15], batch: [54203/59184, loss: 5.3501]\n",
            "Epoch [15/15], batch: [54204/59184, loss: 6.1646]\n",
            "Epoch [15/15], batch: [54205/59184, loss: 5.1881]\n",
            "Epoch [15/15], batch: [54206/59184, loss: 5.7317]\n",
            "Epoch [15/15], batch: [54207/59184, loss: 3.9389]\n",
            "Epoch [15/15], batch: [54208/59184, loss: 6.2497]\n",
            "Epoch [15/15], batch: [54209/59184, loss: 4.9831]\n",
            "Epoch [15/15], batch: [54210/59184, loss: 6.2674]\n",
            "Epoch [15/15], batch: [54211/59184, loss: 6.3350]\n",
            "Epoch [15/15], batch: [54212/59184, loss: 4.9756]\n",
            "Epoch [15/15], batch: [54213/59184, loss: 5.4029]\n",
            "Epoch [15/15], batch: [54214/59184, loss: 2.5021]\n",
            "Epoch [15/15], batch: [54215/59184, loss: 6.7166]\n",
            "Epoch [15/15], batch: [54216/59184, loss: 5.5117]\n",
            "Epoch [15/15], batch: [54217/59184, loss: 5.6111]\n",
            "Epoch [15/15], batch: [54218/59184, loss: 5.3842]\n",
            "Epoch [15/15], batch: [54219/59184, loss: 5.6857]\n",
            "Epoch [15/15], batch: [54220/59184, loss: 4.9194]\n",
            "Epoch [15/15], batch: [54221/59184, loss: 5.2469]\n",
            "Epoch [15/15], batch: [54222/59184, loss: 6.4252]\n",
            "Epoch [15/15], batch: [54223/59184, loss: 6.9188]\n",
            "Epoch [15/15], batch: [54224/59184, loss: 6.2878]\n",
            "Epoch [15/15], batch: [54225/59184, loss: 5.6473]\n",
            "Epoch [15/15], batch: [54226/59184, loss: 5.4399]\n",
            "Epoch [15/15], batch: [54227/59184, loss: 6.7189]\n",
            "Epoch [15/15], batch: [54228/59184, loss: 6.5658]\n",
            "Epoch [15/15], batch: [54229/59184, loss: 6.7927]\n",
            "Epoch [15/15], batch: [54230/59184, loss: 5.5962]\n",
            "Epoch [15/15], batch: [54231/59184, loss: 5.2519]\n",
            "Epoch [15/15], batch: [54232/59184, loss: 5.8389]\n",
            "Epoch [15/15], batch: [54233/59184, loss: 6.2076]\n",
            "Epoch [15/15], batch: [54234/59184, loss: 5.8355]\n",
            "Epoch [15/15], batch: [54235/59184, loss: 4.1532]\n",
            "Epoch [15/15], batch: [54236/59184, loss: 4.7626]\n",
            "Epoch [15/15], batch: [54237/59184, loss: 4.1075]\n",
            "Epoch [15/15], batch: [54238/59184, loss: 3.9351]\n",
            "Epoch [15/15], batch: [54239/59184, loss: 5.6432]\n",
            "Epoch [15/15], batch: [54240/59184, loss: 5.5256]\n",
            "Epoch [15/15], batch: [54241/59184, loss: 5.8239]\n",
            "Epoch [15/15], batch: [54242/59184, loss: 3.8361]\n",
            "Epoch [15/15], batch: [54243/59184, loss: 4.7005]\n",
            "Epoch [15/15], batch: [54244/59184, loss: 5.9382]\n",
            "Epoch [15/15], batch: [54245/59184, loss: 4.4770]\n",
            "Epoch [15/15], batch: [54246/59184, loss: 5.3293]\n",
            "Epoch [15/15], batch: [54247/59184, loss: 5.8608]\n",
            "Epoch [15/15], batch: [54248/59184, loss: 6.2854]\n",
            "Epoch [15/15], batch: [54249/59184, loss: 3.6439]\n",
            "Epoch [15/15], batch: [54250/59184, loss: 6.1648]\n",
            "Epoch [15/15], batch: [54251/59184, loss: 6.5481]\n",
            "Epoch [15/15], batch: [54252/59184, loss: 6.1258]\n",
            "Epoch [15/15], batch: [54253/59184, loss: 6.2048]\n",
            "Epoch [15/15], batch: [54254/59184, loss: 4.1572]\n",
            "Epoch [15/15], batch: [54255/59184, loss: 4.9904]\n",
            "Epoch [15/15], batch: [54256/59184, loss: 5.8032]\n",
            "Epoch [15/15], batch: [54257/59184, loss: 5.1433]\n",
            "Epoch [15/15], batch: [54258/59184, loss: 6.0195]\n",
            "Epoch [15/15], batch: [54259/59184, loss: 6.7929]\n",
            "Epoch [15/15], batch: [54260/59184, loss: 3.5776]\n",
            "Epoch [15/15], batch: [54261/59184, loss: 6.7298]\n",
            "Epoch [15/15], batch: [54262/59184, loss: 6.1586]\n",
            "Epoch [15/15], batch: [54263/59184, loss: 4.2070]\n",
            "Epoch [15/15], batch: [54264/59184, loss: 4.7127]\n",
            "Epoch [15/15], batch: [54265/59184, loss: 4.6141]\n",
            "Epoch [15/15], batch: [54266/59184, loss: 2.4995]\n",
            "Epoch [15/15], batch: [54267/59184, loss: 4.8166]\n",
            "Epoch [15/15], batch: [54268/59184, loss: 4.3156]\n",
            "Epoch [15/15], batch: [54269/59184, loss: 4.7649]\n",
            "Epoch [15/15], batch: [54270/59184, loss: 6.1524]\n",
            "Epoch [15/15], batch: [54271/59184, loss: 5.6661]\n",
            "Epoch [15/15], batch: [54272/59184, loss: 6.0274]\n",
            "Epoch [15/15], batch: [54273/59184, loss: 6.2537]\n",
            "Epoch [15/15], batch: [54274/59184, loss: 6.5659]\n",
            "Epoch [15/15], batch: [54275/59184, loss: 6.4144]\n",
            "Epoch [15/15], batch: [54276/59184, loss: 5.9579]\n",
            "Epoch [15/15], batch: [54277/59184, loss: 6.8825]\n",
            "Epoch [15/15], batch: [54278/59184, loss: 6.5507]\n",
            "Epoch [15/15], batch: [54279/59184, loss: 4.0791]\n",
            "Epoch [15/15], batch: [54280/59184, loss: 4.9030]\n",
            "Epoch [15/15], batch: [54281/59184, loss: 5.1605]\n",
            "Epoch [15/15], batch: [54282/59184, loss: 5.3659]\n",
            "Epoch [15/15], batch: [54283/59184, loss: 6.3416]\n",
            "Epoch [15/15], batch: [54284/59184, loss: 5.5933]\n",
            "Epoch [15/15], batch: [54285/59184, loss: 4.3129]\n",
            "Epoch [15/15], batch: [54286/59184, loss: 5.4404]\n",
            "Epoch [15/15], batch: [54287/59184, loss: 8.0442]\n",
            "Epoch [15/15], batch: [54288/59184, loss: 6.2491]\n",
            "Epoch [15/15], batch: [54289/59184, loss: 7.2824]\n",
            "Epoch [15/15], batch: [54290/59184, loss: 4.7458]\n",
            "Epoch [15/15], batch: [54291/59184, loss: 6.4642]\n",
            "Epoch [15/15], batch: [54292/59184, loss: 6.9835]\n",
            "Epoch [15/15], batch: [54293/59184, loss: 4.9399]\n",
            "Epoch [15/15], batch: [54294/59184, loss: 4.5878]\n",
            "Epoch [15/15], batch: [54295/59184, loss: 5.3625]\n",
            "Epoch [15/15], batch: [54296/59184, loss: 6.1018]\n",
            "Epoch [15/15], batch: [54297/59184, loss: 4.8153]\n",
            "Epoch [15/15], batch: [54298/59184, loss: 5.2714]\n",
            "Epoch [15/15], batch: [54299/59184, loss: 5.2882]\n",
            "Epoch [15/15], batch: [54300/59184, loss: 5.0703]\n",
            "Epoch [15/15], batch: [54301/59184, loss: 4.5243]\n",
            "Epoch [15/15], batch: [54302/59184, loss: 4.4095]\n",
            "Epoch [15/15], batch: [54303/59184, loss: 6.4397]\n",
            "Epoch [15/15], batch: [54304/59184, loss: 3.1832]\n",
            "Epoch [15/15], batch: [54305/59184, loss: 5.2433]\n",
            "Epoch [15/15], batch: [54306/59184, loss: 4.9458]\n",
            "Epoch [15/15], batch: [54307/59184, loss: 5.5770]\n",
            "Epoch [15/15], batch: [54308/59184, loss: 5.6809]\n",
            "Epoch [15/15], batch: [54309/59184, loss: 6.1055]\n",
            "Epoch [15/15], batch: [54310/59184, loss: 5.0003]\n",
            "Epoch [15/15], batch: [54311/59184, loss: 5.9342]\n",
            "Epoch [15/15], batch: [54312/59184, loss: 5.6141]\n",
            "Epoch [15/15], batch: [54313/59184, loss: 4.6782]\n",
            "Epoch [15/15], batch: [54314/59184, loss: 5.9361]\n",
            "Epoch [15/15], batch: [54315/59184, loss: 6.4173]\n",
            "Epoch [15/15], batch: [54316/59184, loss: 5.5157]\n",
            "Epoch [15/15], batch: [54317/59184, loss: 7.4609]\n",
            "Epoch [15/15], batch: [54318/59184, loss: 6.4918]\n",
            "Epoch [15/15], batch: [54319/59184, loss: 5.5068]\n",
            "Epoch [15/15], batch: [54320/59184, loss: 5.8204]\n",
            "Epoch [15/15], batch: [54321/59184, loss: 6.5471]\n",
            "Epoch [15/15], batch: [54322/59184, loss: 4.8097]\n",
            "Epoch [15/15], batch: [54323/59184, loss: 5.4895]\n",
            "Epoch [15/15], batch: [54324/59184, loss: 6.8026]\n",
            "Epoch [15/15], batch: [54325/59184, loss: 6.3187]\n",
            "Epoch [15/15], batch: [54326/59184, loss: 5.1582]\n",
            "Epoch [15/15], batch: [54327/59184, loss: 5.2780]\n",
            "Epoch [15/15], batch: [54328/59184, loss: 6.0187]\n",
            "Epoch [15/15], batch: [54329/59184, loss: 5.4608]\n",
            "Epoch [15/15], batch: [54330/59184, loss: 6.0673]\n",
            "Epoch [15/15], batch: [54331/59184, loss: 4.6442]\n",
            "Epoch [15/15], batch: [54332/59184, loss: 5.7002]\n",
            "Epoch [15/15], batch: [54333/59184, loss: 6.8858]\n",
            "Epoch [15/15], batch: [54334/59184, loss: 5.3550]\n",
            "Epoch [15/15], batch: [54335/59184, loss: 5.5728]\n",
            "Epoch [15/15], batch: [54336/59184, loss: 5.2629]\n",
            "Epoch [15/15], batch: [54337/59184, loss: 5.6101]\n",
            "Epoch [15/15], batch: [54338/59184, loss: 5.7647]\n",
            "Epoch [15/15], batch: [54339/59184, loss: 7.6541]\n",
            "Epoch [15/15], batch: [54340/59184, loss: 6.5150]\n",
            "Epoch [15/15], batch: [54341/59184, loss: 6.4426]\n",
            "Epoch [15/15], batch: [54342/59184, loss: 6.6046]\n",
            "Epoch [15/15], batch: [54343/59184, loss: 8.2740]\n",
            "Epoch [15/15], batch: [54344/59184, loss: 5.5039]\n",
            "Epoch [15/15], batch: [54345/59184, loss: 6.1222]\n",
            "Epoch [15/15], batch: [54346/59184, loss: 5.0347]\n",
            "Epoch [15/15], batch: [54347/59184, loss: 6.4368]\n",
            "Epoch [15/15], batch: [54348/59184, loss: 5.7279]\n",
            "Epoch [15/15], batch: [54349/59184, loss: 6.8328]\n",
            "Epoch [15/15], batch: [54350/59184, loss: 5.8727]\n",
            "Epoch [15/15], batch: [54351/59184, loss: 5.8235]\n",
            "Epoch [15/15], batch: [54352/59184, loss: 5.6349]\n",
            "Epoch [15/15], batch: [54353/59184, loss: 4.5936]\n",
            "Epoch [15/15], batch: [54354/59184, loss: 5.7983]\n",
            "Epoch [15/15], batch: [54355/59184, loss: 6.7479]\n",
            "Epoch [15/15], batch: [54356/59184, loss: 7.1113]\n",
            "Epoch [15/15], batch: [54357/59184, loss: 5.2421]\n",
            "Epoch [15/15], batch: [54358/59184, loss: 5.0623]\n",
            "Epoch [15/15], batch: [54359/59184, loss: 6.0569]\n",
            "Epoch [15/15], batch: [54360/59184, loss: 5.9848]\n",
            "Epoch [15/15], batch: [54361/59184, loss: 5.1572]\n",
            "Epoch [15/15], batch: [54362/59184, loss: 4.9779]\n",
            "Epoch [15/15], batch: [54363/59184, loss: 5.5566]\n",
            "Epoch [15/15], batch: [54364/59184, loss: 5.3264]\n",
            "Epoch [15/15], batch: [54365/59184, loss: 5.1738]\n",
            "Epoch [15/15], batch: [54366/59184, loss: 5.2309]\n",
            "Epoch [15/15], batch: [54367/59184, loss: 5.7555]\n",
            "Epoch [15/15], batch: [54368/59184, loss: 5.0771]\n",
            "Epoch [15/15], batch: [54369/59184, loss: 3.5726]\n",
            "Epoch [15/15], batch: [54370/59184, loss: 7.4360]\n",
            "Epoch [15/15], batch: [54371/59184, loss: 6.2490]\n",
            "Epoch [15/15], batch: [54372/59184, loss: 6.1781]\n",
            "Epoch [15/15], batch: [54373/59184, loss: 4.7899]\n",
            "Epoch [15/15], batch: [54374/59184, loss: 3.9346]\n",
            "Epoch [15/15], batch: [54375/59184, loss: 5.6709]\n",
            "Epoch [15/15], batch: [54376/59184, loss: 6.8283]\n",
            "Epoch [15/15], batch: [54377/59184, loss: 5.9155]\n",
            "Epoch [15/15], batch: [54378/59184, loss: 6.0334]\n",
            "Epoch [15/15], batch: [54379/59184, loss: 4.8310]\n",
            "Epoch [15/15], batch: [54380/59184, loss: 6.0607]\n",
            "Epoch [15/15], batch: [54381/59184, loss: 4.1178]\n",
            "Epoch [15/15], batch: [54382/59184, loss: 5.3086]\n",
            "Epoch [15/15], batch: [54383/59184, loss: 5.9640]\n",
            "Epoch [15/15], batch: [54384/59184, loss: 6.5974]\n",
            "Epoch [15/15], batch: [54385/59184, loss: 5.5009]\n",
            "Epoch [15/15], batch: [54386/59184, loss: 4.2670]\n",
            "Epoch [15/15], batch: [54387/59184, loss: 6.0951]\n",
            "Epoch [15/15], batch: [54388/59184, loss: 6.5633]\n",
            "Epoch [15/15], batch: [54389/59184, loss: 5.1142]\n",
            "Epoch [15/15], batch: [54390/59184, loss: 4.9488]\n",
            "Epoch [15/15], batch: [54391/59184, loss: 5.8115]\n",
            "Epoch [15/15], batch: [54392/59184, loss: 6.9321]\n",
            "Epoch [15/15], batch: [54393/59184, loss: 5.8645]\n",
            "Epoch [15/15], batch: [54394/59184, loss: 6.5852]\n",
            "Epoch [15/15], batch: [54395/59184, loss: 5.7781]\n",
            "Epoch [15/15], batch: [54396/59184, loss: 6.1471]\n",
            "Epoch [15/15], batch: [54397/59184, loss: 6.7421]\n",
            "Epoch [15/15], batch: [54398/59184, loss: 4.5834]\n",
            "Epoch [15/15], batch: [54399/59184, loss: 4.4300]\n",
            "Epoch [15/15], batch: [54400/59184, loss: 5.6524]\n",
            "Epoch [15/15], batch: [54401/59184, loss: 6.5931]\n",
            "Epoch [15/15], batch: [54402/59184, loss: 4.0659]\n",
            "Epoch [15/15], batch: [54403/59184, loss: 4.2989]\n",
            "Epoch [15/15], batch: [54404/59184, loss: 4.1375]\n",
            "Epoch [15/15], batch: [54405/59184, loss: 5.6406]\n",
            "Epoch [15/15], batch: [54406/59184, loss: 4.5815]\n",
            "Epoch [15/15], batch: [54407/59184, loss: 5.1034]\n",
            "Epoch [15/15], batch: [54408/59184, loss: 7.2433]\n",
            "Epoch [15/15], batch: [54409/59184, loss: 6.2706]\n",
            "Epoch [15/15], batch: [54410/59184, loss: 5.1788]\n",
            "Epoch [15/15], batch: [54411/59184, loss: 6.6228]\n",
            "Epoch [15/15], batch: [54412/59184, loss: 5.2185]\n",
            "Epoch [15/15], batch: [54413/59184, loss: 6.6899]\n",
            "Epoch [15/15], batch: [54414/59184, loss: 6.1572]\n",
            "Epoch [15/15], batch: [54415/59184, loss: 4.9457]\n",
            "Epoch [15/15], batch: [54416/59184, loss: 4.4749]\n",
            "Epoch [15/15], batch: [54417/59184, loss: 6.6631]\n",
            "Epoch [15/15], batch: [54418/59184, loss: 5.1387]\n",
            "Epoch [15/15], batch: [54419/59184, loss: 6.6815]\n",
            "Epoch [15/15], batch: [54420/59184, loss: 4.3419]\n",
            "Epoch [15/15], batch: [54421/59184, loss: 6.7688]\n",
            "Epoch [15/15], batch: [54422/59184, loss: 5.8095]\n",
            "Epoch [15/15], batch: [54423/59184, loss: 3.4413]\n",
            "Epoch [15/15], batch: [54424/59184, loss: 3.7793]\n",
            "Epoch [15/15], batch: [54425/59184, loss: 5.9419]\n",
            "Epoch [15/15], batch: [54426/59184, loss: 3.9502]\n",
            "Epoch [15/15], batch: [54427/59184, loss: 4.9720]\n",
            "Epoch [15/15], batch: [54428/59184, loss: 6.9362]\n",
            "Epoch [15/15], batch: [54429/59184, loss: 6.2977]\n",
            "Epoch [15/15], batch: [54430/59184, loss: 6.2320]\n",
            "Epoch [15/15], batch: [54431/59184, loss: 4.6042]\n",
            "Epoch [15/15], batch: [54432/59184, loss: 6.2507]\n",
            "Epoch [15/15], batch: [54433/59184, loss: 6.3516]\n",
            "Epoch [15/15], batch: [54434/59184, loss: 5.0176]\n",
            "Epoch [15/15], batch: [54435/59184, loss: 4.7263]\n",
            "Epoch [15/15], batch: [54436/59184, loss: 5.6094]\n",
            "Epoch [15/15], batch: [54437/59184, loss: 5.9164]\n",
            "Epoch [15/15], batch: [54438/59184, loss: 6.4930]\n",
            "Epoch [15/15], batch: [54439/59184, loss: 6.2988]\n",
            "Epoch [15/15], batch: [54440/59184, loss: 5.6163]\n",
            "Epoch [15/15], batch: [54441/59184, loss: 6.4963]\n",
            "Epoch [15/15], batch: [54442/59184, loss: 5.4060]\n",
            "Epoch [15/15], batch: [54443/59184, loss: 6.6247]\n",
            "Epoch [15/15], batch: [54444/59184, loss: 4.8521]\n",
            "Epoch [15/15], batch: [54445/59184, loss: 4.0303]\n",
            "Epoch [15/15], batch: [54446/59184, loss: 4.1462]\n",
            "Epoch [15/15], batch: [54447/59184, loss: 4.5830]\n",
            "Epoch [15/15], batch: [54448/59184, loss: 5.4670]\n",
            "Epoch [15/15], batch: [54449/59184, loss: 6.0311]\n",
            "Epoch [15/15], batch: [54450/59184, loss: 2.9075]\n",
            "Epoch [15/15], batch: [54451/59184, loss: 3.4388]\n",
            "Epoch [15/15], batch: [54452/59184, loss: 4.0113]\n",
            "Epoch [15/15], batch: [54453/59184, loss: 5.5197]\n",
            "Epoch [15/15], batch: [54454/59184, loss: 6.3483]\n",
            "Epoch [15/15], batch: [54455/59184, loss: 7.4785]\n",
            "Epoch [15/15], batch: [54456/59184, loss: 6.4817]\n",
            "Epoch [15/15], batch: [54457/59184, loss: 5.5213]\n",
            "Epoch [15/15], batch: [54458/59184, loss: 5.2939]\n",
            "Epoch [15/15], batch: [54459/59184, loss: 5.2877]\n",
            "Epoch [15/15], batch: [54460/59184, loss: 5.8431]\n",
            "Epoch [15/15], batch: [54461/59184, loss: 5.6654]\n",
            "Epoch [15/15], batch: [54462/59184, loss: 5.6338]\n",
            "Epoch [15/15], batch: [54463/59184, loss: 4.3413]\n",
            "Epoch [15/15], batch: [54464/59184, loss: 3.7709]\n",
            "Epoch [15/15], batch: [54465/59184, loss: 3.6358]\n",
            "Epoch [15/15], batch: [54466/59184, loss: 4.0760]\n",
            "Epoch [15/15], batch: [54467/59184, loss: 5.6871]\n",
            "Epoch [15/15], batch: [54468/59184, loss: 4.8875]\n",
            "Epoch [15/15], batch: [54469/59184, loss: 6.3335]\n",
            "Epoch [15/15], batch: [54470/59184, loss: 5.7295]\n",
            "Epoch [15/15], batch: [54471/59184, loss: 5.4227]\n",
            "Epoch [15/15], batch: [54472/59184, loss: 4.5827]\n",
            "Epoch [15/15], batch: [54473/59184, loss: 4.6541]\n",
            "Epoch [15/15], batch: [54474/59184, loss: 7.1631]\n",
            "Epoch [15/15], batch: [54475/59184, loss: 6.3725]\n",
            "Epoch [15/15], batch: [54476/59184, loss: 5.5662]\n",
            "Epoch [15/15], batch: [54477/59184, loss: 4.5814]\n",
            "Epoch [15/15], batch: [54478/59184, loss: 5.9307]\n",
            "Epoch [15/15], batch: [54479/59184, loss: 6.2560]\n",
            "Epoch [15/15], batch: [54480/59184, loss: 6.4357]\n",
            "Epoch [15/15], batch: [54481/59184, loss: 5.8987]\n",
            "Epoch [15/15], batch: [54482/59184, loss: 6.1373]\n",
            "Epoch [15/15], batch: [54483/59184, loss: 4.0491]\n",
            "Epoch [15/15], batch: [54484/59184, loss: 6.0755]\n",
            "Epoch [15/15], batch: [54485/59184, loss: 5.7490]\n",
            "Epoch [15/15], batch: [54486/59184, loss: 5.1732]\n",
            "Epoch [15/15], batch: [54487/59184, loss: 5.8028]\n",
            "Epoch [15/15], batch: [54488/59184, loss: 4.1005]\n",
            "Epoch [15/15], batch: [54489/59184, loss: 5.4954]\n",
            "Epoch [15/15], batch: [54490/59184, loss: 5.1284]\n",
            "Epoch [15/15], batch: [54491/59184, loss: 5.1212]\n",
            "Epoch [15/15], batch: [54492/59184, loss: 5.1620]\n",
            "Epoch [15/15], batch: [54493/59184, loss: 5.6616]\n",
            "Epoch [15/15], batch: [54494/59184, loss: 3.9450]\n",
            "Epoch [15/15], batch: [54495/59184, loss: 5.1976]\n",
            "Epoch [15/15], batch: [54496/59184, loss: 5.6935]\n",
            "Epoch [15/15], batch: [54497/59184, loss: 6.6814]\n",
            "Epoch [15/15], batch: [54498/59184, loss: 6.0079]\n",
            "Epoch [15/15], batch: [54499/59184, loss: 4.4162]\n",
            "Epoch [15/15], batch: [54500/59184, loss: 6.3645]\n",
            "Epoch [15/15], batch: [54501/59184, loss: 5.7702]\n",
            "Epoch [15/15], batch: [54502/59184, loss: 3.5309]\n",
            "Epoch [15/15], batch: [54503/59184, loss: 5.9342]\n",
            "Epoch [15/15], batch: [54504/59184, loss: 7.4062]\n",
            "Epoch [15/15], batch: [54505/59184, loss: 6.5086]\n",
            "Epoch [15/15], batch: [54506/59184, loss: 5.2217]\n",
            "Epoch [15/15], batch: [54507/59184, loss: 5.3768]\n",
            "Epoch [15/15], batch: [54508/59184, loss: 6.8962]\n",
            "Epoch [15/15], batch: [54509/59184, loss: 5.1762]\n",
            "Epoch [15/15], batch: [54510/59184, loss: 3.9964]\n",
            "Epoch [15/15], batch: [54511/59184, loss: 5.5464]\n",
            "Epoch [15/15], batch: [54512/59184, loss: 6.3808]\n",
            "Epoch [15/15], batch: [54513/59184, loss: 5.2643]\n",
            "Epoch [15/15], batch: [54514/59184, loss: 7.6033]\n",
            "Epoch [15/15], batch: [54515/59184, loss: 7.4547]\n",
            "Epoch [15/15], batch: [54516/59184, loss: 3.5943]\n",
            "Epoch [15/15], batch: [54517/59184, loss: 4.8852]\n",
            "Epoch [15/15], batch: [54518/59184, loss: 4.8353]\n",
            "Epoch [15/15], batch: [54519/59184, loss: 6.8492]\n",
            "Epoch [15/15], batch: [54520/59184, loss: 4.4911]\n",
            "Epoch [15/15], batch: [54521/59184, loss: 5.6888]\n",
            "Epoch [15/15], batch: [54522/59184, loss: 6.9684]\n",
            "Epoch [15/15], batch: [54523/59184, loss: 4.6210]\n",
            "Epoch [15/15], batch: [54524/59184, loss: 5.1078]\n",
            "Epoch [15/15], batch: [54525/59184, loss: 4.4353]\n",
            "Epoch [15/15], batch: [54526/59184, loss: 4.1434]\n",
            "Epoch [15/15], batch: [54527/59184, loss: 4.3271]\n",
            "Epoch [15/15], batch: [54528/59184, loss: 5.4137]\n",
            "Epoch [15/15], batch: [54529/59184, loss: 6.3410]\n",
            "Epoch [15/15], batch: [54530/59184, loss: 5.7530]\n",
            "Epoch [15/15], batch: [54531/59184, loss: 7.3652]\n",
            "Epoch [15/15], batch: [54532/59184, loss: 5.0100]\n",
            "Epoch [15/15], batch: [54533/59184, loss: 4.7698]\n",
            "Epoch [15/15], batch: [54534/59184, loss: 4.6777]\n",
            "Epoch [15/15], batch: [54535/59184, loss: 6.1316]\n",
            "Epoch [15/15], batch: [54536/59184, loss: 5.7768]\n",
            "Epoch [15/15], batch: [54537/59184, loss: 5.5138]\n",
            "Epoch [15/15], batch: [54538/59184, loss: 7.3943]\n",
            "Epoch [15/15], batch: [54539/59184, loss: 5.7699]\n",
            "Epoch [15/15], batch: [54540/59184, loss: 4.8725]\n",
            "Epoch [15/15], batch: [54541/59184, loss: 6.1429]\n",
            "Epoch [15/15], batch: [54542/59184, loss: 5.4077]\n",
            "Epoch [15/15], batch: [54543/59184, loss: 6.5371]\n",
            "Epoch [15/15], batch: [54544/59184, loss: 6.1758]\n",
            "Epoch [15/15], batch: [54545/59184, loss: 7.2290]\n",
            "Epoch [15/15], batch: [54546/59184, loss: 5.7502]\n",
            "Epoch [15/15], batch: [54547/59184, loss: 7.3961]\n",
            "Epoch [15/15], batch: [54548/59184, loss: 7.0829]\n",
            "Epoch [15/15], batch: [54549/59184, loss: 6.4956]\n",
            "Epoch [15/15], batch: [54550/59184, loss: 5.4715]\n",
            "Epoch [15/15], batch: [54551/59184, loss: 4.2968]\n",
            "Epoch [15/15], batch: [54552/59184, loss: 6.1786]\n",
            "Epoch [15/15], batch: [54553/59184, loss: 5.5995]\n",
            "Epoch [15/15], batch: [54554/59184, loss: 6.7129]\n",
            "Epoch [15/15], batch: [54555/59184, loss: 4.8683]\n",
            "Epoch [15/15], batch: [54556/59184, loss: 6.6938]\n",
            "Epoch [15/15], batch: [54557/59184, loss: 4.7033]\n",
            "Epoch [15/15], batch: [54558/59184, loss: 6.9679]\n",
            "Epoch [15/15], batch: [54559/59184, loss: 4.6271]\n",
            "Epoch [15/15], batch: [54560/59184, loss: 4.8412]\n",
            "Epoch [15/15], batch: [54561/59184, loss: 5.2193]\n",
            "Epoch [15/15], batch: [54562/59184, loss: 5.8557]\n",
            "Epoch [15/15], batch: [54563/59184, loss: 7.2917]\n",
            "Epoch [15/15], batch: [54564/59184, loss: 7.2954]\n",
            "Epoch [15/15], batch: [54565/59184, loss: 4.5630]\n",
            "Epoch [15/15], batch: [54566/59184, loss: 4.6641]\n",
            "Epoch [15/15], batch: [54567/59184, loss: 5.5655]\n",
            "Epoch [15/15], batch: [54568/59184, loss: 5.7816]\n",
            "Epoch [15/15], batch: [54569/59184, loss: 6.2981]\n",
            "Epoch [15/15], batch: [54570/59184, loss: 5.4386]\n",
            "Epoch [15/15], batch: [54571/59184, loss: 7.2477]\n",
            "Epoch [15/15], batch: [54572/59184, loss: 4.6863]\n",
            "Epoch [15/15], batch: [54573/59184, loss: 5.7757]\n",
            "Epoch [15/15], batch: [54574/59184, loss: 5.0135]\n",
            "Epoch [15/15], batch: [54575/59184, loss: 6.3945]\n",
            "Epoch [15/15], batch: [54576/59184, loss: 6.2067]\n",
            "Epoch [15/15], batch: [54577/59184, loss: 5.0882]\n",
            "Epoch [15/15], batch: [54578/59184, loss: 6.4917]\n",
            "Epoch [15/15], batch: [54579/59184, loss: 4.5369]\n",
            "Epoch [15/15], batch: [54580/59184, loss: 5.9898]\n",
            "Epoch [15/15], batch: [54581/59184, loss: 7.3715]\n",
            "Epoch [15/15], batch: [54582/59184, loss: 5.6633]\n",
            "Epoch [15/15], batch: [54583/59184, loss: 6.9638]\n",
            "Epoch [15/15], batch: [54584/59184, loss: 6.1182]\n",
            "Epoch [15/15], batch: [54585/59184, loss: 7.3604]\n",
            "Epoch [15/15], batch: [54586/59184, loss: 5.2569]\n",
            "Epoch [15/15], batch: [54587/59184, loss: 5.8221]\n",
            "Epoch [15/15], batch: [54588/59184, loss: 4.8373]\n",
            "Epoch [15/15], batch: [54589/59184, loss: 5.6139]\n",
            "Epoch [15/15], batch: [54590/59184, loss: 7.1851]\n",
            "Epoch [15/15], batch: [54591/59184, loss: 6.4450]\n",
            "Epoch [15/15], batch: [54592/59184, loss: 5.0222]\n",
            "Epoch [15/15], batch: [54593/59184, loss: 5.7154]\n",
            "Epoch [15/15], batch: [54594/59184, loss: 6.7143]\n",
            "Epoch [15/15], batch: [54595/59184, loss: 7.1700]\n",
            "Epoch [15/15], batch: [54596/59184, loss: 7.0020]\n",
            "Epoch [15/15], batch: [54597/59184, loss: 4.9740]\n",
            "Epoch [15/15], batch: [54598/59184, loss: 6.2584]\n",
            "Epoch [15/15], batch: [54599/59184, loss: 5.5987]\n",
            "Epoch [15/15], batch: [54600/59184, loss: 4.3432]\n",
            "Epoch [15/15], batch: [54601/59184, loss: 5.2383]\n",
            "Epoch [15/15], batch: [54602/59184, loss: 6.7363]\n",
            "Epoch [15/15], batch: [54603/59184, loss: 6.1531]\n",
            "Epoch [15/15], batch: [54604/59184, loss: 6.3713]\n",
            "Epoch [15/15], batch: [54605/59184, loss: 6.2281]\n",
            "Epoch [15/15], batch: [54606/59184, loss: 6.6712]\n",
            "Epoch [15/15], batch: [54607/59184, loss: 6.8838]\n",
            "Epoch [15/15], batch: [54608/59184, loss: 6.6410]\n",
            "Epoch [15/15], batch: [54609/59184, loss: 6.6609]\n",
            "Epoch [15/15], batch: [54610/59184, loss: 5.3936]\n",
            "Epoch [15/15], batch: [54611/59184, loss: 4.8810]\n",
            "Epoch [15/15], batch: [54612/59184, loss: 6.5571]\n",
            "Epoch [15/15], batch: [54613/59184, loss: 3.6684]\n",
            "Epoch [15/15], batch: [54614/59184, loss: 6.1151]\n",
            "Epoch [15/15], batch: [54615/59184, loss: 6.3758]\n",
            "Epoch [15/15], batch: [54616/59184, loss: 4.5827]\n",
            "Epoch [15/15], batch: [54617/59184, loss: 3.9561]\n",
            "Epoch [15/15], batch: [54618/59184, loss: 5.3775]\n",
            "Epoch [15/15], batch: [54619/59184, loss: 4.9738]\n",
            "Epoch [15/15], batch: [54620/59184, loss: 4.8247]\n",
            "Epoch [15/15], batch: [54621/59184, loss: 4.8050]\n",
            "Epoch [15/15], batch: [54622/59184, loss: 4.5911]\n",
            "Epoch [15/15], batch: [54623/59184, loss: 4.5353]\n",
            "Epoch [15/15], batch: [54624/59184, loss: 2.8605]\n",
            "Epoch [15/15], batch: [54625/59184, loss: 3.3529]\n",
            "Epoch [15/15], batch: [54626/59184, loss: 5.6870]\n",
            "Epoch [15/15], batch: [54627/59184, loss: 5.8907]\n",
            "Epoch [15/15], batch: [54628/59184, loss: 5.5756]\n",
            "Epoch [15/15], batch: [54629/59184, loss: 3.5357]\n",
            "Epoch [15/15], batch: [54630/59184, loss: 3.6560]\n",
            "Epoch [15/15], batch: [54631/59184, loss: 4.8054]\n",
            "Epoch [15/15], batch: [54632/59184, loss: 5.0011]\n",
            "Epoch [15/15], batch: [54633/59184, loss: 6.3241]\n",
            "Epoch [15/15], batch: [54634/59184, loss: 5.3294]\n",
            "Epoch [15/15], batch: [54635/59184, loss: 6.3426]\n",
            "Epoch [15/15], batch: [54636/59184, loss: 7.2317]\n",
            "Epoch [15/15], batch: [54637/59184, loss: 7.0724]\n",
            "Epoch [15/15], batch: [54638/59184, loss: 7.8200]\n",
            "Epoch [15/15], batch: [54639/59184, loss: 7.0998]\n",
            "Epoch [15/15], batch: [54640/59184, loss: 4.5579]\n",
            "Epoch [15/15], batch: [54641/59184, loss: 2.7897]\n",
            "Epoch [15/15], batch: [54642/59184, loss: 6.1076]\n",
            "Epoch [15/15], batch: [54643/59184, loss: 5.7730]\n",
            "Epoch [15/15], batch: [54644/59184, loss: 5.0417]\n",
            "Epoch [15/15], batch: [54645/59184, loss: 5.4627]\n",
            "Epoch [15/15], batch: [54646/59184, loss: 5.3759]\n",
            "Epoch [15/15], batch: [54647/59184, loss: 5.1496]\n",
            "Epoch [15/15], batch: [54648/59184, loss: 6.7753]\n",
            "Epoch [15/15], batch: [54649/59184, loss: 3.8642]\n",
            "Epoch [15/15], batch: [54650/59184, loss: 5.2757]\n",
            "Epoch [15/15], batch: [54651/59184, loss: 5.6314]\n",
            "Epoch [15/15], batch: [54652/59184, loss: 6.0437]\n",
            "Epoch [15/15], batch: [54653/59184, loss: 4.2016]\n",
            "Epoch [15/15], batch: [54654/59184, loss: 3.0854]\n",
            "Epoch [15/15], batch: [54655/59184, loss: 5.3188]\n",
            "Epoch [15/15], batch: [54656/59184, loss: 5.8984]\n",
            "Epoch [15/15], batch: [54657/59184, loss: 6.4580]\n",
            "Epoch [15/15], batch: [54658/59184, loss: 7.2239]\n",
            "Epoch [15/15], batch: [54659/59184, loss: 5.6011]\n",
            "Epoch [15/15], batch: [54660/59184, loss: 5.1208]\n",
            "Epoch [15/15], batch: [54661/59184, loss: 5.0037]\n",
            "Epoch [15/15], batch: [54662/59184, loss: 4.7578]\n",
            "Epoch [15/15], batch: [54663/59184, loss: 6.0771]\n",
            "Epoch [15/15], batch: [54664/59184, loss: 6.7195]\n",
            "Epoch [15/15], batch: [54665/59184, loss: 6.3712]\n",
            "Epoch [15/15], batch: [54666/59184, loss: 6.0233]\n",
            "Epoch [15/15], batch: [54667/59184, loss: 4.1594]\n",
            "Epoch [15/15], batch: [54668/59184, loss: 5.5056]\n",
            "Epoch [15/15], batch: [54669/59184, loss: 5.8589]\n",
            "Epoch [15/15], batch: [54670/59184, loss: 5.7429]\n",
            "Epoch [15/15], batch: [54671/59184, loss: 6.7100]\n",
            "Epoch [15/15], batch: [54672/59184, loss: 5.7415]\n",
            "Epoch [15/15], batch: [54673/59184, loss: 5.9400]\n",
            "Epoch [15/15], batch: [54674/59184, loss: 4.7697]\n",
            "Epoch [15/15], batch: [54675/59184, loss: 6.4381]\n",
            "Epoch [15/15], batch: [54676/59184, loss: 5.3525]\n",
            "Epoch [15/15], batch: [54677/59184, loss: 5.5542]\n",
            "Epoch [15/15], batch: [54678/59184, loss: 6.7686]\n",
            "Epoch [15/15], batch: [54679/59184, loss: 6.3347]\n",
            "Epoch [15/15], batch: [54680/59184, loss: 6.9697]\n",
            "Epoch [15/15], batch: [54681/59184, loss: 5.9781]\n",
            "Epoch [15/15], batch: [54682/59184, loss: 6.5066]\n",
            "Epoch [15/15], batch: [54683/59184, loss: 6.7080]\n",
            "Epoch [15/15], batch: [54684/59184, loss: 6.7274]\n",
            "Epoch [15/15], batch: [54685/59184, loss: 5.8027]\n",
            "Epoch [15/15], batch: [54686/59184, loss: 4.6456]\n",
            "Epoch [15/15], batch: [54687/59184, loss: 4.8971]\n",
            "Epoch [15/15], batch: [54688/59184, loss: 5.2894]\n",
            "Epoch [15/15], batch: [54689/59184, loss: 6.4629]\n",
            "Epoch [15/15], batch: [54690/59184, loss: 5.1004]\n",
            "Epoch [15/15], batch: [54691/59184, loss: 5.7824]\n",
            "Epoch [15/15], batch: [54692/59184, loss: 5.6752]\n",
            "Epoch [15/15], batch: [54693/59184, loss: 5.2852]\n",
            "Epoch [15/15], batch: [54694/59184, loss: 4.4989]\n",
            "Epoch [15/15], batch: [54695/59184, loss: 6.8748]\n",
            "Epoch [15/15], batch: [54696/59184, loss: 6.9465]\n",
            "Epoch [15/15], batch: [54697/59184, loss: 6.9940]\n",
            "Epoch [15/15], batch: [54698/59184, loss: 6.6029]\n",
            "Epoch [15/15], batch: [54699/59184, loss: 5.8817]\n",
            "Epoch [15/15], batch: [54700/59184, loss: 4.3902]\n",
            "Epoch [15/15], batch: [54701/59184, loss: 5.1936]\n",
            "Epoch [15/15], batch: [54702/59184, loss: 5.4190]\n",
            "Epoch [15/15], batch: [54703/59184, loss: 5.8111]\n",
            "Epoch [15/15], batch: [54704/59184, loss: 6.4742]\n",
            "Epoch [15/15], batch: [54705/59184, loss: 4.5918]\n",
            "Epoch [15/15], batch: [54706/59184, loss: 5.1704]\n",
            "Epoch [15/15], batch: [54707/59184, loss: 5.1166]\n",
            "Epoch [15/15], batch: [54708/59184, loss: 6.6358]\n",
            "Epoch [15/15], batch: [54709/59184, loss: 5.4510]\n",
            "Epoch [15/15], batch: [54710/59184, loss: 6.0061]\n",
            "Epoch [15/15], batch: [54711/59184, loss: 7.6462]\n",
            "Epoch [15/15], batch: [54712/59184, loss: 6.1575]\n",
            "Epoch [15/15], batch: [54713/59184, loss: 6.3810]\n",
            "Epoch [15/15], batch: [54714/59184, loss: 4.3670]\n",
            "Epoch [15/15], batch: [54715/59184, loss: 6.7055]\n",
            "Epoch [15/15], batch: [54716/59184, loss: 4.7794]\n",
            "Epoch [15/15], batch: [54717/59184, loss: 6.6897]\n",
            "Epoch [15/15], batch: [54718/59184, loss: 5.2626]\n",
            "Epoch [15/15], batch: [54719/59184, loss: 4.9877]\n",
            "Epoch [15/15], batch: [54720/59184, loss: 5.7984]\n",
            "Epoch [15/15], batch: [54721/59184, loss: 5.8232]\n",
            "Epoch [15/15], batch: [54722/59184, loss: 5.6043]\n",
            "Epoch [15/15], batch: [54723/59184, loss: 6.6033]\n",
            "Epoch [15/15], batch: [54724/59184, loss: 5.0999]\n",
            "Epoch [15/15], batch: [54725/59184, loss: 5.0635]\n",
            "Epoch [15/15], batch: [54726/59184, loss: 6.4769]\n",
            "Epoch [15/15], batch: [54727/59184, loss: 5.6016]\n",
            "Epoch [15/15], batch: [54728/59184, loss: 6.7546]\n",
            "Epoch [15/15], batch: [54729/59184, loss: 5.1567]\n",
            "Epoch [15/15], batch: [54730/59184, loss: 6.4235]\n",
            "Epoch [15/15], batch: [54731/59184, loss: 5.8090]\n",
            "Epoch [15/15], batch: [54732/59184, loss: 5.3191]\n",
            "Epoch [15/15], batch: [54733/59184, loss: 5.4892]\n",
            "Epoch [15/15], batch: [54734/59184, loss: 6.3752]\n",
            "Epoch [15/15], batch: [54735/59184, loss: 6.5649]\n",
            "Epoch [15/15], batch: [54736/59184, loss: 6.4876]\n",
            "Epoch [15/15], batch: [54737/59184, loss: 5.7260]\n",
            "Epoch [15/15], batch: [54738/59184, loss: 6.7692]\n",
            "Epoch [15/15], batch: [54739/59184, loss: 5.9759]\n",
            "Epoch [15/15], batch: [54740/59184, loss: 5.4908]\n",
            "Epoch [15/15], batch: [54741/59184, loss: 5.9458]\n",
            "Epoch [15/15], batch: [54742/59184, loss: 7.1990]\n",
            "Epoch [15/15], batch: [54743/59184, loss: 6.2267]\n",
            "Epoch [15/15], batch: [54744/59184, loss: 6.1246]\n",
            "Epoch [15/15], batch: [54745/59184, loss: 5.0552]\n",
            "Epoch [15/15], batch: [54746/59184, loss: 7.4621]\n",
            "Epoch [15/15], batch: [54747/59184, loss: 6.0928]\n",
            "Epoch [15/15], batch: [54748/59184, loss: 6.8625]\n",
            "Epoch [15/15], batch: [54749/59184, loss: 7.6376]\n",
            "Epoch [15/15], batch: [54750/59184, loss: 6.4643]\n",
            "Epoch [15/15], batch: [54751/59184, loss: 5.8007]\n",
            "Epoch [15/15], batch: [54752/59184, loss: 6.1268]\n",
            "Epoch [15/15], batch: [54753/59184, loss: 5.7740]\n",
            "Epoch [15/15], batch: [54754/59184, loss: 4.9746]\n",
            "Epoch [15/15], batch: [54755/59184, loss: 5.8259]\n",
            "Epoch [15/15], batch: [54756/59184, loss: 6.6044]\n",
            "Epoch [15/15], batch: [54757/59184, loss: 5.6540]\n",
            "Epoch [15/15], batch: [54758/59184, loss: 5.7621]\n",
            "Epoch [15/15], batch: [54759/59184, loss: 5.7025]\n",
            "Epoch [15/15], batch: [54760/59184, loss: 7.3574]\n",
            "Epoch [15/15], batch: [54761/59184, loss: 3.5983]\n",
            "Epoch [15/15], batch: [54762/59184, loss: 5.6013]\n",
            "Epoch [15/15], batch: [54763/59184, loss: 4.9630]\n",
            "Epoch [15/15], batch: [54764/59184, loss: 3.8068]\n",
            "Epoch [15/15], batch: [54765/59184, loss: 4.6161]\n",
            "Epoch [15/15], batch: [54766/59184, loss: 4.1402]\n",
            "Epoch [15/15], batch: [54767/59184, loss: 4.8157]\n",
            "Epoch [15/15], batch: [54768/59184, loss: 7.3543]\n",
            "Epoch [15/15], batch: [54769/59184, loss: 6.3979]\n",
            "Epoch [15/15], batch: [54770/59184, loss: 7.5196]\n",
            "Epoch [15/15], batch: [54771/59184, loss: 7.1658]\n",
            "Epoch [15/15], batch: [54772/59184, loss: 5.0269]\n",
            "Epoch [15/15], batch: [54773/59184, loss: 7.0701]\n",
            "Epoch [15/15], batch: [54774/59184, loss: 6.7501]\n",
            "Epoch [15/15], batch: [54775/59184, loss: 4.0435]\n",
            "Epoch [15/15], batch: [54776/59184, loss: 6.5727]\n",
            "Epoch [15/15], batch: [54777/59184, loss: 5.8679]\n",
            "Epoch [15/15], batch: [54778/59184, loss: 6.4568]\n",
            "Epoch [15/15], batch: [54779/59184, loss: 6.7486]\n",
            "Epoch [15/15], batch: [54780/59184, loss: 5.8321]\n",
            "Epoch [15/15], batch: [54781/59184, loss: 8.2053]\n",
            "Epoch [15/15], batch: [54782/59184, loss: 6.1925]\n",
            "Epoch [15/15], batch: [54783/59184, loss: 5.8094]\n",
            "Epoch [15/15], batch: [54784/59184, loss: 6.5419]\n",
            "Epoch [15/15], batch: [54785/59184, loss: 6.4931]\n",
            "Epoch [15/15], batch: [54786/59184, loss: 3.8128]\n",
            "Epoch [15/15], batch: [54787/59184, loss: 5.9084]\n",
            "Epoch [15/15], batch: [54788/59184, loss: 4.5940]\n",
            "Epoch [15/15], batch: [54789/59184, loss: 4.8665]\n",
            "Epoch [15/15], batch: [54790/59184, loss: 5.4095]\n",
            "Epoch [15/15], batch: [54791/59184, loss: 6.5254]\n",
            "Epoch [15/15], batch: [54792/59184, loss: 4.8521]\n",
            "Epoch [15/15], batch: [54793/59184, loss: 6.5379]\n",
            "Epoch [15/15], batch: [54794/59184, loss: 5.2031]\n",
            "Epoch [15/15], batch: [54795/59184, loss: 5.6197]\n",
            "Epoch [15/15], batch: [54796/59184, loss: 6.1213]\n",
            "Epoch [15/15], batch: [54797/59184, loss: 5.6044]\n",
            "Epoch [15/15], batch: [54798/59184, loss: 5.5181]\n",
            "Epoch [15/15], batch: [54799/59184, loss: 6.6477]\n",
            "Epoch [15/15], batch: [54800/59184, loss: 6.3913]\n",
            "Epoch [15/15], batch: [54801/59184, loss: 6.4494]\n",
            "Epoch [15/15], batch: [54802/59184, loss: 5.4763]\n",
            "Epoch [15/15], batch: [54803/59184, loss: 6.2185]\n",
            "Epoch [15/15], batch: [54804/59184, loss: 4.8444]\n",
            "Epoch [15/15], batch: [54805/59184, loss: 4.2959]\n",
            "Epoch [15/15], batch: [54806/59184, loss: 6.1354]\n",
            "Epoch [15/15], batch: [54807/59184, loss: 6.1289]\n",
            "Epoch [15/15], batch: [54808/59184, loss: 4.6266]\n",
            "Epoch [15/15], batch: [54809/59184, loss: 4.7044]\n",
            "Epoch [15/15], batch: [54810/59184, loss: 4.5911]\n",
            "Epoch [15/15], batch: [54811/59184, loss: 7.2059]\n",
            "Epoch [15/15], batch: [54812/59184, loss: 8.6771]\n",
            "Epoch [15/15], batch: [54813/59184, loss: 7.2425]\n",
            "Epoch [15/15], batch: [54814/59184, loss: 5.6521]\n",
            "Epoch [15/15], batch: [54815/59184, loss: 6.6651]\n",
            "Epoch [15/15], batch: [54816/59184, loss: 5.7476]\n",
            "Epoch [15/15], batch: [54817/59184, loss: 6.1639]\n",
            "Epoch [15/15], batch: [54818/59184, loss: 4.1689]\n",
            "Epoch [15/15], batch: [54819/59184, loss: 6.0238]\n",
            "Epoch [15/15], batch: [54820/59184, loss: 5.2826]\n",
            "Epoch [15/15], batch: [54821/59184, loss: 6.7714]\n",
            "Epoch [15/15], batch: [54822/59184, loss: 5.1784]\n",
            "Epoch [15/15], batch: [54823/59184, loss: 5.3794]\n",
            "Epoch [15/15], batch: [54824/59184, loss: 4.5183]\n",
            "Epoch [15/15], batch: [54825/59184, loss: 7.5848]\n",
            "Epoch [15/15], batch: [54826/59184, loss: 6.1404]\n",
            "Epoch [15/15], batch: [54827/59184, loss: 5.6567]\n",
            "Epoch [15/15], batch: [54828/59184, loss: 7.0366]\n",
            "Epoch [15/15], batch: [54829/59184, loss: 7.0441]\n",
            "Epoch [15/15], batch: [54830/59184, loss: 5.6727]\n",
            "Epoch [15/15], batch: [54831/59184, loss: 4.6816]\n",
            "Epoch [15/15], batch: [54832/59184, loss: 5.7132]\n",
            "Epoch [15/15], batch: [54833/59184, loss: 5.6647]\n",
            "Epoch [15/15], batch: [54834/59184, loss: 5.5692]\n",
            "Epoch [15/15], batch: [54835/59184, loss: 4.8636]\n",
            "Epoch [15/15], batch: [54836/59184, loss: 5.9751]\n",
            "Epoch [15/15], batch: [54837/59184, loss: 4.2417]\n",
            "Epoch [15/15], batch: [54838/59184, loss: 6.1459]\n",
            "Epoch [15/15], batch: [54839/59184, loss: 6.1082]\n",
            "Epoch [15/15], batch: [54840/59184, loss: 5.8646]\n",
            "Epoch [15/15], batch: [54841/59184, loss: 6.5490]\n",
            "Epoch [15/15], batch: [54842/59184, loss: 6.8588]\n",
            "Epoch [15/15], batch: [54843/59184, loss: 6.0627]\n",
            "Epoch [15/15], batch: [54844/59184, loss: 6.0008]\n",
            "Epoch [15/15], batch: [54845/59184, loss: 4.4239]\n",
            "Epoch [15/15], batch: [54846/59184, loss: 4.8684]\n",
            "Epoch [15/15], batch: [54847/59184, loss: 5.8973]\n",
            "Epoch [15/15], batch: [54848/59184, loss: 5.0007]\n",
            "Epoch [15/15], batch: [54849/59184, loss: 4.8090]\n",
            "Epoch [15/15], batch: [54850/59184, loss: 6.1550]\n",
            "Epoch [15/15], batch: [54851/59184, loss: 5.8143]\n",
            "Epoch [15/15], batch: [54852/59184, loss: 5.5727]\n",
            "Epoch [15/15], batch: [54853/59184, loss: 6.7643]\n",
            "Epoch [15/15], batch: [54854/59184, loss: 4.6032]\n",
            "Epoch [15/15], batch: [54855/59184, loss: 3.3767]\n",
            "Epoch [15/15], batch: [54856/59184, loss: 6.3917]\n",
            "Epoch [15/15], batch: [54857/59184, loss: 5.2953]\n",
            "Epoch [15/15], batch: [54858/59184, loss: 6.6642]\n",
            "Epoch [15/15], batch: [54859/59184, loss: 4.8463]\n",
            "Epoch [15/15], batch: [54860/59184, loss: 5.3396]\n",
            "Epoch [15/15], batch: [54861/59184, loss: 6.3351]\n",
            "Epoch [15/15], batch: [54862/59184, loss: 4.9005]\n",
            "Epoch [15/15], batch: [54863/59184, loss: 3.9732]\n",
            "Epoch [15/15], batch: [54864/59184, loss: 6.3971]\n",
            "Epoch [15/15], batch: [54865/59184, loss: 4.6579]\n",
            "Epoch [15/15], batch: [54866/59184, loss: 4.4719]\n",
            "Epoch [15/15], batch: [54867/59184, loss: 5.2204]\n",
            "Epoch [15/15], batch: [54868/59184, loss: 5.8294]\n",
            "Epoch [15/15], batch: [54869/59184, loss: 4.0338]\n",
            "Epoch [15/15], batch: [54870/59184, loss: 5.2505]\n",
            "Epoch [15/15], batch: [54871/59184, loss: 5.3559]\n",
            "Epoch [15/15], batch: [54872/59184, loss: 4.3911]\n",
            "Epoch [15/15], batch: [54873/59184, loss: 5.4322]\n",
            "Epoch [15/15], batch: [54874/59184, loss: 6.3157]\n",
            "Epoch [15/15], batch: [54875/59184, loss: 6.7635]\n",
            "Epoch [15/15], batch: [54876/59184, loss: 5.3954]\n",
            "Epoch [15/15], batch: [54877/59184, loss: 6.1857]\n",
            "Epoch [15/15], batch: [54878/59184, loss: 5.0077]\n",
            "Epoch [15/15], batch: [54879/59184, loss: 5.3873]\n",
            "Epoch [15/15], batch: [54880/59184, loss: 5.9613]\n",
            "Epoch [15/15], batch: [54881/59184, loss: 5.5592]\n",
            "Epoch [15/15], batch: [54882/59184, loss: 6.3325]\n",
            "Epoch [15/15], batch: [54883/59184, loss: 6.8822]\n",
            "Epoch [15/15], batch: [54884/59184, loss: 6.5950]\n",
            "Epoch [15/15], batch: [54885/59184, loss: 6.7091]\n",
            "Epoch [15/15], batch: [54886/59184, loss: 4.6353]\n",
            "Epoch [15/15], batch: [54887/59184, loss: 3.8795]\n",
            "Epoch [15/15], batch: [54888/59184, loss: 5.0733]\n",
            "Epoch [15/15], batch: [54889/59184, loss: 4.4792]\n",
            "Epoch [15/15], batch: [54890/59184, loss: 6.7949]\n",
            "Epoch [15/15], batch: [54891/59184, loss: 5.0627]\n",
            "Epoch [15/15], batch: [54892/59184, loss: 4.7168]\n",
            "Epoch [15/15], batch: [54893/59184, loss: 6.6694]\n",
            "Epoch [15/15], batch: [54894/59184, loss: 6.9655]\n",
            "Epoch [15/15], batch: [54895/59184, loss: 6.2780]\n",
            "Epoch [15/15], batch: [54896/59184, loss: 7.0431]\n",
            "Epoch [15/15], batch: [54897/59184, loss: 7.0745]\n",
            "Epoch [15/15], batch: [54898/59184, loss: 6.4201]\n",
            "Epoch [15/15], batch: [54899/59184, loss: 6.6781]\n",
            "Epoch [15/15], batch: [54900/59184, loss: 6.9509]\n",
            "Epoch [15/15], batch: [54901/59184, loss: 5.9543]\n",
            "Epoch [15/15], batch: [54902/59184, loss: 6.7396]\n",
            "Epoch [15/15], batch: [54903/59184, loss: 6.4423]\n",
            "Epoch [15/15], batch: [54904/59184, loss: 7.9292]\n",
            "Epoch [15/15], batch: [54905/59184, loss: 7.6995]\n",
            "Epoch [15/15], batch: [54906/59184, loss: 6.4964]\n",
            "Epoch [15/15], batch: [54907/59184, loss: 5.9373]\n",
            "Epoch [15/15], batch: [54908/59184, loss: 7.3363]\n",
            "Epoch [15/15], batch: [54909/59184, loss: 6.7655]\n",
            "Epoch [15/15], batch: [54910/59184, loss: 6.7879]\n",
            "Epoch [15/15], batch: [54911/59184, loss: 7.6632]\n",
            "Epoch [15/15], batch: [54912/59184, loss: 6.0909]\n",
            "Epoch [15/15], batch: [54913/59184, loss: 6.6476]\n",
            "Epoch [15/15], batch: [54914/59184, loss: 5.3067]\n",
            "Epoch [15/15], batch: [54915/59184, loss: 5.1323]\n",
            "Epoch [15/15], batch: [54916/59184, loss: 6.2027]\n",
            "Epoch [15/15], batch: [54917/59184, loss: 5.8124]\n",
            "Epoch [15/15], batch: [54918/59184, loss: 5.7783]\n",
            "Epoch [15/15], batch: [54919/59184, loss: 6.1522]\n",
            "Epoch [15/15], batch: [54920/59184, loss: 5.9558]\n",
            "Epoch [15/15], batch: [54921/59184, loss: 4.2526]\n",
            "Epoch [15/15], batch: [54922/59184, loss: 6.1314]\n",
            "Epoch [15/15], batch: [54923/59184, loss: 5.8062]\n",
            "Epoch [15/15], batch: [54924/59184, loss: 5.5157]\n",
            "Epoch [15/15], batch: [54925/59184, loss: 4.0068]\n",
            "Epoch [15/15], batch: [54926/59184, loss: 3.2559]\n",
            "Epoch [15/15], batch: [54927/59184, loss: 5.5974]\n",
            "Epoch [15/15], batch: [54928/59184, loss: 7.5371]\n",
            "Epoch [15/15], batch: [54929/59184, loss: 6.1210]\n",
            "Epoch [15/15], batch: [54930/59184, loss: 5.8998]\n",
            "Epoch [15/15], batch: [54931/59184, loss: 5.6432]\n",
            "Epoch [15/15], batch: [54932/59184, loss: 7.2432]\n",
            "Epoch [15/15], batch: [54933/59184, loss: 6.5043]\n",
            "Epoch [15/15], batch: [54934/59184, loss: 5.0139]\n",
            "Epoch [15/15], batch: [54935/59184, loss: 5.4655]\n",
            "Epoch [15/15], batch: [54936/59184, loss: 5.6459]\n",
            "Epoch [15/15], batch: [54937/59184, loss: 7.2958]\n",
            "Epoch [15/15], batch: [54938/59184, loss: 6.8143]\n",
            "Epoch [15/15], batch: [54939/59184, loss: 5.1477]\n",
            "Epoch [15/15], batch: [54940/59184, loss: 5.9168]\n",
            "Epoch [15/15], batch: [54941/59184, loss: 5.4983]\n",
            "Epoch [15/15], batch: [54942/59184, loss: 5.7169]\n",
            "Epoch [15/15], batch: [54943/59184, loss: 5.9074]\n",
            "Epoch [15/15], batch: [54944/59184, loss: 7.2550]\n",
            "Epoch [15/15], batch: [54945/59184, loss: 4.2568]\n",
            "Epoch [15/15], batch: [54946/59184, loss: 7.2640]\n",
            "Epoch [15/15], batch: [54947/59184, loss: 3.8394]\n",
            "Epoch [15/15], batch: [54948/59184, loss: 5.4537]\n",
            "Epoch [15/15], batch: [54949/59184, loss: 3.8809]\n",
            "Epoch [15/15], batch: [54950/59184, loss: 6.3301]\n",
            "Epoch [15/15], batch: [54951/59184, loss: 6.7399]\n",
            "Epoch [15/15], batch: [54952/59184, loss: 5.0127]\n",
            "Epoch [15/15], batch: [54953/59184, loss: 6.4531]\n",
            "Epoch [15/15], batch: [54954/59184, loss: 6.7201]\n",
            "Epoch [15/15], batch: [54955/59184, loss: 6.2808]\n",
            "Epoch [15/15], batch: [54956/59184, loss: 5.3044]\n",
            "Epoch [15/15], batch: [54957/59184, loss: 5.0831]\n",
            "Epoch [15/15], batch: [54958/59184, loss: 5.2752]\n",
            "Epoch [15/15], batch: [54959/59184, loss: 5.7260]\n",
            "Epoch [15/15], batch: [54960/59184, loss: 5.7058]\n",
            "Epoch [15/15], batch: [54961/59184, loss: 6.1688]\n",
            "Epoch [15/15], batch: [54962/59184, loss: 6.5828]\n",
            "Epoch [15/15], batch: [54963/59184, loss: 4.6375]\n",
            "Epoch [15/15], batch: [54964/59184, loss: 4.3142]\n",
            "Epoch [15/15], batch: [54965/59184, loss: 5.2258]\n",
            "Epoch [15/15], batch: [54966/59184, loss: 5.6989]\n",
            "Epoch [15/15], batch: [54967/59184, loss: 6.2240]\n",
            "Epoch [15/15], batch: [54968/59184, loss: 5.9976]\n",
            "Epoch [15/15], batch: [54969/59184, loss: 6.5904]\n",
            "Epoch [15/15], batch: [54970/59184, loss: 6.7445]\n",
            "Epoch [15/15], batch: [54971/59184, loss: 6.0186]\n",
            "Epoch [15/15], batch: [54972/59184, loss: 3.4461]\n",
            "Epoch [15/15], batch: [54973/59184, loss: 4.6639]\n",
            "Epoch [15/15], batch: [54974/59184, loss: 5.0635]\n",
            "Epoch [15/15], batch: [54975/59184, loss: 5.0402]\n",
            "Epoch [15/15], batch: [54976/59184, loss: 5.0128]\n",
            "Epoch [15/15], batch: [54977/59184, loss: 4.9435]\n",
            "Epoch [15/15], batch: [54978/59184, loss: 5.0128]\n",
            "Epoch [15/15], batch: [54979/59184, loss: 5.4595]\n",
            "Epoch [15/15], batch: [54980/59184, loss: 5.0387]\n",
            "Epoch [15/15], batch: [54981/59184, loss: 5.5671]\n",
            "Epoch [15/15], batch: [54982/59184, loss: 6.2171]\n",
            "Epoch [15/15], batch: [54983/59184, loss: 6.5729]\n",
            "Epoch [15/15], batch: [54984/59184, loss: 5.0539]\n",
            "Epoch [15/15], batch: [54985/59184, loss: 6.3023]\n",
            "Epoch [15/15], batch: [54986/59184, loss: 6.8372]\n",
            "Epoch [15/15], batch: [54987/59184, loss: 6.2266]\n",
            "Epoch [15/15], batch: [54988/59184, loss: 7.0714]\n",
            "Epoch [15/15], batch: [54989/59184, loss: 7.3722]\n",
            "Epoch [15/15], batch: [54990/59184, loss: 5.8049]\n",
            "Epoch [15/15], batch: [54991/59184, loss: 5.4232]\n",
            "Epoch [15/15], batch: [54992/59184, loss: 4.5037]\n",
            "Epoch [15/15], batch: [54993/59184, loss: 6.4369]\n",
            "Epoch [15/15], batch: [54994/59184, loss: 5.8569]\n",
            "Epoch [15/15], batch: [54995/59184, loss: 5.5378]\n",
            "Epoch [15/15], batch: [54996/59184, loss: 6.3141]\n",
            "Epoch [15/15], batch: [54997/59184, loss: 3.9147]\n",
            "Epoch [15/15], batch: [54998/59184, loss: 6.0073]\n",
            "Epoch [15/15], batch: [54999/59184, loss: 5.5544]\n",
            "Epoch [15/15], batch: [55000/59184, loss: 4.0971]\n",
            "Epoch [15/15], batch: [55001/59184, loss: 5.2257]\n",
            "Epoch [15/15], batch: [55002/59184, loss: 7.2896]\n",
            "Epoch [15/15], batch: [55003/59184, loss: 6.9534]\n",
            "Epoch [15/15], batch: [55004/59184, loss: 6.6026]\n",
            "Epoch [15/15], batch: [55005/59184, loss: 5.9213]\n",
            "Epoch [15/15], batch: [55006/59184, loss: 6.9977]\n",
            "Epoch [15/15], batch: [55007/59184, loss: 4.6134]\n",
            "Epoch [15/15], batch: [55008/59184, loss: 5.4745]\n",
            "Epoch [15/15], batch: [55009/59184, loss: 5.4178]\n",
            "Epoch [15/15], batch: [55010/59184, loss: 6.9463]\n",
            "Epoch [15/15], batch: [55011/59184, loss: 3.2837]\n",
            "Epoch [15/15], batch: [55012/59184, loss: 3.8235]\n",
            "Epoch [15/15], batch: [55013/59184, loss: 5.9072]\n",
            "Epoch [15/15], batch: [55014/59184, loss: 4.4630]\n",
            "Epoch [15/15], batch: [55015/59184, loss: 5.4443]\n",
            "Epoch [15/15], batch: [55016/59184, loss: 4.0003]\n",
            "Epoch [15/15], batch: [55017/59184, loss: 6.0296]\n",
            "Epoch [15/15], batch: [55018/59184, loss: 7.4790]\n",
            "Epoch [15/15], batch: [55019/59184, loss: 7.8713]\n",
            "Epoch [15/15], batch: [55020/59184, loss: 5.7016]\n",
            "Epoch [15/15], batch: [55021/59184, loss: 6.3171]\n",
            "Epoch [15/15], batch: [55022/59184, loss: 7.2015]\n",
            "Epoch [15/15], batch: [55023/59184, loss: 5.0118]\n",
            "Epoch [15/15], batch: [55024/59184, loss: 4.8650]\n",
            "Epoch [15/15], batch: [55025/59184, loss: 6.5003]\n",
            "Epoch [15/15], batch: [55026/59184, loss: 8.1882]\n",
            "Epoch [15/15], batch: [55027/59184, loss: 6.5574]\n",
            "Epoch [15/15], batch: [55028/59184, loss: 7.2535]\n",
            "Epoch [15/15], batch: [55029/59184, loss: 5.4045]\n",
            "Epoch [15/15], batch: [55030/59184, loss: 6.9065]\n",
            "Epoch [15/15], batch: [55031/59184, loss: 7.9562]\n",
            "Epoch [15/15], batch: [55032/59184, loss: 6.3914]\n",
            "Epoch [15/15], batch: [55033/59184, loss: 6.4853]\n",
            "Epoch [15/15], batch: [55034/59184, loss: 7.1612]\n",
            "Epoch [15/15], batch: [55035/59184, loss: 6.9148]\n",
            "Epoch [15/15], batch: [55036/59184, loss: 6.5586]\n",
            "Epoch [15/15], batch: [55037/59184, loss: 6.6234]\n",
            "Epoch [15/15], batch: [55038/59184, loss: 5.4536]\n",
            "Epoch [15/15], batch: [55039/59184, loss: 6.7979]\n",
            "Epoch [15/15], batch: [55040/59184, loss: 6.5952]\n",
            "Epoch [15/15], batch: [55041/59184, loss: 5.6721]\n",
            "Epoch [15/15], batch: [55042/59184, loss: 6.8155]\n",
            "Epoch [15/15], batch: [55043/59184, loss: 6.6030]\n",
            "Epoch [15/15], batch: [55044/59184, loss: 6.7542]\n",
            "Epoch [15/15], batch: [55045/59184, loss: 6.2048]\n",
            "Epoch [15/15], batch: [55046/59184, loss: 7.0091]\n",
            "Epoch [15/15], batch: [55047/59184, loss: 6.8856]\n",
            "Epoch [15/15], batch: [55048/59184, loss: 7.7502]\n",
            "Epoch [15/15], batch: [55049/59184, loss: 7.6847]\n",
            "Epoch [15/15], batch: [55050/59184, loss: 6.9548]\n",
            "Epoch [15/15], batch: [55051/59184, loss: 7.1295]\n",
            "Epoch [15/15], batch: [55052/59184, loss: 5.2911]\n",
            "Epoch [15/15], batch: [55053/59184, loss: 7.4875]\n",
            "Epoch [15/15], batch: [55054/59184, loss: 8.2470]\n",
            "Epoch [15/15], batch: [55055/59184, loss: 7.6835]\n",
            "Epoch [15/15], batch: [55056/59184, loss: 6.5718]\n",
            "Epoch [15/15], batch: [55057/59184, loss: 6.4292]\n",
            "Epoch [15/15], batch: [55058/59184, loss: 6.8440]\n",
            "Epoch [15/15], batch: [55059/59184, loss: 6.7471]\n",
            "Epoch [15/15], batch: [55060/59184, loss: 7.1853]\n",
            "Epoch [15/15], batch: [55061/59184, loss: 6.7004]\n",
            "Epoch [15/15], batch: [55062/59184, loss: 5.9619]\n",
            "Epoch [15/15], batch: [55063/59184, loss: 7.1338]\n",
            "Epoch [15/15], batch: [55064/59184, loss: 7.2766]\n",
            "Epoch [15/15], batch: [55065/59184, loss: 7.7132]\n",
            "Epoch [15/15], batch: [55066/59184, loss: 6.7459]\n",
            "Epoch [15/15], batch: [55067/59184, loss: 6.3469]\n",
            "Epoch [15/15], batch: [55068/59184, loss: 5.1154]\n",
            "Epoch [15/15], batch: [55069/59184, loss: 7.8391]\n",
            "Epoch [15/15], batch: [55070/59184, loss: 5.8208]\n",
            "Epoch [15/15], batch: [55071/59184, loss: 6.6821]\n",
            "Epoch [15/15], batch: [55072/59184, loss: 6.9054]\n",
            "Epoch [15/15], batch: [55073/59184, loss: 6.8772]\n",
            "Epoch [15/15], batch: [55074/59184, loss: 6.0832]\n",
            "Epoch [15/15], batch: [55075/59184, loss: 6.0865]\n",
            "Epoch [15/15], batch: [55076/59184, loss: 6.7072]\n",
            "Epoch [15/15], batch: [55077/59184, loss: 4.5171]\n",
            "Epoch [15/15], batch: [55078/59184, loss: 6.3485]\n",
            "Epoch [15/15], batch: [55079/59184, loss: 7.1589]\n",
            "Epoch [15/15], batch: [55080/59184, loss: 6.8721]\n",
            "Epoch [15/15], batch: [55081/59184, loss: 5.9079]\n",
            "Epoch [15/15], batch: [55082/59184, loss: 5.3079]\n",
            "Epoch [15/15], batch: [55083/59184, loss: 7.1136]\n",
            "Epoch [15/15], batch: [55084/59184, loss: 5.8800]\n",
            "Epoch [15/15], batch: [55085/59184, loss: 5.2300]\n",
            "Epoch [15/15], batch: [55086/59184, loss: 7.1759]\n",
            "Epoch [15/15], batch: [55087/59184, loss: 5.8727]\n",
            "Epoch [15/15], batch: [55088/59184, loss: 3.6591]\n",
            "Epoch [15/15], batch: [55089/59184, loss: 4.4362]\n",
            "Epoch [15/15], batch: [55090/59184, loss: 5.8770]\n",
            "Epoch [15/15], batch: [55091/59184, loss: 5.3360]\n",
            "Epoch [15/15], batch: [55092/59184, loss: 5.5225]\n",
            "Epoch [15/15], batch: [55093/59184, loss: 6.9569]\n",
            "Epoch [15/15], batch: [55094/59184, loss: 5.6255]\n",
            "Epoch [15/15], batch: [55095/59184, loss: 5.4716]\n",
            "Epoch [15/15], batch: [55096/59184, loss: 6.3653]\n",
            "Epoch [15/15], batch: [55097/59184, loss: 4.2626]\n",
            "Epoch [15/15], batch: [55098/59184, loss: 4.2036]\n",
            "Epoch [15/15], batch: [55099/59184, loss: 6.4412]\n",
            "Epoch [15/15], batch: [55100/59184, loss: 4.4028]\n",
            "Epoch [15/15], batch: [55101/59184, loss: 5.1636]\n",
            "Epoch [15/15], batch: [55102/59184, loss: 6.8888]\n",
            "Epoch [15/15], batch: [55103/59184, loss: 6.7049]\n",
            "Epoch [15/15], batch: [55104/59184, loss: 7.9706]\n",
            "Epoch [15/15], batch: [55105/59184, loss: 7.0130]\n",
            "Epoch [15/15], batch: [55106/59184, loss: 6.6595]\n",
            "Epoch [15/15], batch: [55107/59184, loss: 5.5078]\n",
            "Epoch [15/15], batch: [55108/59184, loss: 6.1496]\n",
            "Epoch [15/15], batch: [55109/59184, loss: 6.1270]\n",
            "Epoch [15/15], batch: [55110/59184, loss: 6.0047]\n",
            "Epoch [15/15], batch: [55111/59184, loss: 5.0658]\n",
            "Epoch [15/15], batch: [55112/59184, loss: 4.6007]\n",
            "Epoch [15/15], batch: [55113/59184, loss: 4.7439]\n",
            "Epoch [15/15], batch: [55114/59184, loss: 4.9736]\n",
            "Epoch [15/15], batch: [55115/59184, loss: 5.4503]\n",
            "Epoch [15/15], batch: [55116/59184, loss: 3.7050]\n",
            "Epoch [15/15], batch: [55117/59184, loss: 5.7156]\n",
            "Epoch [15/15], batch: [55118/59184, loss: 6.8001]\n",
            "Epoch [15/15], batch: [55119/59184, loss: 4.9940]\n",
            "Epoch [15/15], batch: [55120/59184, loss: 5.9961]\n",
            "Epoch [15/15], batch: [55121/59184, loss: 4.2670]\n",
            "Epoch [15/15], batch: [55122/59184, loss: 5.8549]\n",
            "Epoch [15/15], batch: [55123/59184, loss: 6.2062]\n",
            "Epoch [15/15], batch: [55124/59184, loss: 6.9506]\n",
            "Epoch [15/15], batch: [55125/59184, loss: 6.5237]\n",
            "Epoch [15/15], batch: [55126/59184, loss: 6.7292]\n",
            "Epoch [15/15], batch: [55127/59184, loss: 6.4255]\n",
            "Epoch [15/15], batch: [55128/59184, loss: 7.1727]\n",
            "Epoch [15/15], batch: [55129/59184, loss: 3.6760]\n",
            "Epoch [15/15], batch: [55130/59184, loss: 4.9225]\n",
            "Epoch [15/15], batch: [55131/59184, loss: 6.1856]\n",
            "Epoch [15/15], batch: [55132/59184, loss: 4.2676]\n",
            "Epoch [15/15], batch: [55133/59184, loss: 5.5094]\n",
            "Epoch [15/15], batch: [55134/59184, loss: 5.7226]\n",
            "Epoch [15/15], batch: [55135/59184, loss: 6.2691]\n",
            "Epoch [15/15], batch: [55136/59184, loss: 5.5940]\n",
            "Epoch [15/15], batch: [55137/59184, loss: 4.8533]\n",
            "Epoch [15/15], batch: [55138/59184, loss: 4.5423]\n",
            "Epoch [15/15], batch: [55139/59184, loss: 5.8404]\n",
            "Epoch [15/15], batch: [55140/59184, loss: 6.9820]\n",
            "Epoch [15/15], batch: [55141/59184, loss: 7.5068]\n",
            "Epoch [15/15], batch: [55142/59184, loss: 6.6439]\n",
            "Epoch [15/15], batch: [55143/59184, loss: 5.8743]\n",
            "Epoch [15/15], batch: [55144/59184, loss: 5.4474]\n",
            "Epoch [15/15], batch: [55145/59184, loss: 6.0041]\n",
            "Epoch [15/15], batch: [55146/59184, loss: 6.0331]\n",
            "Epoch [15/15], batch: [55147/59184, loss: 5.9049]\n",
            "Epoch [15/15], batch: [55148/59184, loss: 6.0171]\n",
            "Epoch [15/15], batch: [55149/59184, loss: 5.2050]\n",
            "Epoch [15/15], batch: [55150/59184, loss: 6.6916]\n",
            "Epoch [15/15], batch: [55151/59184, loss: 5.4261]\n",
            "Epoch [15/15], batch: [55152/59184, loss: 6.3690]\n",
            "Epoch [15/15], batch: [55153/59184, loss: 4.2215]\n",
            "Epoch [15/15], batch: [55154/59184, loss: 4.8782]\n",
            "Epoch [15/15], batch: [55155/59184, loss: 5.3400]\n",
            "Epoch [15/15], batch: [55156/59184, loss: 5.1035]\n",
            "Epoch [15/15], batch: [55157/59184, loss: 4.3796]\n",
            "Epoch [15/15], batch: [55158/59184, loss: 6.4487]\n",
            "Epoch [15/15], batch: [55159/59184, loss: 5.5065]\n",
            "Epoch [15/15], batch: [55160/59184, loss: 5.4655]\n",
            "Epoch [15/15], batch: [55161/59184, loss: 4.3926]\n",
            "Epoch [15/15], batch: [55162/59184, loss: 5.5556]\n",
            "Epoch [15/15], batch: [55163/59184, loss: 5.3008]\n",
            "Epoch [15/15], batch: [55164/59184, loss: 5.9837]\n",
            "Epoch [15/15], batch: [55165/59184, loss: 4.2867]\n",
            "Epoch [15/15], batch: [55166/59184, loss: 6.2255]\n",
            "Epoch [15/15], batch: [55167/59184, loss: 6.6284]\n",
            "Epoch [15/15], batch: [55168/59184, loss: 6.6373]\n",
            "Epoch [15/15], batch: [55169/59184, loss: 6.4524]\n",
            "Epoch [15/15], batch: [55170/59184, loss: 5.4976]\n",
            "Epoch [15/15], batch: [55171/59184, loss: 4.9795]\n",
            "Epoch [15/15], batch: [55172/59184, loss: 5.0977]\n",
            "Epoch [15/15], batch: [55173/59184, loss: 5.8378]\n",
            "Epoch [15/15], batch: [55174/59184, loss: 6.0297]\n",
            "Epoch [15/15], batch: [55175/59184, loss: 5.4691]\n",
            "Epoch [15/15], batch: [55176/59184, loss: 5.5413]\n",
            "Epoch [15/15], batch: [55177/59184, loss: 5.1313]\n",
            "Epoch [15/15], batch: [55178/59184, loss: 5.3928]\n",
            "Epoch [15/15], batch: [55179/59184, loss: 6.1322]\n",
            "Epoch [15/15], batch: [55180/59184, loss: 7.1978]\n",
            "Epoch [15/15], batch: [55181/59184, loss: 7.0551]\n",
            "Epoch [15/15], batch: [55182/59184, loss: 7.1360]\n",
            "Epoch [15/15], batch: [55183/59184, loss: 5.8401]\n",
            "Epoch [15/15], batch: [55184/59184, loss: 6.6860]\n",
            "Epoch [15/15], batch: [55185/59184, loss: 6.4290]\n",
            "Epoch [15/15], batch: [55186/59184, loss: 7.1617]\n",
            "Epoch [15/15], batch: [55187/59184, loss: 6.4838]\n",
            "Epoch [15/15], batch: [55188/59184, loss: 5.5664]\n",
            "Epoch [15/15], batch: [55189/59184, loss: 5.6890]\n",
            "Epoch [15/15], batch: [55190/59184, loss: 7.1141]\n",
            "Epoch [15/15], batch: [55191/59184, loss: 6.5912]\n",
            "Epoch [15/15], batch: [55192/59184, loss: 7.4759]\n",
            "Epoch [15/15], batch: [55193/59184, loss: 6.9508]\n",
            "Epoch [15/15], batch: [55194/59184, loss: 6.7846]\n",
            "Epoch [15/15], batch: [55195/59184, loss: 5.7100]\n",
            "Epoch [15/15], batch: [55196/59184, loss: 5.5788]\n",
            "Epoch [15/15], batch: [55197/59184, loss: 7.9136]\n",
            "Epoch [15/15], batch: [55198/59184, loss: 5.0164]\n",
            "Epoch [15/15], batch: [55199/59184, loss: 6.9165]\n",
            "Epoch [15/15], batch: [55200/59184, loss: 7.0252]\n",
            "Epoch [15/15], batch: [55201/59184, loss: 5.8265]\n",
            "Epoch [15/15], batch: [55202/59184, loss: 5.9044]\n",
            "Epoch [15/15], batch: [55203/59184, loss: 6.6283]\n",
            "Epoch [15/15], batch: [55204/59184, loss: 5.2625]\n",
            "Epoch [15/15], batch: [55205/59184, loss: 6.4318]\n",
            "Epoch [15/15], batch: [55206/59184, loss: 3.4902]\n",
            "Epoch [15/15], batch: [55207/59184, loss: 5.4911]\n",
            "Epoch [15/15], batch: [55208/59184, loss: 6.0911]\n",
            "Epoch [15/15], batch: [55209/59184, loss: 6.2107]\n",
            "Epoch [15/15], batch: [55210/59184, loss: 4.8832]\n",
            "Epoch [15/15], batch: [55211/59184, loss: 5.5038]\n",
            "Epoch [15/15], batch: [55212/59184, loss: 4.9664]\n",
            "Epoch [15/15], batch: [55213/59184, loss: 4.4019]\n",
            "Epoch [15/15], batch: [55214/59184, loss: 5.0069]\n",
            "Epoch [15/15], batch: [55215/59184, loss: 5.3850]\n",
            "Epoch [15/15], batch: [55216/59184, loss: 5.2230]\n",
            "Epoch [15/15], batch: [55217/59184, loss: 5.2763]\n",
            "Epoch [15/15], batch: [55218/59184, loss: 6.2131]\n",
            "Epoch [15/15], batch: [55219/59184, loss: 4.7532]\n",
            "Epoch [15/15], batch: [55220/59184, loss: 5.2387]\n",
            "Epoch [15/15], batch: [55221/59184, loss: 5.1928]\n",
            "Epoch [15/15], batch: [55222/59184, loss: 5.9363]\n",
            "Epoch [15/15], batch: [55223/59184, loss: 5.3404]\n",
            "Epoch [15/15], batch: [55224/59184, loss: 4.8850]\n",
            "Epoch [15/15], batch: [55225/59184, loss: 3.4604]\n",
            "Epoch [15/15], batch: [55226/59184, loss: 5.4545]\n",
            "Epoch [15/15], batch: [55227/59184, loss: 6.2817]\n",
            "Epoch [15/15], batch: [55228/59184, loss: 4.4871]\n",
            "Epoch [15/15], batch: [55229/59184, loss: 5.8005]\n",
            "Epoch [15/15], batch: [55230/59184, loss: 5.5100]\n",
            "Epoch [15/15], batch: [55231/59184, loss: 4.2615]\n",
            "Epoch [15/15], batch: [55232/59184, loss: 6.8310]\n",
            "Epoch [15/15], batch: [55233/59184, loss: 5.7945]\n",
            "Epoch [15/15], batch: [55234/59184, loss: 7.0755]\n",
            "Epoch [15/15], batch: [55235/59184, loss: 6.2444]\n",
            "Epoch [15/15], batch: [55236/59184, loss: 4.5404]\n",
            "Epoch [15/15], batch: [55237/59184, loss: 4.7739]\n",
            "Epoch [15/15], batch: [55238/59184, loss: 4.4972]\n",
            "Epoch [15/15], batch: [55239/59184, loss: 4.9308]\n",
            "Epoch [15/15], batch: [55240/59184, loss: 4.8182]\n",
            "Epoch [15/15], batch: [55241/59184, loss: 5.0253]\n",
            "Epoch [15/15], batch: [55242/59184, loss: 5.8213]\n",
            "Epoch [15/15], batch: [55243/59184, loss: 4.4035]\n",
            "Epoch [15/15], batch: [55244/59184, loss: 3.9294]\n",
            "Epoch [15/15], batch: [55245/59184, loss: 5.5059]\n",
            "Epoch [15/15], batch: [55246/59184, loss: 5.4937]\n",
            "Epoch [15/15], batch: [55247/59184, loss: 4.2688]\n",
            "Epoch [15/15], batch: [55248/59184, loss: 5.2557]\n",
            "Epoch [15/15], batch: [55249/59184, loss: 4.1824]\n",
            "Epoch [15/15], batch: [55250/59184, loss: 5.2270]\n",
            "Epoch [15/15], batch: [55251/59184, loss: 4.8516]\n",
            "Epoch [15/15], batch: [55252/59184, loss: 5.2439]\n",
            "Epoch [15/15], batch: [55253/59184, loss: 7.0512]\n",
            "Epoch [15/15], batch: [55254/59184, loss: 5.3763]\n",
            "Epoch [15/15], batch: [55255/59184, loss: 6.0032]\n",
            "Epoch [15/15], batch: [55256/59184, loss: 3.5891]\n",
            "Epoch [15/15], batch: [55257/59184, loss: 5.8202]\n",
            "Epoch [15/15], batch: [55258/59184, loss: 4.9884]\n",
            "Epoch [15/15], batch: [55259/59184, loss: 3.6542]\n",
            "Epoch [15/15], batch: [55260/59184, loss: 2.8423]\n",
            "Epoch [15/15], batch: [55261/59184, loss: 6.4481]\n",
            "Epoch [15/15], batch: [55262/59184, loss: 4.2610]\n",
            "Epoch [15/15], batch: [55263/59184, loss: 5.1004]\n",
            "Epoch [15/15], batch: [55264/59184, loss: 7.3767]\n",
            "Epoch [15/15], batch: [55265/59184, loss: 7.3990]\n",
            "Epoch [15/15], batch: [55266/59184, loss: 3.7974]\n",
            "Epoch [15/15], batch: [55267/59184, loss: 5.4362]\n",
            "Epoch [15/15], batch: [55268/59184, loss: 4.8032]\n",
            "Epoch [15/15], batch: [55269/59184, loss: 5.5919]\n",
            "Epoch [15/15], batch: [55270/59184, loss: 4.4109]\n",
            "Epoch [15/15], batch: [55271/59184, loss: 5.7573]\n",
            "Epoch [15/15], batch: [55272/59184, loss: 5.5499]\n",
            "Epoch [15/15], batch: [55273/59184, loss: 2.9269]\n",
            "Epoch [15/15], batch: [55274/59184, loss: 6.4703]\n",
            "Epoch [15/15], batch: [55275/59184, loss: 6.0748]\n",
            "Epoch [15/15], batch: [55276/59184, loss: 5.3094]\n",
            "Epoch [15/15], batch: [55277/59184, loss: 7.3529]\n",
            "Epoch [15/15], batch: [55278/59184, loss: 4.8429]\n",
            "Epoch [15/15], batch: [55279/59184, loss: 6.8277]\n",
            "Epoch [15/15], batch: [55280/59184, loss: 6.3783]\n",
            "Epoch [15/15], batch: [55281/59184, loss: 4.4877]\n",
            "Epoch [15/15], batch: [55282/59184, loss: 6.8135]\n",
            "Epoch [15/15], batch: [55283/59184, loss: 5.5470]\n",
            "Epoch [15/15], batch: [55284/59184, loss: 6.3332]\n",
            "Epoch [15/15], batch: [55285/59184, loss: 6.6816]\n",
            "Epoch [15/15], batch: [55286/59184, loss: 6.4063]\n",
            "Epoch [15/15], batch: [55287/59184, loss: 3.8880]\n",
            "Epoch [15/15], batch: [55288/59184, loss: 6.7939]\n",
            "Epoch [15/15], batch: [55289/59184, loss: 5.8037]\n",
            "Epoch [15/15], batch: [55290/59184, loss: 4.7420]\n",
            "Epoch [15/15], batch: [55291/59184, loss: 3.9568]\n",
            "Epoch [15/15], batch: [55292/59184, loss: 4.7927]\n",
            "Epoch [15/15], batch: [55293/59184, loss: 5.0266]\n",
            "Epoch [15/15], batch: [55294/59184, loss: 3.8617]\n",
            "Epoch [15/15], batch: [55295/59184, loss: 5.2384]\n",
            "Epoch [15/15], batch: [55296/59184, loss: 5.9454]\n",
            "Epoch [15/15], batch: [55297/59184, loss: 5.4317]\n",
            "Epoch [15/15], batch: [55298/59184, loss: 6.6198]\n",
            "Epoch [15/15], batch: [55299/59184, loss: 6.6274]\n",
            "Epoch [15/15], batch: [55300/59184, loss: 6.0144]\n",
            "Epoch [15/15], batch: [55301/59184, loss: 5.9407]\n",
            "Epoch [15/15], batch: [55302/59184, loss: 6.6327]\n",
            "Epoch [15/15], batch: [55303/59184, loss: 7.1237]\n",
            "Epoch [15/15], batch: [55304/59184, loss: 6.1627]\n",
            "Epoch [15/15], batch: [55305/59184, loss: 6.1967]\n",
            "Epoch [15/15], batch: [55306/59184, loss: 5.6238]\n",
            "Epoch [15/15], batch: [55307/59184, loss: 6.6274]\n",
            "Epoch [15/15], batch: [55308/59184, loss: 7.7473]\n",
            "Epoch [15/15], batch: [55309/59184, loss: 6.3627]\n",
            "Epoch [15/15], batch: [55310/59184, loss: 5.9910]\n",
            "Epoch [15/15], batch: [55311/59184, loss: 6.3225]\n",
            "Epoch [15/15], batch: [55312/59184, loss: 4.5553]\n",
            "Epoch [15/15], batch: [55313/59184, loss: 5.0583]\n",
            "Epoch [15/15], batch: [55314/59184, loss: 4.3944]\n",
            "Epoch [15/15], batch: [55315/59184, loss: 4.4401]\n",
            "Epoch [15/15], batch: [55316/59184, loss: 5.8133]\n",
            "Epoch [15/15], batch: [55317/59184, loss: 5.6568]\n",
            "Epoch [15/15], batch: [55318/59184, loss: 3.5701]\n",
            "Epoch [15/15], batch: [55319/59184, loss: 4.8932]\n",
            "Epoch [15/15], batch: [55320/59184, loss: 5.1408]\n",
            "Epoch [15/15], batch: [55321/59184, loss: 4.8699]\n",
            "Epoch [15/15], batch: [55322/59184, loss: 4.7167]\n",
            "Epoch [15/15], batch: [55323/59184, loss: 5.6738]\n",
            "Epoch [15/15], batch: [55324/59184, loss: 7.2171]\n",
            "Epoch [15/15], batch: [55325/59184, loss: 5.9072]\n",
            "Epoch [15/15], batch: [55326/59184, loss: 6.3281]\n",
            "Epoch [15/15], batch: [55327/59184, loss: 5.5410]\n",
            "Epoch [15/15], batch: [55328/59184, loss: 4.4805]\n",
            "Epoch [15/15], batch: [55329/59184, loss: 4.5185]\n",
            "Epoch [15/15], batch: [55330/59184, loss: 5.3327]\n",
            "Epoch [15/15], batch: [55331/59184, loss: 4.0301]\n",
            "Epoch [15/15], batch: [55332/59184, loss: 5.3720]\n",
            "Epoch [15/15], batch: [55333/59184, loss: 5.4123]\n",
            "Epoch [15/15], batch: [55334/59184, loss: 6.1994]\n",
            "Epoch [15/15], batch: [55335/59184, loss: 5.5518]\n",
            "Epoch [15/15], batch: [55336/59184, loss: 4.7134]\n",
            "Epoch [15/15], batch: [55337/59184, loss: 7.8728]\n",
            "Epoch [15/15], batch: [55338/59184, loss: 5.7560]\n",
            "Epoch [15/15], batch: [55339/59184, loss: 6.3346]\n",
            "Epoch [15/15], batch: [55340/59184, loss: 6.0756]\n",
            "Epoch [15/15], batch: [55341/59184, loss: 5.7561]\n",
            "Epoch [15/15], batch: [55342/59184, loss: 6.9002]\n",
            "Epoch [15/15], batch: [55343/59184, loss: 5.6204]\n",
            "Epoch [15/15], batch: [55344/59184, loss: 5.9383]\n",
            "Epoch [15/15], batch: [55345/59184, loss: 5.1805]\n",
            "Epoch [15/15], batch: [55346/59184, loss: 5.1858]\n",
            "Epoch [15/15], batch: [55347/59184, loss: 3.5999]\n",
            "Epoch [15/15], batch: [55348/59184, loss: 5.9455]\n",
            "Epoch [15/15], batch: [55349/59184, loss: 5.6577]\n",
            "Epoch [15/15], batch: [55350/59184, loss: 5.7190]\n",
            "Epoch [15/15], batch: [55351/59184, loss: 5.8153]\n",
            "Epoch [15/15], batch: [55352/59184, loss: 4.9965]\n",
            "Epoch [15/15], batch: [55353/59184, loss: 5.0134]\n",
            "Epoch [15/15], batch: [55354/59184, loss: 6.6561]\n",
            "Epoch [15/15], batch: [55355/59184, loss: 6.0523]\n",
            "Epoch [15/15], batch: [55356/59184, loss: 5.4084]\n",
            "Epoch [15/15], batch: [55357/59184, loss: 4.4371]\n",
            "Epoch [15/15], batch: [55358/59184, loss: 6.2066]\n",
            "Epoch [15/15], batch: [55359/59184, loss: 5.8052]\n",
            "Epoch [15/15], batch: [55360/59184, loss: 4.3937]\n",
            "Epoch [15/15], batch: [55361/59184, loss: 5.2175]\n",
            "Epoch [15/15], batch: [55362/59184, loss: 5.1110]\n",
            "Epoch [15/15], batch: [55363/59184, loss: 6.2965]\n",
            "Epoch [15/15], batch: [55364/59184, loss: 4.7051]\n",
            "Epoch [15/15], batch: [55365/59184, loss: 6.3803]\n",
            "Epoch [15/15], batch: [55366/59184, loss: 6.6062]\n",
            "Epoch [15/15], batch: [55367/59184, loss: 3.8429]\n",
            "Epoch [15/15], batch: [55368/59184, loss: 5.4980]\n",
            "Epoch [15/15], batch: [55369/59184, loss: 4.3793]\n",
            "Epoch [15/15], batch: [55370/59184, loss: 4.8844]\n",
            "Epoch [15/15], batch: [55371/59184, loss: 4.6871]\n",
            "Epoch [15/15], batch: [55372/59184, loss: 6.4147]\n",
            "Epoch [15/15], batch: [55373/59184, loss: 5.4619]\n",
            "Epoch [15/15], batch: [55374/59184, loss: 5.1284]\n",
            "Epoch [15/15], batch: [55375/59184, loss: 5.2608]\n",
            "Epoch [15/15], batch: [55376/59184, loss: 6.0137]\n",
            "Epoch [15/15], batch: [55377/59184, loss: 4.3132]\n",
            "Epoch [15/15], batch: [55378/59184, loss: 4.5755]\n",
            "Epoch [15/15], batch: [55379/59184, loss: 6.3831]\n",
            "Epoch [15/15], batch: [55380/59184, loss: 5.3334]\n",
            "Epoch [15/15], batch: [55381/59184, loss: 5.8765]\n",
            "Epoch [15/15], batch: [55382/59184, loss: 5.3279]\n",
            "Epoch [15/15], batch: [55383/59184, loss: 5.1819]\n",
            "Epoch [15/15], batch: [55384/59184, loss: 5.0542]\n",
            "Epoch [15/15], batch: [55385/59184, loss: 5.3625]\n",
            "Epoch [15/15], batch: [55386/59184, loss: 5.6859]\n",
            "Epoch [15/15], batch: [55387/59184, loss: 6.4646]\n",
            "Epoch [15/15], batch: [55388/59184, loss: 4.1884]\n",
            "Epoch [15/15], batch: [55389/59184, loss: 5.3717]\n",
            "Epoch [15/15], batch: [55390/59184, loss: 6.3885]\n",
            "Epoch [15/15], batch: [55391/59184, loss: 6.7790]\n",
            "Epoch [15/15], batch: [55392/59184, loss: 5.1861]\n",
            "Epoch [15/15], batch: [55393/59184, loss: 6.9494]\n",
            "Epoch [15/15], batch: [55394/59184, loss: 5.9527]\n",
            "Epoch [15/15], batch: [55395/59184, loss: 6.5624]\n",
            "Epoch [15/15], batch: [55396/59184, loss: 6.3592]\n",
            "Epoch [15/15], batch: [55397/59184, loss: 5.4594]\n",
            "Epoch [15/15], batch: [55398/59184, loss: 6.7370]\n",
            "Epoch [15/15], batch: [55399/59184, loss: 4.4526]\n",
            "Epoch [15/15], batch: [55400/59184, loss: 4.6259]\n",
            "Epoch [15/15], batch: [55401/59184, loss: 6.8803]\n",
            "Epoch [15/15], batch: [55402/59184, loss: 6.0743]\n",
            "Epoch [15/15], batch: [55403/59184, loss: 5.6024]\n",
            "Epoch [15/15], batch: [55404/59184, loss: 5.5178]\n",
            "Epoch [15/15], batch: [55405/59184, loss: 4.5356]\n",
            "Epoch [15/15], batch: [55406/59184, loss: 5.3503]\n",
            "Epoch [15/15], batch: [55407/59184, loss: 6.0996]\n",
            "Epoch [15/15], batch: [55408/59184, loss: 6.4173]\n",
            "Epoch [15/15], batch: [55409/59184, loss: 6.0234]\n",
            "Epoch [15/15], batch: [55410/59184, loss: 5.7971]\n",
            "Epoch [15/15], batch: [55411/59184, loss: 4.6986]\n",
            "Epoch [15/15], batch: [55412/59184, loss: 6.3551]\n",
            "Epoch [15/15], batch: [55413/59184, loss: 7.3736]\n",
            "Epoch [15/15], batch: [55414/59184, loss: 5.6926]\n",
            "Epoch [15/15], batch: [55415/59184, loss: 6.5732]\n",
            "Epoch [15/15], batch: [55416/59184, loss: 6.2565]\n",
            "Epoch [15/15], batch: [55417/59184, loss: 5.3677]\n",
            "Epoch [15/15], batch: [55418/59184, loss: 6.1939]\n",
            "Epoch [15/15], batch: [55419/59184, loss: 6.8681]\n",
            "Epoch [15/15], batch: [55420/59184, loss: 6.0697]\n",
            "Epoch [15/15], batch: [55421/59184, loss: 6.2479]\n",
            "Epoch [15/15], batch: [55422/59184, loss: 6.7279]\n",
            "Epoch [15/15], batch: [55423/59184, loss: 6.2453]\n",
            "Epoch [15/15], batch: [55424/59184, loss: 7.9505]\n",
            "Epoch [15/15], batch: [55425/59184, loss: 6.2218]\n",
            "Epoch [15/15], batch: [55426/59184, loss: 7.1235]\n",
            "Epoch [15/15], batch: [55427/59184, loss: 7.4951]\n",
            "Epoch [15/15], batch: [55428/59184, loss: 5.6698]\n",
            "Epoch [15/15], batch: [55429/59184, loss: 6.7997]\n",
            "Epoch [15/15], batch: [55430/59184, loss: 6.9900]\n",
            "Epoch [15/15], batch: [55431/59184, loss: 6.5090]\n",
            "Epoch [15/15], batch: [55432/59184, loss: 5.9672]\n",
            "Epoch [15/15], batch: [55433/59184, loss: 5.7431]\n",
            "Epoch [15/15], batch: [55434/59184, loss: 5.2189]\n",
            "Epoch [15/15], batch: [55435/59184, loss: 7.2295]\n",
            "Epoch [15/15], batch: [55436/59184, loss: 6.3933]\n",
            "Epoch [15/15], batch: [55437/59184, loss: 6.7159]\n",
            "Epoch [15/15], batch: [55438/59184, loss: 6.5182]\n",
            "Epoch [15/15], batch: [55439/59184, loss: 5.6156]\n",
            "Epoch [15/15], batch: [55440/59184, loss: 6.5649]\n",
            "Epoch [15/15], batch: [55441/59184, loss: 7.0834]\n",
            "Epoch [15/15], batch: [55442/59184, loss: 6.1130]\n",
            "Epoch [15/15], batch: [55443/59184, loss: 6.4239]\n",
            "Epoch [15/15], batch: [55444/59184, loss: 6.8851]\n",
            "Epoch [15/15], batch: [55445/59184, loss: 6.8399]\n",
            "Epoch [15/15], batch: [55446/59184, loss: 6.5519]\n",
            "Epoch [15/15], batch: [55447/59184, loss: 4.6988]\n",
            "Epoch [15/15], batch: [55448/59184, loss: 4.9211]\n",
            "Epoch [15/15], batch: [55449/59184, loss: 5.3887]\n",
            "Epoch [15/15], batch: [55450/59184, loss: 4.7452]\n",
            "Epoch [15/15], batch: [55451/59184, loss: 5.5159]\n",
            "Epoch [15/15], batch: [55452/59184, loss: 5.5013]\n",
            "Epoch [15/15], batch: [55453/59184, loss: 4.1165]\n",
            "Epoch [15/15], batch: [55454/59184, loss: 6.5274]\n",
            "Epoch [15/15], batch: [55455/59184, loss: 5.6631]\n",
            "Epoch [15/15], batch: [55456/59184, loss: 6.7864]\n",
            "Epoch [15/15], batch: [55457/59184, loss: 5.5482]\n",
            "Epoch [15/15], batch: [55458/59184, loss: 6.8077]\n",
            "Epoch [15/15], batch: [55459/59184, loss: 5.6059]\n",
            "Epoch [15/15], batch: [55460/59184, loss: 7.3967]\n",
            "Epoch [15/15], batch: [55461/59184, loss: 6.2732]\n",
            "Epoch [15/15], batch: [55462/59184, loss: 6.1653]\n",
            "Epoch [15/15], batch: [55463/59184, loss: 6.3389]\n",
            "Epoch [15/15], batch: [55464/59184, loss: 5.4406]\n",
            "Epoch [15/15], batch: [55465/59184, loss: 5.9382]\n",
            "Epoch [15/15], batch: [55466/59184, loss: 7.0351]\n",
            "Epoch [15/15], batch: [55467/59184, loss: 5.3072]\n",
            "Epoch [15/15], batch: [55468/59184, loss: 6.7062]\n",
            "Epoch [15/15], batch: [55469/59184, loss: 6.0440]\n",
            "Epoch [15/15], batch: [55470/59184, loss: 7.2556]\n",
            "Epoch [15/15], batch: [55471/59184, loss: 5.8523]\n",
            "Epoch [15/15], batch: [55472/59184, loss: 5.2036]\n",
            "Epoch [15/15], batch: [55473/59184, loss: 5.9752]\n",
            "Epoch [15/15], batch: [55474/59184, loss: 3.3281]\n",
            "Epoch [15/15], batch: [55475/59184, loss: 4.5722]\n",
            "Epoch [15/15], batch: [55476/59184, loss: 4.4061]\n",
            "Epoch [15/15], batch: [55477/59184, loss: 3.9305]\n",
            "Epoch [15/15], batch: [55478/59184, loss: 4.2409]\n",
            "Epoch [15/15], batch: [55479/59184, loss: 5.3129]\n",
            "Epoch [15/15], batch: [55480/59184, loss: 3.4704]\n",
            "Epoch [15/15], batch: [55481/59184, loss: 5.9976]\n",
            "Epoch [15/15], batch: [55482/59184, loss: 4.1613]\n",
            "Epoch [15/15], batch: [55483/59184, loss: 5.9222]\n",
            "Epoch [15/15], batch: [55484/59184, loss: 6.5503]\n",
            "Epoch [15/15], batch: [55485/59184, loss: 6.8736]\n",
            "Epoch [15/15], batch: [55486/59184, loss: 6.8800]\n",
            "Epoch [15/15], batch: [55487/59184, loss: 5.9608]\n",
            "Epoch [15/15], batch: [55488/59184, loss: 5.6666]\n",
            "Epoch [15/15], batch: [55489/59184, loss: 5.4991]\n",
            "Epoch [15/15], batch: [55490/59184, loss: 7.2319]\n",
            "Epoch [15/15], batch: [55491/59184, loss: 5.2050]\n",
            "Epoch [15/15], batch: [55492/59184, loss: 5.9965]\n",
            "Epoch [15/15], batch: [55493/59184, loss: 5.7836]\n",
            "Epoch [15/15], batch: [55494/59184, loss: 6.3399]\n",
            "Epoch [15/15], batch: [55495/59184, loss: 6.4372]\n",
            "Epoch [15/15], batch: [55496/59184, loss: 7.6829]\n",
            "Epoch [15/15], batch: [55497/59184, loss: 5.6328]\n",
            "Epoch [15/15], batch: [55498/59184, loss: 6.6662]\n",
            "Epoch [15/15], batch: [55499/59184, loss: 5.4087]\n",
            "Epoch [15/15], batch: [55500/59184, loss: 5.1494]\n",
            "Epoch [15/15], batch: [55501/59184, loss: 5.7831]\n",
            "Epoch [15/15], batch: [55502/59184, loss: 5.5703]\n",
            "Epoch [15/15], batch: [55503/59184, loss: 5.9096]\n",
            "Epoch [15/15], batch: [55504/59184, loss: 6.5600]\n",
            "Epoch [15/15], batch: [55505/59184, loss: 5.5142]\n",
            "Epoch [15/15], batch: [55506/59184, loss: 4.8586]\n",
            "Epoch [15/15], batch: [55507/59184, loss: 5.9397]\n",
            "Epoch [15/15], batch: [55508/59184, loss: 5.5356]\n",
            "Epoch [15/15], batch: [55509/59184, loss: 3.5679]\n",
            "Epoch [15/15], batch: [55510/59184, loss: 4.8903]\n",
            "Epoch [15/15], batch: [55511/59184, loss: 3.4479]\n",
            "Epoch [15/15], batch: [55512/59184, loss: 4.0678]\n",
            "Epoch [15/15], batch: [55513/59184, loss: 4.1688]\n",
            "Epoch [15/15], batch: [55514/59184, loss: 4.0617]\n",
            "Epoch [15/15], batch: [55515/59184, loss: 5.2689]\n",
            "Epoch [15/15], batch: [55516/59184, loss: 5.8595]\n",
            "Epoch [15/15], batch: [55517/59184, loss: 6.9070]\n",
            "Epoch [15/15], batch: [55518/59184, loss: 5.1386]\n",
            "Epoch [15/15], batch: [55519/59184, loss: 5.6551]\n",
            "Epoch [15/15], batch: [55520/59184, loss: 5.1112]\n",
            "Epoch [15/15], batch: [55521/59184, loss: 4.3101]\n",
            "Epoch [15/15], batch: [55522/59184, loss: 6.3908]\n",
            "Epoch [15/15], batch: [55523/59184, loss: 4.5818]\n",
            "Epoch [15/15], batch: [55524/59184, loss: 6.5036]\n",
            "Epoch [15/15], batch: [55525/59184, loss: 5.3096]\n",
            "Epoch [15/15], batch: [55526/59184, loss: 6.4837]\n",
            "Epoch [15/15], batch: [55527/59184, loss: 6.3586]\n",
            "Epoch [15/15], batch: [55528/59184, loss: 5.9062]\n",
            "Epoch [15/15], batch: [55529/59184, loss: 7.2728]\n",
            "Epoch [15/15], batch: [55530/59184, loss: 5.8374]\n",
            "Epoch [15/15], batch: [55531/59184, loss: 7.2122]\n",
            "Epoch [15/15], batch: [55532/59184, loss: 6.1212]\n",
            "Epoch [15/15], batch: [55533/59184, loss: 7.6823]\n",
            "Epoch [15/15], batch: [55534/59184, loss: 6.5426]\n",
            "Epoch [15/15], batch: [55535/59184, loss: 5.8131]\n",
            "Epoch [15/15], batch: [55536/59184, loss: 4.4690]\n",
            "Epoch [15/15], batch: [55537/59184, loss: 6.8556]\n",
            "Epoch [15/15], batch: [55538/59184, loss: 5.6374]\n",
            "Epoch [15/15], batch: [55539/59184, loss: 3.4535]\n",
            "Epoch [15/15], batch: [55540/59184, loss: 6.8767]\n",
            "Epoch [15/15], batch: [55541/59184, loss: 5.7357]\n",
            "Epoch [15/15], batch: [55542/59184, loss: 4.4789]\n",
            "Epoch [15/15], batch: [55543/59184, loss: 4.8475]\n",
            "Epoch [15/15], batch: [55544/59184, loss: 5.3360]\n",
            "Epoch [15/15], batch: [55545/59184, loss: 7.0863]\n",
            "Epoch [15/15], batch: [55546/59184, loss: 3.9942]\n",
            "Epoch [15/15], batch: [55547/59184, loss: 7.0413]\n",
            "Epoch [15/15], batch: [55548/59184, loss: 5.4603]\n",
            "Epoch [15/15], batch: [55549/59184, loss: 6.7267]\n",
            "Epoch [15/15], batch: [55550/59184, loss: 3.3507]\n",
            "Epoch [15/15], batch: [55551/59184, loss: 8.1018]\n",
            "Epoch [15/15], batch: [55552/59184, loss: 7.9802]\n",
            "Epoch [15/15], batch: [55553/59184, loss: 5.3521]\n",
            "Epoch [15/15], batch: [55554/59184, loss: 7.1237]\n",
            "Epoch [15/15], batch: [55555/59184, loss: 5.8264]\n",
            "Epoch [15/15], batch: [55556/59184, loss: 6.1196]\n",
            "Epoch [15/15], batch: [55557/59184, loss: 5.2298]\n",
            "Epoch [15/15], batch: [55558/59184, loss: 5.1779]\n",
            "Epoch [15/15], batch: [55559/59184, loss: 4.6309]\n",
            "Epoch [15/15], batch: [55560/59184, loss: 5.4002]\n",
            "Epoch [15/15], batch: [55561/59184, loss: 6.6519]\n",
            "Epoch [15/15], batch: [55562/59184, loss: 6.7677]\n",
            "Epoch [15/15], batch: [55563/59184, loss: 5.4956]\n",
            "Epoch [15/15], batch: [55564/59184, loss: 4.5514]\n",
            "Epoch [15/15], batch: [55565/59184, loss: 4.4779]\n",
            "Epoch [15/15], batch: [55566/59184, loss: 3.7958]\n",
            "Epoch [15/15], batch: [55567/59184, loss: 4.0849]\n",
            "Epoch [15/15], batch: [55568/59184, loss: 5.8178]\n",
            "Epoch [15/15], batch: [55569/59184, loss: 3.0713]\n",
            "Epoch [15/15], batch: [55570/59184, loss: 5.9380]\n",
            "Epoch [15/15], batch: [55571/59184, loss: 5.6387]\n",
            "Epoch [15/15], batch: [55572/59184, loss: 5.3398]\n",
            "Epoch [15/15], batch: [55573/59184, loss: 4.3610]\n",
            "Epoch [15/15], batch: [55574/59184, loss: 6.0356]\n",
            "Epoch [15/15], batch: [55575/59184, loss: 5.9857]\n",
            "Epoch [15/15], batch: [55576/59184, loss: 5.4957]\n",
            "Epoch [15/15], batch: [55577/59184, loss: 5.0861]\n",
            "Epoch [15/15], batch: [55578/59184, loss: 6.1480]\n",
            "Epoch [15/15], batch: [55579/59184, loss: 5.0514]\n",
            "Epoch [15/15], batch: [55580/59184, loss: 6.5193]\n",
            "Epoch [15/15], batch: [55581/59184, loss: 7.3946]\n",
            "Epoch [15/15], batch: [55582/59184, loss: 4.7880]\n",
            "Epoch [15/15], batch: [55583/59184, loss: 6.5254]\n",
            "Epoch [15/15], batch: [55584/59184, loss: 3.6122]\n",
            "Epoch [15/15], batch: [55585/59184, loss: 3.9801]\n",
            "Epoch [15/15], batch: [55586/59184, loss: 5.3038]\n",
            "Epoch [15/15], batch: [55587/59184, loss: 4.7315]\n",
            "Epoch [15/15], batch: [55588/59184, loss: 5.5053]\n",
            "Epoch [15/15], batch: [55589/59184, loss: 6.6205]\n",
            "Epoch [15/15], batch: [55590/59184, loss: 5.5244]\n",
            "Epoch [15/15], batch: [55591/59184, loss: 5.8336]\n",
            "Epoch [15/15], batch: [55592/59184, loss: 8.2295]\n",
            "Epoch [15/15], batch: [55593/59184, loss: 5.6509]\n",
            "Epoch [15/15], batch: [55594/59184, loss: 5.2022]\n",
            "Epoch [15/15], batch: [55595/59184, loss: 5.7924]\n",
            "Epoch [15/15], batch: [55596/59184, loss: 6.0381]\n",
            "Epoch [15/15], batch: [55597/59184, loss: 5.3706]\n",
            "Epoch [15/15], batch: [55598/59184, loss: 4.8033]\n",
            "Epoch [15/15], batch: [55599/59184, loss: 3.3153]\n",
            "Epoch [15/15], batch: [55600/59184, loss: 6.4217]\n",
            "Epoch [15/15], batch: [55601/59184, loss: 5.2766]\n",
            "Epoch [15/15], batch: [55602/59184, loss: 4.3680]\n",
            "Epoch [15/15], batch: [55603/59184, loss: 4.8308]\n",
            "Epoch [15/15], batch: [55604/59184, loss: 5.7865]\n",
            "Epoch [15/15], batch: [55605/59184, loss: 7.1142]\n",
            "Epoch [15/15], batch: [55606/59184, loss: 7.6052]\n",
            "Epoch [15/15], batch: [55607/59184, loss: 6.4343]\n",
            "Epoch [15/15], batch: [55608/59184, loss: 5.7134]\n",
            "Epoch [15/15], batch: [55609/59184, loss: 7.9273]\n",
            "Epoch [15/15], batch: [55610/59184, loss: 6.4889]\n",
            "Epoch [15/15], batch: [55611/59184, loss: 6.7408]\n",
            "Epoch [15/15], batch: [55612/59184, loss: 7.4455]\n",
            "Epoch [15/15], batch: [55613/59184, loss: 7.5357]\n",
            "Epoch [15/15], batch: [55614/59184, loss: 6.6363]\n",
            "Epoch [15/15], batch: [55615/59184, loss: 6.3508]\n",
            "Epoch [15/15], batch: [55616/59184, loss: 5.1550]\n",
            "Epoch [15/15], batch: [55617/59184, loss: 6.3870]\n",
            "Epoch [15/15], batch: [55618/59184, loss: 6.4328]\n",
            "Epoch [15/15], batch: [55619/59184, loss: 6.9473]\n",
            "Epoch [15/15], batch: [55620/59184, loss: 5.0284]\n",
            "Epoch [15/15], batch: [55621/59184, loss: 6.9086]\n",
            "Epoch [15/15], batch: [55622/59184, loss: 6.2362]\n",
            "Epoch [15/15], batch: [55623/59184, loss: 5.6321]\n",
            "Epoch [15/15], batch: [55624/59184, loss: 3.7712]\n",
            "Epoch [15/15], batch: [55625/59184, loss: 5.3251]\n",
            "Epoch [15/15], batch: [55626/59184, loss: 4.9700]\n",
            "Epoch [15/15], batch: [55627/59184, loss: 6.5761]\n",
            "Epoch [15/15], batch: [55628/59184, loss: 5.8676]\n",
            "Epoch [15/15], batch: [55629/59184, loss: 5.1508]\n",
            "Epoch [15/15], batch: [55630/59184, loss: 4.7566]\n",
            "Epoch [15/15], batch: [55631/59184, loss: 5.1526]\n",
            "Epoch [15/15], batch: [55632/59184, loss: 6.0043]\n",
            "Epoch [15/15], batch: [55633/59184, loss: 5.0470]\n",
            "Epoch [15/15], batch: [55634/59184, loss: 4.4564]\n",
            "Epoch [15/15], batch: [55635/59184, loss: 4.9183]\n",
            "Epoch [15/15], batch: [55636/59184, loss: 5.1010]\n",
            "Epoch [15/15], batch: [55637/59184, loss: 4.4691]\n",
            "Epoch [15/15], batch: [55638/59184, loss: 5.3671]\n",
            "Epoch [15/15], batch: [55639/59184, loss: 4.5150]\n",
            "Epoch [15/15], batch: [55640/59184, loss: 5.5237]\n",
            "Epoch [15/15], batch: [55641/59184, loss: 6.0675]\n",
            "Epoch [15/15], batch: [55642/59184, loss: 6.8734]\n",
            "Epoch [15/15], batch: [55643/59184, loss: 3.9988]\n",
            "Epoch [15/15], batch: [55644/59184, loss: 5.0703]\n",
            "Epoch [15/15], batch: [55645/59184, loss: 5.5794]\n",
            "Epoch [15/15], batch: [55646/59184, loss: 4.1472]\n",
            "Epoch [15/15], batch: [55647/59184, loss: 4.8068]\n",
            "Epoch [15/15], batch: [55648/59184, loss: 4.3948]\n",
            "Epoch [15/15], batch: [55649/59184, loss: 5.1105]\n",
            "Epoch [15/15], batch: [55650/59184, loss: 5.3458]\n",
            "Epoch [15/15], batch: [55651/59184, loss: 5.9906]\n",
            "Epoch [15/15], batch: [55652/59184, loss: 5.7162]\n",
            "Epoch [15/15], batch: [55653/59184, loss: 6.3688]\n",
            "Epoch [15/15], batch: [55654/59184, loss: 5.8961]\n",
            "Epoch [15/15], batch: [55655/59184, loss: 7.0299]\n",
            "Epoch [15/15], batch: [55656/59184, loss: 6.6395]\n",
            "Epoch [15/15], batch: [55657/59184, loss: 5.4472]\n",
            "Epoch [15/15], batch: [55658/59184, loss: 6.7231]\n",
            "Epoch [15/15], batch: [55659/59184, loss: 4.5767]\n",
            "Epoch [15/15], batch: [55660/59184, loss: 5.3315]\n",
            "Epoch [15/15], batch: [55661/59184, loss: 4.7290]\n",
            "Epoch [15/15], batch: [55662/59184, loss: 5.1570]\n",
            "Epoch [15/15], batch: [55663/59184, loss: 5.7420]\n",
            "Epoch [15/15], batch: [55664/59184, loss: 6.0906]\n",
            "Epoch [15/15], batch: [55665/59184, loss: 3.7716]\n",
            "Epoch [15/15], batch: [55666/59184, loss: 4.4803]\n",
            "Epoch [15/15], batch: [55667/59184, loss: 5.7842]\n",
            "Epoch [15/15], batch: [55668/59184, loss: 7.1035]\n",
            "Epoch [15/15], batch: [55669/59184, loss: 5.2744]\n",
            "Epoch [15/15], batch: [55670/59184, loss: 5.0257]\n",
            "Epoch [15/15], batch: [55671/59184, loss: 4.0379]\n",
            "Epoch [15/15], batch: [55672/59184, loss: 6.8261]\n",
            "Epoch [15/15], batch: [55673/59184, loss: 4.3480]\n",
            "Epoch [15/15], batch: [55674/59184, loss: 4.8202]\n",
            "Epoch [15/15], batch: [55675/59184, loss: 5.4392]\n",
            "Epoch [15/15], batch: [55676/59184, loss: 6.7962]\n",
            "Epoch [15/15], batch: [55677/59184, loss: 6.8334]\n",
            "Epoch [15/15], batch: [55678/59184, loss: 5.9850]\n",
            "Epoch [15/15], batch: [55679/59184, loss: 6.4818]\n",
            "Epoch [15/15], batch: [55680/59184, loss: 5.0815]\n",
            "Epoch [15/15], batch: [55681/59184, loss: 4.1608]\n",
            "Epoch [15/15], batch: [55682/59184, loss: 5.9321]\n",
            "Epoch [15/15], batch: [55683/59184, loss: 5.7101]\n",
            "Epoch [15/15], batch: [55684/59184, loss: 6.0975]\n",
            "Epoch [15/15], batch: [55685/59184, loss: 5.8083]\n",
            "Epoch [15/15], batch: [55686/59184, loss: 6.1978]\n",
            "Epoch [15/15], batch: [55687/59184, loss: 4.4556]\n",
            "Epoch [15/15], batch: [55688/59184, loss: 6.1822]\n",
            "Epoch [15/15], batch: [55689/59184, loss: 5.9709]\n",
            "Epoch [15/15], batch: [55690/59184, loss: 6.1529]\n",
            "Epoch [15/15], batch: [55691/59184, loss: 4.8894]\n",
            "Epoch [15/15], batch: [55692/59184, loss: 4.1614]\n",
            "Epoch [15/15], batch: [55693/59184, loss: 4.8226]\n",
            "Epoch [15/15], batch: [55694/59184, loss: 4.8687]\n",
            "Epoch [15/15], batch: [55695/59184, loss: 3.2335]\n",
            "Epoch [15/15], batch: [55696/59184, loss: 5.7246]\n",
            "Epoch [15/15], batch: [55697/59184, loss: 6.2443]\n",
            "Epoch [15/15], batch: [55698/59184, loss: 7.2470]\n",
            "Epoch [15/15], batch: [55699/59184, loss: 5.5351]\n",
            "Epoch [15/15], batch: [55700/59184, loss: 6.9346]\n",
            "Epoch [15/15], batch: [55701/59184, loss: 7.2896]\n",
            "Epoch [15/15], batch: [55702/59184, loss: 5.1867]\n",
            "Epoch [15/15], batch: [55703/59184, loss: 4.8777]\n",
            "Epoch [15/15], batch: [55704/59184, loss: 6.0791]\n",
            "Epoch [15/15], batch: [55705/59184, loss: 5.4480]\n",
            "Epoch [15/15], batch: [55706/59184, loss: 5.2642]\n",
            "Epoch [15/15], batch: [55707/59184, loss: 5.3840]\n",
            "Epoch [15/15], batch: [55708/59184, loss: 7.0080]\n",
            "Epoch [15/15], batch: [55709/59184, loss: 6.3791]\n",
            "Epoch [15/15], batch: [55710/59184, loss: 6.3602]\n",
            "Epoch [15/15], batch: [55711/59184, loss: 6.4026]\n",
            "Epoch [15/15], batch: [55712/59184, loss: 5.9407]\n",
            "Epoch [15/15], batch: [55713/59184, loss: 7.0561]\n",
            "Epoch [15/15], batch: [55714/59184, loss: 6.0516]\n",
            "Epoch [15/15], batch: [55715/59184, loss: 6.3061]\n",
            "Epoch [15/15], batch: [55716/59184, loss: 6.2082]\n",
            "Epoch [15/15], batch: [55717/59184, loss: 5.9888]\n",
            "Epoch [15/15], batch: [55718/59184, loss: 7.1416]\n",
            "Epoch [15/15], batch: [55719/59184, loss: 5.3511]\n",
            "Epoch [15/15], batch: [55720/59184, loss: 3.1174]\n",
            "Epoch [15/15], batch: [55721/59184, loss: 5.8616]\n",
            "Epoch [15/15], batch: [55722/59184, loss: 6.4647]\n",
            "Epoch [15/15], batch: [55723/59184, loss: 6.2502]\n",
            "Epoch [15/15], batch: [55724/59184, loss: 4.9756]\n",
            "Epoch [15/15], batch: [55725/59184, loss: 4.8362]\n",
            "Epoch [15/15], batch: [55726/59184, loss: 4.2908]\n",
            "Epoch [15/15], batch: [55727/59184, loss: 4.8721]\n",
            "Epoch [15/15], batch: [55728/59184, loss: 6.3915]\n",
            "Epoch [15/15], batch: [55729/59184, loss: 4.7387]\n",
            "Epoch [15/15], batch: [55730/59184, loss: 4.7469]\n",
            "Epoch [15/15], batch: [55731/59184, loss: 5.7384]\n",
            "Epoch [15/15], batch: [55732/59184, loss: 4.8850]\n",
            "Epoch [15/15], batch: [55733/59184, loss: 3.5049]\n",
            "Epoch [15/15], batch: [55734/59184, loss: 5.7196]\n",
            "Epoch [15/15], batch: [55735/59184, loss: 5.4300]\n",
            "Epoch [15/15], batch: [55736/59184, loss: 3.6894]\n",
            "Epoch [15/15], batch: [55737/59184, loss: 4.2811]\n",
            "Epoch [15/15], batch: [55738/59184, loss: 5.6423]\n",
            "Epoch [15/15], batch: [55739/59184, loss: 4.6646]\n",
            "Epoch [15/15], batch: [55740/59184, loss: 5.6825]\n",
            "Epoch [15/15], batch: [55741/59184, loss: 6.0469]\n",
            "Epoch [15/15], batch: [55742/59184, loss: 5.8622]\n",
            "Epoch [15/15], batch: [55743/59184, loss: 5.9791]\n",
            "Epoch [15/15], batch: [55744/59184, loss: 5.3482]\n",
            "Epoch [15/15], batch: [55745/59184, loss: 5.7569]\n",
            "Epoch [15/15], batch: [55746/59184, loss: 4.5919]\n",
            "Epoch [15/15], batch: [55747/59184, loss: 5.0712]\n",
            "Epoch [15/15], batch: [55748/59184, loss: 6.7963]\n",
            "Epoch [15/15], batch: [55749/59184, loss: 4.6379]\n",
            "Epoch [15/15], batch: [55750/59184, loss: 4.8124]\n",
            "Epoch [15/15], batch: [55751/59184, loss: 5.0284]\n",
            "Epoch [15/15], batch: [55752/59184, loss: 5.2345]\n",
            "Epoch [15/15], batch: [55753/59184, loss: 5.1817]\n",
            "Epoch [15/15], batch: [55754/59184, loss: 7.4522]\n",
            "Epoch [15/15], batch: [55755/59184, loss: 4.1495]\n",
            "Epoch [15/15], batch: [55756/59184, loss: 5.4105]\n",
            "Epoch [15/15], batch: [55757/59184, loss: 5.4199]\n",
            "Epoch [15/15], batch: [55758/59184, loss: 5.3765]\n",
            "Epoch [15/15], batch: [55759/59184, loss: 5.1219]\n",
            "Epoch [15/15], batch: [55760/59184, loss: 6.6702]\n",
            "Epoch [15/15], batch: [55761/59184, loss: 4.9949]\n",
            "Epoch [15/15], batch: [55762/59184, loss: 4.4040]\n",
            "Epoch [15/15], batch: [55763/59184, loss: 5.5722]\n",
            "Epoch [15/15], batch: [55764/59184, loss: 5.2554]\n",
            "Epoch [15/15], batch: [55765/59184, loss: 6.4014]\n",
            "Epoch [15/15], batch: [55766/59184, loss: 6.4792]\n",
            "Epoch [15/15], batch: [55767/59184, loss: 6.7046]\n",
            "Epoch [15/15], batch: [55768/59184, loss: 6.8788]\n",
            "Epoch [15/15], batch: [55769/59184, loss: 7.3025]\n",
            "Epoch [15/15], batch: [55770/59184, loss: 6.2228]\n",
            "Epoch [15/15], batch: [55771/59184, loss: 4.2674]\n",
            "Epoch [15/15], batch: [55772/59184, loss: 6.2580]\n",
            "Epoch [15/15], batch: [55773/59184, loss: 7.8836]\n",
            "Epoch [15/15], batch: [55774/59184, loss: 6.9367]\n",
            "Epoch [15/15], batch: [55775/59184, loss: 7.6304]\n",
            "Epoch [15/15], batch: [55776/59184, loss: 6.6126]\n",
            "Epoch [15/15], batch: [55777/59184, loss: 7.6321]\n",
            "Epoch [15/15], batch: [55778/59184, loss: 6.2477]\n",
            "Epoch [15/15], batch: [55779/59184, loss: 5.7157]\n",
            "Epoch [15/15], batch: [55780/59184, loss: 5.9971]\n",
            "Epoch [15/15], batch: [55781/59184, loss: 5.9943]\n",
            "Epoch [15/15], batch: [55782/59184, loss: 5.6584]\n",
            "Epoch [15/15], batch: [55783/59184, loss: 7.1552]\n",
            "Epoch [15/15], batch: [55784/59184, loss: 5.4684]\n",
            "Epoch [15/15], batch: [55785/59184, loss: 6.3560]\n",
            "Epoch [15/15], batch: [55786/59184, loss: 6.6553]\n",
            "Epoch [15/15], batch: [55787/59184, loss: 4.5478]\n",
            "Epoch [15/15], batch: [55788/59184, loss: 7.1882]\n",
            "Epoch [15/15], batch: [55789/59184, loss: 6.3601]\n",
            "Epoch [15/15], batch: [55790/59184, loss: 6.4919]\n",
            "Epoch [15/15], batch: [55791/59184, loss: 5.9922]\n",
            "Epoch [15/15], batch: [55792/59184, loss: 5.3700]\n",
            "Epoch [15/15], batch: [55793/59184, loss: 5.3497]\n",
            "Epoch [15/15], batch: [55794/59184, loss: 5.4271]\n",
            "Epoch [15/15], batch: [55795/59184, loss: 5.7865]\n",
            "Epoch [15/15], batch: [55796/59184, loss: 4.2223]\n",
            "Epoch [15/15], batch: [55797/59184, loss: 4.4935]\n",
            "Epoch [15/15], batch: [55798/59184, loss: 5.9707]\n",
            "Epoch [15/15], batch: [55799/59184, loss: 4.9046]\n",
            "Epoch [15/15], batch: [55800/59184, loss: 6.2515]\n",
            "Epoch [15/15], batch: [55801/59184, loss: 5.1705]\n",
            "Epoch [15/15], batch: [55802/59184, loss: 6.5748]\n",
            "Epoch [15/15], batch: [55803/59184, loss: 6.7007]\n",
            "Epoch [15/15], batch: [55804/59184, loss: 5.6479]\n",
            "Epoch [15/15], batch: [55805/59184, loss: 5.0496]\n",
            "Epoch [15/15], batch: [55806/59184, loss: 4.6824]\n",
            "Epoch [15/15], batch: [55807/59184, loss: 7.1418]\n",
            "Epoch [15/15], batch: [55808/59184, loss: 3.7534]\n",
            "Epoch [15/15], batch: [55809/59184, loss: 4.5205]\n",
            "Epoch [15/15], batch: [55810/59184, loss: 5.6030]\n",
            "Epoch [15/15], batch: [55811/59184, loss: 6.0183]\n",
            "Epoch [15/15], batch: [55812/59184, loss: 3.8560]\n",
            "Epoch [15/15], batch: [55813/59184, loss: 5.1491]\n",
            "Epoch [15/15], batch: [55814/59184, loss: 5.6020]\n",
            "Epoch [15/15], batch: [55815/59184, loss: 5.8238]\n",
            "Epoch [15/15], batch: [55816/59184, loss: 4.5175]\n",
            "Epoch [15/15], batch: [55817/59184, loss: 5.6320]\n",
            "Epoch [15/15], batch: [55818/59184, loss: 5.9402]\n",
            "Epoch [15/15], batch: [55819/59184, loss: 6.9397]\n",
            "Epoch [15/15], batch: [55820/59184, loss: 3.8771]\n",
            "Epoch [15/15], batch: [55821/59184, loss: 6.4842]\n",
            "Epoch [15/15], batch: [55822/59184, loss: 5.7955]\n",
            "Epoch [15/15], batch: [55823/59184, loss: 5.5452]\n",
            "Epoch [15/15], batch: [55824/59184, loss: 7.2455]\n",
            "Epoch [15/15], batch: [55825/59184, loss: 5.7105]\n",
            "Epoch [15/15], batch: [55826/59184, loss: 6.6127]\n",
            "Epoch [15/15], batch: [55827/59184, loss: 5.0197]\n",
            "Epoch [15/15], batch: [55828/59184, loss: 6.3270]\n",
            "Epoch [15/15], batch: [55829/59184, loss: 7.7083]\n",
            "Epoch [15/15], batch: [55830/59184, loss: 6.7535]\n",
            "Epoch [15/15], batch: [55831/59184, loss: 6.8809]\n",
            "Epoch [15/15], batch: [55832/59184, loss: 6.3420]\n",
            "Epoch [15/15], batch: [55833/59184, loss: 4.8920]\n",
            "Epoch [15/15], batch: [55834/59184, loss: 7.0386]\n",
            "Epoch [15/15], batch: [55835/59184, loss: 4.3807]\n",
            "Epoch [15/15], batch: [55836/59184, loss: 6.4787]\n",
            "Epoch [15/15], batch: [55837/59184, loss: 5.6275]\n",
            "Epoch [15/15], batch: [55838/59184, loss: 4.5565]\n",
            "Epoch [15/15], batch: [55839/59184, loss: 5.6058]\n",
            "Epoch [15/15], batch: [55840/59184, loss: 5.1688]\n",
            "Epoch [15/15], batch: [55841/59184, loss: 5.9325]\n",
            "Epoch [15/15], batch: [55842/59184, loss: 5.9277]\n",
            "Epoch [15/15], batch: [55843/59184, loss: 5.2284]\n",
            "Epoch [15/15], batch: [55844/59184, loss: 5.9602]\n",
            "Epoch [15/15], batch: [55845/59184, loss: 6.6137]\n",
            "Epoch [15/15], batch: [55846/59184, loss: 6.1470]\n",
            "Epoch [15/15], batch: [55847/59184, loss: 5.3535]\n",
            "Epoch [15/15], batch: [55848/59184, loss: 5.1792]\n",
            "Epoch [15/15], batch: [55849/59184, loss: 6.8241]\n",
            "Epoch [15/15], batch: [55850/59184, loss: 6.2922]\n",
            "Epoch [15/15], batch: [55851/59184, loss: 4.8559]\n",
            "Epoch [15/15], batch: [55852/59184, loss: 5.4852]\n",
            "Epoch [15/15], batch: [55853/59184, loss: 7.3088]\n",
            "Epoch [15/15], batch: [55854/59184, loss: 4.9253]\n",
            "Epoch [15/15], batch: [55855/59184, loss: 6.5150]\n",
            "Epoch [15/15], batch: [55856/59184, loss: 6.2094]\n",
            "Epoch [15/15], batch: [55857/59184, loss: 4.2965]\n",
            "Epoch [15/15], batch: [55858/59184, loss: 7.3949]\n",
            "Epoch [15/15], batch: [55859/59184, loss: 6.1887]\n",
            "Epoch [15/15], batch: [55860/59184, loss: 6.5630]\n",
            "Epoch [15/15], batch: [55861/59184, loss: 5.8809]\n",
            "Epoch [15/15], batch: [55862/59184, loss: 6.5806]\n",
            "Epoch [15/15], batch: [55863/59184, loss: 6.7556]\n",
            "Epoch [15/15], batch: [55864/59184, loss: 7.1688]\n",
            "Epoch [15/15], batch: [55865/59184, loss: 7.2297]\n",
            "Epoch [15/15], batch: [55866/59184, loss: 4.9288]\n",
            "Epoch [15/15], batch: [55867/59184, loss: 5.1324]\n",
            "Epoch [15/15], batch: [55868/59184, loss: 5.8984]\n",
            "Epoch [15/15], batch: [55869/59184, loss: 6.5579]\n",
            "Epoch [15/15], batch: [55870/59184, loss: 5.8780]\n",
            "Epoch [15/15], batch: [55871/59184, loss: 6.3485]\n",
            "Epoch [15/15], batch: [55872/59184, loss: 6.7865]\n",
            "Epoch [15/15], batch: [55873/59184, loss: 5.9478]\n",
            "Epoch [15/15], batch: [55874/59184, loss: 7.2211]\n",
            "Epoch [15/15], batch: [55875/59184, loss: 7.3710]\n",
            "Epoch [15/15], batch: [55876/59184, loss: 6.2575]\n",
            "Epoch [15/15], batch: [55877/59184, loss: 5.9223]\n",
            "Epoch [15/15], batch: [55878/59184, loss: 5.7658]\n",
            "Epoch [15/15], batch: [55879/59184, loss: 5.6622]\n",
            "Epoch [15/15], batch: [55880/59184, loss: 7.8007]\n",
            "Epoch [15/15], batch: [55881/59184, loss: 4.2013]\n",
            "Epoch [15/15], batch: [55882/59184, loss: 5.1077]\n",
            "Epoch [15/15], batch: [55883/59184, loss: 5.3825]\n",
            "Epoch [15/15], batch: [55884/59184, loss: 6.4831]\n",
            "Epoch [15/15], batch: [55885/59184, loss: 5.6543]\n",
            "Epoch [15/15], batch: [55886/59184, loss: 6.6132]\n",
            "Epoch [15/15], batch: [55887/59184, loss: 7.0218]\n",
            "Epoch [15/15], batch: [55888/59184, loss: 5.8882]\n",
            "Epoch [15/15], batch: [55889/59184, loss: 6.0185]\n",
            "Epoch [15/15], batch: [55890/59184, loss: 6.0679]\n",
            "Epoch [15/15], batch: [55891/59184, loss: 6.4050]\n",
            "Epoch [15/15], batch: [55892/59184, loss: 6.5896]\n",
            "Epoch [15/15], batch: [55893/59184, loss: 7.9153]\n",
            "Epoch [15/15], batch: [55894/59184, loss: 5.6785]\n",
            "Epoch [15/15], batch: [55895/59184, loss: 6.7366]\n",
            "Epoch [15/15], batch: [55896/59184, loss: 5.0320]\n",
            "Epoch [15/15], batch: [55897/59184, loss: 6.6799]\n",
            "Epoch [15/15], batch: [55898/59184, loss: 5.0419]\n",
            "Epoch [15/15], batch: [55899/59184, loss: 7.5601]\n",
            "Epoch [15/15], batch: [55900/59184, loss: 7.4394]\n",
            "Epoch [15/15], batch: [55901/59184, loss: 7.2611]\n",
            "Epoch [15/15], batch: [55902/59184, loss: 6.7113]\n",
            "Epoch [15/15], batch: [55903/59184, loss: 6.7406]\n",
            "Epoch [15/15], batch: [55904/59184, loss: 6.0449]\n",
            "Epoch [15/15], batch: [55905/59184, loss: 6.2295]\n",
            "Epoch [15/15], batch: [55906/59184, loss: 6.7139]\n",
            "Epoch [15/15], batch: [55907/59184, loss: 6.3188]\n",
            "Epoch [15/15], batch: [55908/59184, loss: 5.7468]\n",
            "Epoch [15/15], batch: [55909/59184, loss: 5.3234]\n",
            "Epoch [15/15], batch: [55910/59184, loss: 5.9313]\n",
            "Epoch [15/15], batch: [55911/59184, loss: 7.2389]\n",
            "Epoch [15/15], batch: [55912/59184, loss: 7.8042]\n",
            "Epoch [15/15], batch: [55913/59184, loss: 4.7482]\n",
            "Epoch [15/15], batch: [55914/59184, loss: 4.9991]\n",
            "Epoch [15/15], batch: [55915/59184, loss: 5.4148]\n",
            "Epoch [15/15], batch: [55916/59184, loss: 6.3196]\n",
            "Epoch [15/15], batch: [55917/59184, loss: 5.8225]\n",
            "Epoch [15/15], batch: [55918/59184, loss: 5.3617]\n",
            "Epoch [15/15], batch: [55919/59184, loss: 4.5543]\n",
            "Epoch [15/15], batch: [55920/59184, loss: 5.4485]\n",
            "Epoch [15/15], batch: [55921/59184, loss: 5.9589]\n",
            "Epoch [15/15], batch: [55922/59184, loss: 5.2479]\n",
            "Epoch [15/15], batch: [55923/59184, loss: 4.9340]\n",
            "Epoch [15/15], batch: [55924/59184, loss: 5.3569]\n",
            "Epoch [15/15], batch: [55925/59184, loss: 4.0074]\n",
            "Epoch [15/15], batch: [55926/59184, loss: 4.8530]\n",
            "Epoch [15/15], batch: [55927/59184, loss: 5.5085]\n",
            "Epoch [15/15], batch: [55928/59184, loss: 3.9057]\n",
            "Epoch [15/15], batch: [55929/59184, loss: 4.5605]\n",
            "Epoch [15/15], batch: [55930/59184, loss: 4.9757]\n",
            "Epoch [15/15], batch: [55931/59184, loss: 6.0179]\n",
            "Epoch [15/15], batch: [55932/59184, loss: 5.1498]\n",
            "Epoch [15/15], batch: [55933/59184, loss: 4.2539]\n",
            "Epoch [15/15], batch: [55934/59184, loss: 6.5225]\n",
            "Epoch [15/15], batch: [55935/59184, loss: 5.4046]\n",
            "Epoch [15/15], batch: [55936/59184, loss: 6.6598]\n",
            "Epoch [15/15], batch: [55937/59184, loss: 4.6651]\n",
            "Epoch [15/15], batch: [55938/59184, loss: 5.6871]\n",
            "Epoch [15/15], batch: [55939/59184, loss: 5.3033]\n",
            "Epoch [15/15], batch: [55940/59184, loss: 5.4810]\n",
            "Epoch [15/15], batch: [55941/59184, loss: 5.5999]\n",
            "Epoch [15/15], batch: [55942/59184, loss: 5.9152]\n",
            "Epoch [15/15], batch: [55943/59184, loss: 5.6545]\n",
            "Epoch [15/15], batch: [55944/59184, loss: 5.5371]\n",
            "Epoch [15/15], batch: [55945/59184, loss: 4.1673]\n",
            "Epoch [15/15], batch: [55946/59184, loss: 6.2907]\n",
            "Epoch [15/15], batch: [55947/59184, loss: 6.8771]\n",
            "Epoch [15/15], batch: [55948/59184, loss: 4.4113]\n",
            "Epoch [15/15], batch: [55949/59184, loss: 4.9195]\n",
            "Epoch [15/15], batch: [55950/59184, loss: 6.3942]\n",
            "Epoch [15/15], batch: [55951/59184, loss: 6.0824]\n",
            "Epoch [15/15], batch: [55952/59184, loss: 5.8835]\n",
            "Epoch [15/15], batch: [55953/59184, loss: 5.3353]\n",
            "Epoch [15/15], batch: [55954/59184, loss: 5.4510]\n",
            "Epoch [15/15], batch: [55955/59184, loss: 4.4944]\n",
            "Epoch [15/15], batch: [55956/59184, loss: 5.6338]\n",
            "Epoch [15/15], batch: [55957/59184, loss: 5.8255]\n",
            "Epoch [15/15], batch: [55958/59184, loss: 6.0427]\n",
            "Epoch [15/15], batch: [55959/59184, loss: 6.4190]\n",
            "Epoch [15/15], batch: [55960/59184, loss: 6.0207]\n",
            "Epoch [15/15], batch: [55961/59184, loss: 4.6373]\n",
            "Epoch [15/15], batch: [55962/59184, loss: 5.9757]\n",
            "Epoch [15/15], batch: [55963/59184, loss: 6.1171]\n",
            "Epoch [15/15], batch: [55964/59184, loss: 6.8192]\n",
            "Epoch [15/15], batch: [55965/59184, loss: 5.6509]\n",
            "Epoch [15/15], batch: [55966/59184, loss: 6.7388]\n",
            "Epoch [15/15], batch: [55967/59184, loss: 5.1440]\n",
            "Epoch [15/15], batch: [55968/59184, loss: 6.5705]\n",
            "Epoch [15/15], batch: [55969/59184, loss: 6.1150]\n",
            "Epoch [15/15], batch: [55970/59184, loss: 5.8691]\n",
            "Epoch [15/15], batch: [55971/59184, loss: 5.8607]\n",
            "Epoch [15/15], batch: [55972/59184, loss: 4.3042]\n",
            "Epoch [15/15], batch: [55973/59184, loss: 4.3733]\n",
            "Epoch [15/15], batch: [55974/59184, loss: 4.8755]\n",
            "Epoch [15/15], batch: [55975/59184, loss: 6.8661]\n",
            "Epoch [15/15], batch: [55976/59184, loss: 4.8741]\n",
            "Epoch [15/15], batch: [55977/59184, loss: 3.9414]\n",
            "Epoch [15/15], batch: [55978/59184, loss: 3.4294]\n",
            "Epoch [15/15], batch: [55979/59184, loss: 6.4413]\n",
            "Epoch [15/15], batch: [55980/59184, loss: 6.6414]\n",
            "Epoch [15/15], batch: [55981/59184, loss: 7.1695]\n",
            "Epoch [15/15], batch: [55982/59184, loss: 7.5579]\n",
            "Epoch [15/15], batch: [55983/59184, loss: 5.4133]\n",
            "Epoch [15/15], batch: [55984/59184, loss: 6.1700]\n",
            "Epoch [15/15], batch: [55985/59184, loss: 5.9959]\n",
            "Epoch [15/15], batch: [55986/59184, loss: 5.8654]\n",
            "Epoch [15/15], batch: [55987/59184, loss: 5.1797]\n",
            "Epoch [15/15], batch: [55988/59184, loss: 4.2549]\n",
            "Epoch [15/15], batch: [55989/59184, loss: 6.8102]\n",
            "Epoch [15/15], batch: [55990/59184, loss: 6.4492]\n",
            "Epoch [15/15], batch: [55991/59184, loss: 5.4402]\n",
            "Epoch [15/15], batch: [55992/59184, loss: 6.7653]\n",
            "Epoch [15/15], batch: [55993/59184, loss: 5.7187]\n",
            "Epoch [15/15], batch: [55994/59184, loss: 5.3720]\n",
            "Epoch [15/15], batch: [55995/59184, loss: 5.8364]\n",
            "Epoch [15/15], batch: [55996/59184, loss: 4.5173]\n",
            "Epoch [15/15], batch: [55997/59184, loss: 5.1927]\n",
            "Epoch [15/15], batch: [55998/59184, loss: 5.9139]\n",
            "Epoch [15/15], batch: [55999/59184, loss: 5.9499]\n",
            "Epoch [15/15], batch: [56000/59184, loss: 6.2581]\n",
            "Epoch [15/15], batch: [56001/59184, loss: 6.4406]\n",
            "Epoch [15/15], batch: [56002/59184, loss: 7.0469]\n",
            "Epoch [15/15], batch: [56003/59184, loss: 3.8075]\n",
            "Epoch [15/15], batch: [56004/59184, loss: 7.7184]\n",
            "Epoch [15/15], batch: [56005/59184, loss: 6.7771]\n",
            "Epoch [15/15], batch: [56006/59184, loss: 7.1487]\n",
            "Epoch [15/15], batch: [56007/59184, loss: 6.2424]\n",
            "Epoch [15/15], batch: [56008/59184, loss: 4.6966]\n",
            "Epoch [15/15], batch: [56009/59184, loss: 6.6789]\n",
            "Epoch [15/15], batch: [56010/59184, loss: 5.6238]\n",
            "Epoch [15/15], batch: [56011/59184, loss: 5.8480]\n",
            "Epoch [15/15], batch: [56012/59184, loss: 6.6497]\n",
            "Epoch [15/15], batch: [56013/59184, loss: 7.4797]\n",
            "Epoch [15/15], batch: [56014/59184, loss: 5.3968]\n",
            "Epoch [15/15], batch: [56015/59184, loss: 6.3703]\n",
            "Epoch [15/15], batch: [56016/59184, loss: 7.2362]\n",
            "Epoch [15/15], batch: [56017/59184, loss: 5.8896]\n",
            "Epoch [15/15], batch: [56018/59184, loss: 7.7122]\n",
            "Epoch [15/15], batch: [56019/59184, loss: 5.6481]\n",
            "Epoch [15/15], batch: [56020/59184, loss: 7.2036]\n",
            "Epoch [15/15], batch: [56021/59184, loss: 7.0691]\n",
            "Epoch [15/15], batch: [56022/59184, loss: 7.0047]\n",
            "Epoch [15/15], batch: [56023/59184, loss: 7.0073]\n",
            "Epoch [15/15], batch: [56024/59184, loss: 3.9003]\n",
            "Epoch [15/15], batch: [56025/59184, loss: 5.1023]\n",
            "Epoch [15/15], batch: [56026/59184, loss: 5.1237]\n",
            "Epoch [15/15], batch: [56027/59184, loss: 4.3535]\n",
            "Epoch [15/15], batch: [56028/59184, loss: 4.9493]\n",
            "Epoch [15/15], batch: [56029/59184, loss: 6.2328]\n",
            "Epoch [15/15], batch: [56030/59184, loss: 5.7314]\n",
            "Epoch [15/15], batch: [56031/59184, loss: 5.7684]\n",
            "Epoch [15/15], batch: [56032/59184, loss: 6.7803]\n",
            "Epoch [15/15], batch: [56033/59184, loss: 7.1683]\n",
            "Epoch [15/15], batch: [56034/59184, loss: 4.2445]\n",
            "Epoch [15/15], batch: [56035/59184, loss: 5.7664]\n",
            "Epoch [15/15], batch: [56036/59184, loss: 6.4595]\n",
            "Epoch [15/15], batch: [56037/59184, loss: 3.7117]\n",
            "Epoch [15/15], batch: [56038/59184, loss: 5.2985]\n",
            "Epoch [15/15], batch: [56039/59184, loss: 4.5897]\n",
            "Epoch [15/15], batch: [56040/59184, loss: 6.9067]\n",
            "Epoch [15/15], batch: [56041/59184, loss: 6.5344]\n",
            "Epoch [15/15], batch: [56042/59184, loss: 5.2047]\n",
            "Epoch [15/15], batch: [56043/59184, loss: 6.5794]\n",
            "Epoch [15/15], batch: [56044/59184, loss: 5.0683]\n",
            "Epoch [15/15], batch: [56045/59184, loss: 7.0964]\n",
            "Epoch [15/15], batch: [56046/59184, loss: 6.0387]\n",
            "Epoch [15/15], batch: [56047/59184, loss: 5.4548]\n",
            "Epoch [15/15], batch: [56048/59184, loss: 6.5629]\n",
            "Epoch [15/15], batch: [56049/59184, loss: 5.9361]\n",
            "Epoch [15/15], batch: [56050/59184, loss: 5.8060]\n",
            "Epoch [15/15], batch: [56051/59184, loss: 4.8206]\n",
            "Epoch [15/15], batch: [56052/59184, loss: 6.7468]\n",
            "Epoch [15/15], batch: [56053/59184, loss: 6.3227]\n",
            "Epoch [15/15], batch: [56054/59184, loss: 4.8797]\n",
            "Epoch [15/15], batch: [56055/59184, loss: 5.4515]\n",
            "Epoch [15/15], batch: [56056/59184, loss: 6.0692]\n",
            "Epoch [15/15], batch: [56057/59184, loss: 5.7635]\n",
            "Epoch [15/15], batch: [56058/59184, loss: 5.6618]\n",
            "Epoch [15/15], batch: [56059/59184, loss: 6.0126]\n",
            "Epoch [15/15], batch: [56060/59184, loss: 6.8021]\n",
            "Epoch [15/15], batch: [56061/59184, loss: 6.2210]\n",
            "Epoch [15/15], batch: [56062/59184, loss: 4.6727]\n",
            "Epoch [15/15], batch: [56063/59184, loss: 5.9504]\n",
            "Epoch [15/15], batch: [56064/59184, loss: 5.8169]\n",
            "Epoch [15/15], batch: [56065/59184, loss: 6.4294]\n",
            "Epoch [15/15], batch: [56066/59184, loss: 5.6986]\n",
            "Epoch [15/15], batch: [56067/59184, loss: 6.2000]\n",
            "Epoch [15/15], batch: [56068/59184, loss: 6.1042]\n",
            "Epoch [15/15], batch: [56069/59184, loss: 5.3830]\n",
            "Epoch [15/15], batch: [56070/59184, loss: 6.7183]\n",
            "Epoch [15/15], batch: [56071/59184, loss: 4.2717]\n",
            "Epoch [15/15], batch: [56072/59184, loss: 4.4968]\n",
            "Epoch [15/15], batch: [56073/59184, loss: 5.3178]\n",
            "Epoch [15/15], batch: [56074/59184, loss: 4.5400]\n",
            "Epoch [15/15], batch: [56075/59184, loss: 4.3444]\n",
            "Epoch [15/15], batch: [56076/59184, loss: 2.9639]\n",
            "Epoch [15/15], batch: [56077/59184, loss: 3.8954]\n",
            "Epoch [15/15], batch: [56078/59184, loss: 4.7447]\n",
            "Epoch [15/15], batch: [56079/59184, loss: 3.7756]\n",
            "Epoch [15/15], batch: [56080/59184, loss: 6.1013]\n",
            "Epoch [15/15], batch: [56081/59184, loss: 5.0794]\n",
            "Epoch [15/15], batch: [56082/59184, loss: 7.1969]\n",
            "Epoch [15/15], batch: [56083/59184, loss: 6.1503]\n",
            "Epoch [15/15], batch: [56084/59184, loss: 5.5583]\n",
            "Epoch [15/15], batch: [56085/59184, loss: 5.3409]\n",
            "Epoch [15/15], batch: [56086/59184, loss: 5.7783]\n",
            "Epoch [15/15], batch: [56087/59184, loss: 6.1819]\n",
            "Epoch [15/15], batch: [56088/59184, loss: 5.2160]\n",
            "Epoch [15/15], batch: [56089/59184, loss: 5.6162]\n",
            "Epoch [15/15], batch: [56090/59184, loss: 5.4330]\n",
            "Epoch [15/15], batch: [56091/59184, loss: 6.3429]\n",
            "Epoch [15/15], batch: [56092/59184, loss: 5.6803]\n",
            "Epoch [15/15], batch: [56093/59184, loss: 5.8965]\n",
            "Epoch [15/15], batch: [56094/59184, loss: 6.8069]\n",
            "Epoch [15/15], batch: [56095/59184, loss: 5.2704]\n",
            "Epoch [15/15], batch: [56096/59184, loss: 5.7185]\n",
            "Epoch [15/15], batch: [56097/59184, loss: 3.9331]\n",
            "Epoch [15/15], batch: [56098/59184, loss: 3.7090]\n",
            "Epoch [15/15], batch: [56099/59184, loss: 5.8782]\n",
            "Epoch [15/15], batch: [56100/59184, loss: 4.2709]\n",
            "Epoch [15/15], batch: [56101/59184, loss: 4.5461]\n",
            "Epoch [15/15], batch: [56102/59184, loss: 4.3946]\n",
            "Epoch [15/15], batch: [56103/59184, loss: 5.2704]\n",
            "Epoch [15/15], batch: [56104/59184, loss: 5.8584]\n",
            "Epoch [15/15], batch: [56105/59184, loss: 5.1129]\n",
            "Epoch [15/15], batch: [56106/59184, loss: 5.1261]\n",
            "Epoch [15/15], batch: [56107/59184, loss: 6.0819]\n",
            "Epoch [15/15], batch: [56108/59184, loss: 4.8627]\n",
            "Epoch [15/15], batch: [56109/59184, loss: 4.4689]\n",
            "Epoch [15/15], batch: [56110/59184, loss: 5.3323]\n",
            "Epoch [15/15], batch: [56111/59184, loss: 5.3196]\n",
            "Epoch [15/15], batch: [56112/59184, loss: 7.2549]\n",
            "Epoch [15/15], batch: [56113/59184, loss: 5.1870]\n",
            "Epoch [15/15], batch: [56114/59184, loss: 6.7717]\n",
            "Epoch [15/15], batch: [56115/59184, loss: 5.7255]\n",
            "Epoch [15/15], batch: [56116/59184, loss: 6.6152]\n",
            "Epoch [15/15], batch: [56117/59184, loss: 6.8703]\n",
            "Epoch [15/15], batch: [56118/59184, loss: 6.1420]\n",
            "Epoch [15/15], batch: [56119/59184, loss: 6.6838]\n",
            "Epoch [15/15], batch: [56120/59184, loss: 5.8378]\n",
            "Epoch [15/15], batch: [56121/59184, loss: 5.4628]\n",
            "Epoch [15/15], batch: [56122/59184, loss: 7.0265]\n",
            "Epoch [15/15], batch: [56123/59184, loss: 8.3291]\n",
            "Epoch [15/15], batch: [56124/59184, loss: 4.5754]\n",
            "Epoch [15/15], batch: [56125/59184, loss: 5.9673]\n",
            "Epoch [15/15], batch: [56126/59184, loss: 5.9600]\n",
            "Epoch [15/15], batch: [56127/59184, loss: 7.1907]\n",
            "Epoch [15/15], batch: [56128/59184, loss: 6.5557]\n",
            "Epoch [15/15], batch: [56129/59184, loss: 5.2891]\n",
            "Epoch [15/15], batch: [56130/59184, loss: 5.4467]\n",
            "Epoch [15/15], batch: [56131/59184, loss: 5.4016]\n",
            "Epoch [15/15], batch: [56132/59184, loss: 5.9773]\n",
            "Epoch [15/15], batch: [56133/59184, loss: 3.6332]\n",
            "Epoch [15/15], batch: [56134/59184, loss: 6.0909]\n",
            "Epoch [15/15], batch: [56135/59184, loss: 5.5334]\n",
            "Epoch [15/15], batch: [56136/59184, loss: 5.5505]\n",
            "Epoch [15/15], batch: [56137/59184, loss: 6.3334]\n",
            "Epoch [15/15], batch: [56138/59184, loss: 6.7397]\n",
            "Epoch [15/15], batch: [56139/59184, loss: 7.2568]\n",
            "Epoch [15/15], batch: [56140/59184, loss: 5.5626]\n",
            "Epoch [15/15], batch: [56141/59184, loss: 6.0231]\n",
            "Epoch [15/15], batch: [56142/59184, loss: 7.4777]\n",
            "Epoch [15/15], batch: [56143/59184, loss: 6.9523]\n",
            "Epoch [15/15], batch: [56144/59184, loss: 7.9855]\n",
            "Epoch [15/15], batch: [56145/59184, loss: 5.7150]\n",
            "Epoch [15/15], batch: [56146/59184, loss: 5.5574]\n",
            "Epoch [15/15], batch: [56147/59184, loss: 6.3252]\n",
            "Epoch [15/15], batch: [56148/59184, loss: 5.5880]\n",
            "Epoch [15/15], batch: [56149/59184, loss: 6.3748]\n",
            "Epoch [15/15], batch: [56150/59184, loss: 7.5384]\n",
            "Epoch [15/15], batch: [56151/59184, loss: 5.5730]\n",
            "Epoch [15/15], batch: [56152/59184, loss: 3.3625]\n",
            "Epoch [15/15], batch: [56153/59184, loss: 5.7590]\n",
            "Epoch [15/15], batch: [56154/59184, loss: 5.6063]\n",
            "Epoch [15/15], batch: [56155/59184, loss: 4.7381]\n",
            "Epoch [15/15], batch: [56156/59184, loss: 5.8031]\n",
            "Epoch [15/15], batch: [56157/59184, loss: 5.2991]\n",
            "Epoch [15/15], batch: [56158/59184, loss: 6.0930]\n",
            "Epoch [15/15], batch: [56159/59184, loss: 5.3573]\n",
            "Epoch [15/15], batch: [56160/59184, loss: 5.9185]\n",
            "Epoch [15/15], batch: [56161/59184, loss: 7.2764]\n",
            "Epoch [15/15], batch: [56162/59184, loss: 4.1516]\n",
            "Epoch [15/15], batch: [56163/59184, loss: 5.1415]\n",
            "Epoch [15/15], batch: [56164/59184, loss: 5.6432]\n",
            "Epoch [15/15], batch: [56165/59184, loss: 3.1489]\n",
            "Epoch [15/15], batch: [56166/59184, loss: 4.2945]\n",
            "Epoch [15/15], batch: [56167/59184, loss: 5.3086]\n",
            "Epoch [15/15], batch: [56168/59184, loss: 6.2052]\n",
            "Epoch [15/15], batch: [56169/59184, loss: 6.7045]\n",
            "Epoch [15/15], batch: [56170/59184, loss: 7.5817]\n",
            "Epoch [15/15], batch: [56171/59184, loss: 6.3438]\n",
            "Epoch [15/15], batch: [56172/59184, loss: 6.1151]\n",
            "Epoch [15/15], batch: [56173/59184, loss: 6.6010]\n",
            "Epoch [15/15], batch: [56174/59184, loss: 7.1558]\n",
            "Epoch [15/15], batch: [56175/59184, loss: 5.8707]\n",
            "Epoch [15/15], batch: [56176/59184, loss: 6.9721]\n",
            "Epoch [15/15], batch: [56177/59184, loss: 5.5409]\n",
            "Epoch [15/15], batch: [56178/59184, loss: 6.0971]\n",
            "Epoch [15/15], batch: [56179/59184, loss: 6.5742]\n",
            "Epoch [15/15], batch: [56180/59184, loss: 5.2377]\n",
            "Epoch [15/15], batch: [56181/59184, loss: 5.7324]\n",
            "Epoch [15/15], batch: [56182/59184, loss: 6.1126]\n",
            "Epoch [15/15], batch: [56183/59184, loss: 6.3939]\n",
            "Epoch [15/15], batch: [56184/59184, loss: 6.0040]\n",
            "Epoch [15/15], batch: [56185/59184, loss: 6.1803]\n",
            "Epoch [15/15], batch: [56186/59184, loss: 7.3686]\n",
            "Epoch [15/15], batch: [56187/59184, loss: 5.0494]\n",
            "Epoch [15/15], batch: [56188/59184, loss: 7.2003]\n",
            "Epoch [15/15], batch: [56189/59184, loss: 6.9173]\n",
            "Epoch [15/15], batch: [56190/59184, loss: 5.3559]\n",
            "Epoch [15/15], batch: [56191/59184, loss: 4.6686]\n",
            "Epoch [15/15], batch: [56192/59184, loss: 5.9164]\n",
            "Epoch [15/15], batch: [56193/59184, loss: 6.4736]\n",
            "Epoch [15/15], batch: [56194/59184, loss: 5.1297]\n",
            "Epoch [15/15], batch: [56195/59184, loss: 8.6171]\n",
            "Epoch [15/15], batch: [56196/59184, loss: 6.2737]\n",
            "Epoch [15/15], batch: [56197/59184, loss: 5.6354]\n",
            "Epoch [15/15], batch: [56198/59184, loss: 6.3405]\n",
            "Epoch [15/15], batch: [56199/59184, loss: 4.8648]\n",
            "Epoch [15/15], batch: [56200/59184, loss: 5.3849]\n",
            "Epoch [15/15], batch: [56201/59184, loss: 5.2635]\n",
            "Epoch [15/15], batch: [56202/59184, loss: 5.9425]\n",
            "Epoch [15/15], batch: [56203/59184, loss: 5.8613]\n",
            "Epoch [15/15], batch: [56204/59184, loss: 4.9443]\n",
            "Epoch [15/15], batch: [56205/59184, loss: 5.9167]\n",
            "Epoch [15/15], batch: [56206/59184, loss: 7.6609]\n",
            "Epoch [15/15], batch: [56207/59184, loss: 6.3950]\n",
            "Epoch [15/15], batch: [56208/59184, loss: 5.3020]\n",
            "Epoch [15/15], batch: [56209/59184, loss: 5.4163]\n",
            "Epoch [15/15], batch: [56210/59184, loss: 6.1431]\n",
            "Epoch [15/15], batch: [56211/59184, loss: 5.4025]\n",
            "Epoch [15/15], batch: [56212/59184, loss: 6.5479]\n",
            "Epoch [15/15], batch: [56213/59184, loss: 6.3738]\n",
            "Epoch [15/15], batch: [56214/59184, loss: 7.1393]\n",
            "Epoch [15/15], batch: [56215/59184, loss: 4.5542]\n",
            "Epoch [15/15], batch: [56216/59184, loss: 6.4144]\n",
            "Epoch [15/15], batch: [56217/59184, loss: 6.7658]\n",
            "Epoch [15/15], batch: [56218/59184, loss: 6.5004]\n",
            "Epoch [15/15], batch: [56219/59184, loss: 5.1838]\n",
            "Epoch [15/15], batch: [56220/59184, loss: 5.9753]\n",
            "Epoch [15/15], batch: [56221/59184, loss: 6.7702]\n",
            "Epoch [15/15], batch: [56222/59184, loss: 6.0811]\n",
            "Epoch [15/15], batch: [56223/59184, loss: 5.5551]\n",
            "Epoch [15/15], batch: [56224/59184, loss: 5.7245]\n",
            "Epoch [15/15], batch: [56225/59184, loss: 5.6872]\n",
            "Epoch [15/15], batch: [56226/59184, loss: 5.2088]\n",
            "Epoch [15/15], batch: [56227/59184, loss: 5.6008]\n",
            "Epoch [15/15], batch: [56228/59184, loss: 6.2527]\n",
            "Epoch [15/15], batch: [56229/59184, loss: 5.6208]\n",
            "Epoch [15/15], batch: [56230/59184, loss: 5.4014]\n",
            "Epoch [15/15], batch: [56231/59184, loss: 7.1145]\n",
            "Epoch [15/15], batch: [56232/59184, loss: 6.6271]\n",
            "Epoch [15/15], batch: [56233/59184, loss: 6.4456]\n",
            "Epoch [15/15], batch: [56234/59184, loss: 3.8417]\n",
            "Epoch [15/15], batch: [56235/59184, loss: 4.2527]\n",
            "Epoch [15/15], batch: [56236/59184, loss: 6.9545]\n",
            "Epoch [15/15], batch: [56237/59184, loss: 7.0030]\n",
            "Epoch [15/15], batch: [56238/59184, loss: 4.9836]\n",
            "Epoch [15/15], batch: [56239/59184, loss: 4.8407]\n",
            "Epoch [15/15], batch: [56240/59184, loss: 4.5732]\n",
            "Epoch [15/15], batch: [56241/59184, loss: 6.9619]\n",
            "Epoch [15/15], batch: [56242/59184, loss: 6.0860]\n",
            "Epoch [15/15], batch: [56243/59184, loss: 4.7609]\n",
            "Epoch [15/15], batch: [56244/59184, loss: 3.3555]\n",
            "Epoch [15/15], batch: [56245/59184, loss: 5.9500]\n",
            "Epoch [15/15], batch: [56246/59184, loss: 5.9263]\n",
            "Epoch [15/15], batch: [56247/59184, loss: 5.1872]\n",
            "Epoch [15/15], batch: [56248/59184, loss: 6.5567]\n",
            "Epoch [15/15], batch: [56249/59184, loss: 6.2743]\n",
            "Epoch [15/15], batch: [56250/59184, loss: 6.3718]\n",
            "Epoch [15/15], batch: [56251/59184, loss: 6.4926]\n",
            "Epoch [15/15], batch: [56252/59184, loss: 6.9370]\n",
            "Epoch [15/15], batch: [56253/59184, loss: 6.1905]\n",
            "Epoch [15/15], batch: [56254/59184, loss: 5.3708]\n",
            "Epoch [15/15], batch: [56255/59184, loss: 4.7761]\n",
            "Epoch [15/15], batch: [56256/59184, loss: 4.0076]\n",
            "Epoch [15/15], batch: [56257/59184, loss: 4.5396]\n",
            "Epoch [15/15], batch: [56258/59184, loss: 5.9283]\n",
            "Epoch [15/15], batch: [56259/59184, loss: 4.3542]\n",
            "Epoch [15/15], batch: [56260/59184, loss: 4.2233]\n",
            "Epoch [15/15], batch: [56261/59184, loss: 4.9836]\n",
            "Epoch [15/15], batch: [56262/59184, loss: 6.0524]\n",
            "Epoch [15/15], batch: [56263/59184, loss: 3.9710]\n",
            "Epoch [15/15], batch: [56264/59184, loss: 6.0454]\n",
            "Epoch [15/15], batch: [56265/59184, loss: 5.3944]\n",
            "Epoch [15/15], batch: [56266/59184, loss: 4.1862]\n",
            "Epoch [15/15], batch: [56267/59184, loss: 5.5213]\n",
            "Epoch [15/15], batch: [56268/59184, loss: 4.4901]\n",
            "Epoch [15/15], batch: [56269/59184, loss: 4.9959]\n",
            "Epoch [15/15], batch: [56270/59184, loss: 4.3093]\n",
            "Epoch [15/15], batch: [56271/59184, loss: 7.2865]\n",
            "Epoch [15/15], batch: [56272/59184, loss: 5.2305]\n",
            "Epoch [15/15], batch: [56273/59184, loss: 5.9200]\n",
            "Epoch [15/15], batch: [56274/59184, loss: 5.7285]\n",
            "Epoch [15/15], batch: [56275/59184, loss: 5.7594]\n",
            "Epoch [15/15], batch: [56276/59184, loss: 5.4102]\n",
            "Epoch [15/15], batch: [56277/59184, loss: 4.7282]\n",
            "Epoch [15/15], batch: [56278/59184, loss: 5.6135]\n",
            "Epoch [15/15], batch: [56279/59184, loss: 5.7918]\n",
            "Epoch [15/15], batch: [56280/59184, loss: 4.4398]\n",
            "Epoch [15/15], batch: [56281/59184, loss: 4.7938]\n",
            "Epoch [15/15], batch: [56282/59184, loss: 5.4901]\n",
            "Epoch [15/15], batch: [56283/59184, loss: 5.1452]\n",
            "Epoch [15/15], batch: [56284/59184, loss: 7.3981]\n",
            "Epoch [15/15], batch: [56285/59184, loss: 7.0489]\n",
            "Epoch [15/15], batch: [56286/59184, loss: 6.8889]\n",
            "Epoch [15/15], batch: [56287/59184, loss: 6.4051]\n",
            "Epoch [15/15], batch: [56288/59184, loss: 5.8809]\n",
            "Epoch [15/15], batch: [56289/59184, loss: 6.7910]\n",
            "Epoch [15/15], batch: [56290/59184, loss: 5.2961]\n",
            "Epoch [15/15], batch: [56291/59184, loss: 7.1694]\n",
            "Epoch [15/15], batch: [56292/59184, loss: 5.2419]\n",
            "Epoch [15/15], batch: [56293/59184, loss: 5.8799]\n",
            "Epoch [15/15], batch: [56294/59184, loss: 4.5767]\n",
            "Epoch [15/15], batch: [56295/59184, loss: 4.9553]\n",
            "Epoch [15/15], batch: [56296/59184, loss: 5.6835]\n",
            "Epoch [15/15], batch: [56297/59184, loss: 5.1089]\n",
            "Epoch [15/15], batch: [56298/59184, loss: 6.5792]\n",
            "Epoch [15/15], batch: [56299/59184, loss: 6.6255]\n",
            "Epoch [15/15], batch: [56300/59184, loss: 6.3428]\n",
            "Epoch [15/15], batch: [56301/59184, loss: 6.2642]\n",
            "Epoch [15/15], batch: [56302/59184, loss: 7.1284]\n",
            "Epoch [15/15], batch: [56303/59184, loss: 3.3919]\n",
            "Epoch [15/15], batch: [56304/59184, loss: 5.9209]\n",
            "Epoch [15/15], batch: [56305/59184, loss: 6.8907]\n",
            "Epoch [15/15], batch: [56306/59184, loss: 4.8550]\n",
            "Epoch [15/15], batch: [56307/59184, loss: 4.8755]\n",
            "Epoch [15/15], batch: [56308/59184, loss: 6.6487]\n",
            "Epoch [15/15], batch: [56309/59184, loss: 4.4858]\n",
            "Epoch [15/15], batch: [56310/59184, loss: 6.7524]\n",
            "Epoch [15/15], batch: [56311/59184, loss: 5.9510]\n",
            "Epoch [15/15], batch: [56312/59184, loss: 6.2640]\n",
            "Epoch [15/15], batch: [56313/59184, loss: 6.1343]\n",
            "Epoch [15/15], batch: [56314/59184, loss: 6.3982]\n",
            "Epoch [15/15], batch: [56315/59184, loss: 5.4250]\n",
            "Epoch [15/15], batch: [56316/59184, loss: 5.1957]\n",
            "Epoch [15/15], batch: [56317/59184, loss: 6.6847]\n",
            "Epoch [15/15], batch: [56318/59184, loss: 6.3668]\n",
            "Epoch [15/15], batch: [56319/59184, loss: 6.4115]\n",
            "Epoch [15/15], batch: [56320/59184, loss: 6.6055]\n",
            "Epoch [15/15], batch: [56321/59184, loss: 5.9548]\n",
            "Epoch [15/15], batch: [56322/59184, loss: 6.4545]\n",
            "Epoch [15/15], batch: [56323/59184, loss: 6.4356]\n",
            "Epoch [15/15], batch: [56324/59184, loss: 6.6522]\n",
            "Epoch [15/15], batch: [56325/59184, loss: 5.6964]\n",
            "Epoch [15/15], batch: [56326/59184, loss: 6.9056]\n",
            "Epoch [15/15], batch: [56327/59184, loss: 5.7058]\n",
            "Epoch [15/15], batch: [56328/59184, loss: 4.3883]\n",
            "Epoch [15/15], batch: [56329/59184, loss: 4.7564]\n",
            "Epoch [15/15], batch: [56330/59184, loss: 5.5253]\n",
            "Epoch [15/15], batch: [56331/59184, loss: 3.7578]\n",
            "Epoch [15/15], batch: [56332/59184, loss: 4.6620]\n",
            "Epoch [15/15], batch: [56333/59184, loss: 5.1984]\n",
            "Epoch [15/15], batch: [56334/59184, loss: 4.8889]\n",
            "Epoch [15/15], batch: [56335/59184, loss: 5.2363]\n",
            "Epoch [15/15], batch: [56336/59184, loss: 5.7318]\n",
            "Epoch [15/15], batch: [56337/59184, loss: 6.2164]\n",
            "Epoch [15/15], batch: [56338/59184, loss: 3.6469]\n",
            "Epoch [15/15], batch: [56339/59184, loss: 6.7795]\n",
            "Epoch [15/15], batch: [56340/59184, loss: 5.2080]\n",
            "Epoch [15/15], batch: [56341/59184, loss: 6.4646]\n",
            "Epoch [15/15], batch: [56342/59184, loss: 7.4132]\n",
            "Epoch [15/15], batch: [56343/59184, loss: 6.0620]\n",
            "Epoch [15/15], batch: [56344/59184, loss: 6.1026]\n",
            "Epoch [15/15], batch: [56345/59184, loss: 6.1119]\n",
            "Epoch [15/15], batch: [56346/59184, loss: 6.8271]\n",
            "Epoch [15/15], batch: [56347/59184, loss: 6.1721]\n",
            "Epoch [15/15], batch: [56348/59184, loss: 6.1281]\n",
            "Epoch [15/15], batch: [56349/59184, loss: 6.1380]\n",
            "Epoch [15/15], batch: [56350/59184, loss: 5.1416]\n",
            "Epoch [15/15], batch: [56351/59184, loss: 6.0132]\n",
            "Epoch [15/15], batch: [56352/59184, loss: 6.9200]\n",
            "Epoch [15/15], batch: [56353/59184, loss: 6.0795]\n",
            "Epoch [15/15], batch: [56354/59184, loss: 4.4811]\n",
            "Epoch [15/15], batch: [56355/59184, loss: 5.9909]\n",
            "Epoch [15/15], batch: [56356/59184, loss: 4.4358]\n",
            "Epoch [15/15], batch: [56357/59184, loss: 5.7422]\n",
            "Epoch [15/15], batch: [56358/59184, loss: 5.9544]\n",
            "Epoch [15/15], batch: [56359/59184, loss: 5.5776]\n",
            "Epoch [15/15], batch: [56360/59184, loss: 7.0265]\n",
            "Epoch [15/15], batch: [56361/59184, loss: 5.8046]\n",
            "Epoch [15/15], batch: [56362/59184, loss: 4.9261]\n",
            "Epoch [15/15], batch: [56363/59184, loss: 6.1889]\n",
            "Epoch [15/15], batch: [56364/59184, loss: 5.9016]\n",
            "Epoch [15/15], batch: [56365/59184, loss: 3.0626]\n",
            "Epoch [15/15], batch: [56366/59184, loss: 5.0200]\n",
            "Epoch [15/15], batch: [56367/59184, loss: 4.2712]\n",
            "Epoch [15/15], batch: [56368/59184, loss: 4.4400]\n",
            "Epoch [15/15], batch: [56369/59184, loss: 5.0413]\n",
            "Epoch [15/15], batch: [56370/59184, loss: 4.2783]\n",
            "Epoch [15/15], batch: [56371/59184, loss: 4.3805]\n",
            "Epoch [15/15], batch: [56372/59184, loss: 5.7159]\n",
            "Epoch [15/15], batch: [56373/59184, loss: 5.1221]\n",
            "Epoch [15/15], batch: [56374/59184, loss: 6.3655]\n",
            "Epoch [15/15], batch: [56375/59184, loss: 6.5456]\n",
            "Epoch [15/15], batch: [56376/59184, loss: 4.4107]\n",
            "Epoch [15/15], batch: [56377/59184, loss: 4.4901]\n",
            "Epoch [15/15], batch: [56378/59184, loss: 6.2747]\n",
            "Epoch [15/15], batch: [56379/59184, loss: 7.4329]\n",
            "Epoch [15/15], batch: [56380/59184, loss: 4.7432]\n",
            "Epoch [15/15], batch: [56381/59184, loss: 5.9110]\n",
            "Epoch [15/15], batch: [56382/59184, loss: 7.0608]\n",
            "Epoch [15/15], batch: [56383/59184, loss: 4.9988]\n",
            "Epoch [15/15], batch: [56384/59184, loss: 5.5559]\n",
            "Epoch [15/15], batch: [56385/59184, loss: 3.7789]\n",
            "Epoch [15/15], batch: [56386/59184, loss: 7.2910]\n",
            "Epoch [15/15], batch: [56387/59184, loss: 4.6824]\n",
            "Epoch [15/15], batch: [56388/59184, loss: 6.6953]\n",
            "Epoch [15/15], batch: [56389/59184, loss: 6.1728]\n",
            "Epoch [15/15], batch: [56390/59184, loss: 4.7290]\n",
            "Epoch [15/15], batch: [56391/59184, loss: 5.6049]\n",
            "Epoch [15/15], batch: [56392/59184, loss: 4.8426]\n",
            "Epoch [15/15], batch: [56393/59184, loss: 4.3275]\n",
            "Epoch [15/15], batch: [56394/59184, loss: 5.8991]\n",
            "Epoch [15/15], batch: [56395/59184, loss: 6.3442]\n",
            "Epoch [15/15], batch: [56396/59184, loss: 4.0205]\n",
            "Epoch [15/15], batch: [56397/59184, loss: 7.4516]\n",
            "Epoch [15/15], batch: [56398/59184, loss: 5.6264]\n",
            "Epoch [15/15], batch: [56399/59184, loss: 4.2566]\n",
            "Epoch [15/15], batch: [56400/59184, loss: 4.1851]\n",
            "Epoch [15/15], batch: [56401/59184, loss: 6.4080]\n",
            "Epoch [15/15], batch: [56402/59184, loss: 6.1896]\n",
            "Epoch [15/15], batch: [56403/59184, loss: 6.1217]\n",
            "Epoch [15/15], batch: [56404/59184, loss: 5.2788]\n",
            "Epoch [15/15], batch: [56405/59184, loss: 4.7249]\n",
            "Epoch [15/15], batch: [56406/59184, loss: 4.6117]\n",
            "Epoch [15/15], batch: [56407/59184, loss: 5.3657]\n",
            "Epoch [15/15], batch: [56408/59184, loss: 5.8707]\n",
            "Epoch [15/15], batch: [56409/59184, loss: 5.4700]\n",
            "Epoch [15/15], batch: [56410/59184, loss: 4.8201]\n",
            "Epoch [15/15], batch: [56411/59184, loss: 3.8161]\n",
            "Epoch [15/15], batch: [56412/59184, loss: 5.3017]\n",
            "Epoch [15/15], batch: [56413/59184, loss: 3.8377]\n",
            "Epoch [15/15], batch: [56414/59184, loss: 5.6841]\n",
            "Epoch [15/15], batch: [56415/59184, loss: 5.2397]\n",
            "Epoch [15/15], batch: [56416/59184, loss: 8.8396]\n",
            "Epoch [15/15], batch: [56417/59184, loss: 4.8566]\n",
            "Epoch [15/15], batch: [56418/59184, loss: 5.9992]\n",
            "Epoch [15/15], batch: [56419/59184, loss: 4.0451]\n",
            "Epoch [15/15], batch: [56420/59184, loss: 5.5760]\n",
            "Epoch [15/15], batch: [56421/59184, loss: 6.7046]\n",
            "Epoch [15/15], batch: [56422/59184, loss: 4.8605]\n",
            "Epoch [15/15], batch: [56423/59184, loss: 5.9140]\n",
            "Epoch [15/15], batch: [56424/59184, loss: 6.0214]\n",
            "Epoch [15/15], batch: [56425/59184, loss: 8.2529]\n",
            "Epoch [15/15], batch: [56426/59184, loss: 5.8531]\n",
            "Epoch [15/15], batch: [56427/59184, loss: 5.6825]\n",
            "Epoch [15/15], batch: [56428/59184, loss: 7.5392]\n",
            "Epoch [15/15], batch: [56429/59184, loss: 5.9202]\n",
            "Epoch [15/15], batch: [56430/59184, loss: 8.0633]\n",
            "Epoch [15/15], batch: [56431/59184, loss: 6.9624]\n",
            "Epoch [15/15], batch: [56432/59184, loss: 6.0961]\n",
            "Epoch [15/15], batch: [56433/59184, loss: 5.2110]\n",
            "Epoch [15/15], batch: [56434/59184, loss: 6.6959]\n",
            "Epoch [15/15], batch: [56435/59184, loss: 6.2061]\n",
            "Epoch [15/15], batch: [56436/59184, loss: 5.2645]\n",
            "Epoch [15/15], batch: [56437/59184, loss: 8.2328]\n",
            "Epoch [15/15], batch: [56438/59184, loss: 6.9707]\n",
            "Epoch [15/15], batch: [56439/59184, loss: 6.4978]\n",
            "Epoch [15/15], batch: [56440/59184, loss: 6.2528]\n",
            "Epoch [15/15], batch: [56441/59184, loss: 7.2186]\n",
            "Epoch [15/15], batch: [56442/59184, loss: 7.7193]\n",
            "Epoch [15/15], batch: [56443/59184, loss: 5.6805]\n",
            "Epoch [15/15], batch: [56444/59184, loss: 5.7310]\n",
            "Epoch [15/15], batch: [56445/59184, loss: 5.5593]\n",
            "Epoch [15/15], batch: [56446/59184, loss: 5.7998]\n",
            "Epoch [15/15], batch: [56447/59184, loss: 7.0582]\n",
            "Epoch [15/15], batch: [56448/59184, loss: 6.5932]\n",
            "Epoch [15/15], batch: [56449/59184, loss: 5.0645]\n",
            "Epoch [15/15], batch: [56450/59184, loss: 5.0331]\n",
            "Epoch [15/15], batch: [56451/59184, loss: 4.7395]\n",
            "Epoch [15/15], batch: [56452/59184, loss: 5.7877]\n",
            "Epoch [15/15], batch: [56453/59184, loss: 6.4857]\n",
            "Epoch [15/15], batch: [56454/59184, loss: 4.9297]\n",
            "Epoch [15/15], batch: [56455/59184, loss: 5.2951]\n",
            "Epoch [15/15], batch: [56456/59184, loss: 6.1284]\n",
            "Epoch [15/15], batch: [56457/59184, loss: 5.6289]\n",
            "Epoch [15/15], batch: [56458/59184, loss: 6.9999]\n",
            "Epoch [15/15], batch: [56459/59184, loss: 4.3960]\n",
            "Epoch [15/15], batch: [56460/59184, loss: 6.6989]\n",
            "Epoch [15/15], batch: [56461/59184, loss: 5.9422]\n",
            "Epoch [15/15], batch: [56462/59184, loss: 6.8397]\n",
            "Epoch [15/15], batch: [56463/59184, loss: 5.4975]\n",
            "Epoch [15/15], batch: [56464/59184, loss: 5.9417]\n",
            "Epoch [15/15], batch: [56465/59184, loss: 6.2356]\n",
            "Epoch [15/15], batch: [56466/59184, loss: 7.1548]\n",
            "Epoch [15/15], batch: [56467/59184, loss: 6.5508]\n",
            "Epoch [15/15], batch: [56468/59184, loss: 6.2467]\n",
            "Epoch [15/15], batch: [56469/59184, loss: 5.8660]\n",
            "Epoch [15/15], batch: [56470/59184, loss: 5.4591]\n",
            "Epoch [15/15], batch: [56471/59184, loss: 5.5203]\n",
            "Epoch [15/15], batch: [56472/59184, loss: 4.6170]\n",
            "Epoch [15/15], batch: [56473/59184, loss: 5.9853]\n",
            "Epoch [15/15], batch: [56474/59184, loss: 5.9924]\n",
            "Epoch [15/15], batch: [56475/59184, loss: 4.5444]\n",
            "Epoch [15/15], batch: [56476/59184, loss: 5.7489]\n",
            "Epoch [15/15], batch: [56477/59184, loss: 6.8308]\n",
            "Epoch [15/15], batch: [56478/59184, loss: 8.0552]\n",
            "Epoch [15/15], batch: [56479/59184, loss: 6.1522]\n",
            "Epoch [15/15], batch: [56480/59184, loss: 5.2775]\n",
            "Epoch [15/15], batch: [56481/59184, loss: 5.3036]\n",
            "Epoch [15/15], batch: [56482/59184, loss: 5.7189]\n",
            "Epoch [15/15], batch: [56483/59184, loss: 7.1656]\n",
            "Epoch [15/15], batch: [56484/59184, loss: 6.3610]\n",
            "Epoch [15/15], batch: [56485/59184, loss: 4.9490]\n",
            "Epoch [15/15], batch: [56486/59184, loss: 7.2297]\n",
            "Epoch [15/15], batch: [56487/59184, loss: 6.3386]\n",
            "Epoch [15/15], batch: [56488/59184, loss: 5.9639]\n",
            "Epoch [15/15], batch: [56489/59184, loss: 7.0688]\n",
            "Epoch [15/15], batch: [56490/59184, loss: 5.7913]\n",
            "Epoch [15/15], batch: [56491/59184, loss: 6.6885]\n",
            "Epoch [15/15], batch: [56492/59184, loss: 6.7494]\n",
            "Epoch [15/15], batch: [56493/59184, loss: 7.0692]\n",
            "Epoch [15/15], batch: [56494/59184, loss: 5.9601]\n",
            "Epoch [15/15], batch: [56495/59184, loss: 4.4334]\n",
            "Epoch [15/15], batch: [56496/59184, loss: 3.8224]\n",
            "Epoch [15/15], batch: [56497/59184, loss: 5.9535]\n",
            "Epoch [15/15], batch: [56498/59184, loss: 6.1531]\n",
            "Epoch [15/15], batch: [56499/59184, loss: 3.9376]\n",
            "Epoch [15/15], batch: [56500/59184, loss: 4.1915]\n",
            "Epoch [15/15], batch: [56501/59184, loss: 4.7405]\n",
            "Epoch [15/15], batch: [56502/59184, loss: 4.8027]\n",
            "Epoch [15/15], batch: [56503/59184, loss: 5.0732]\n",
            "Epoch [15/15], batch: [56504/59184, loss: 5.7301]\n",
            "Epoch [15/15], batch: [56505/59184, loss: 6.4868]\n",
            "Epoch [15/15], batch: [56506/59184, loss: 4.8187]\n",
            "Epoch [15/15], batch: [56507/59184, loss: 5.3683]\n",
            "Epoch [15/15], batch: [56508/59184, loss: 5.6538]\n",
            "Epoch [15/15], batch: [56509/59184, loss: 5.9066]\n",
            "Epoch [15/15], batch: [56510/59184, loss: 6.0094]\n",
            "Epoch [15/15], batch: [56511/59184, loss: 6.7265]\n",
            "Epoch [15/15], batch: [56512/59184, loss: 4.5343]\n",
            "Epoch [15/15], batch: [56513/59184, loss: 5.2248]\n",
            "Epoch [15/15], batch: [56514/59184, loss: 6.7752]\n",
            "Epoch [15/15], batch: [56515/59184, loss: 6.8962]\n",
            "Epoch [15/15], batch: [56516/59184, loss: 5.6396]\n",
            "Epoch [15/15], batch: [56517/59184, loss: 5.0581]\n",
            "Epoch [15/15], batch: [56518/59184, loss: 4.7599]\n",
            "Epoch [15/15], batch: [56519/59184, loss: 5.9324]\n",
            "Epoch [15/15], batch: [56520/59184, loss: 5.3250]\n",
            "Epoch [15/15], batch: [56521/59184, loss: 3.8477]\n",
            "Epoch [15/15], batch: [56522/59184, loss: 5.5215]\n",
            "Epoch [15/15], batch: [56523/59184, loss: 6.9463]\n",
            "Epoch [15/15], batch: [56524/59184, loss: 7.5742]\n",
            "Epoch [15/15], batch: [56525/59184, loss: 5.7769]\n",
            "Epoch [15/15], batch: [56526/59184, loss: 6.4476]\n",
            "Epoch [15/15], batch: [56527/59184, loss: 5.3854]\n",
            "Epoch [15/15], batch: [56528/59184, loss: 6.1439]\n",
            "Epoch [15/15], batch: [56529/59184, loss: 4.6919]\n",
            "Epoch [15/15], batch: [56530/59184, loss: 5.3017]\n",
            "Epoch [15/15], batch: [56531/59184, loss: 5.3577]\n",
            "Epoch [15/15], batch: [56532/59184, loss: 4.5323]\n",
            "Epoch [15/15], batch: [56533/59184, loss: 4.9570]\n",
            "Epoch [15/15], batch: [56534/59184, loss: 5.3354]\n",
            "Epoch [15/15], batch: [56535/59184, loss: 6.1080]\n",
            "Epoch [15/15], batch: [56536/59184, loss: 4.9980]\n",
            "Epoch [15/15], batch: [56537/59184, loss: 5.6828]\n",
            "Epoch [15/15], batch: [56538/59184, loss: 6.4705]\n",
            "Epoch [15/15], batch: [56539/59184, loss: 7.4410]\n",
            "Epoch [15/15], batch: [56540/59184, loss: 6.9771]\n",
            "Epoch [15/15], batch: [56541/59184, loss: 6.5683]\n",
            "Epoch [15/15], batch: [56542/59184, loss: 6.2597]\n",
            "Epoch [15/15], batch: [56543/59184, loss: 6.3101]\n",
            "Epoch [15/15], batch: [56544/59184, loss: 4.9118]\n",
            "Epoch [15/15], batch: [56545/59184, loss: 5.2057]\n",
            "Epoch [15/15], batch: [56546/59184, loss: 6.7515]\n",
            "Epoch [15/15], batch: [56547/59184, loss: 5.5429]\n",
            "Epoch [15/15], batch: [56548/59184, loss: 5.5303]\n",
            "Epoch [15/15], batch: [56549/59184, loss: 5.8995]\n",
            "Epoch [15/15], batch: [56550/59184, loss: 6.8214]\n",
            "Epoch [15/15], batch: [56551/59184, loss: 7.0094]\n",
            "Epoch [15/15], batch: [56552/59184, loss: 6.1053]\n",
            "Epoch [15/15], batch: [56553/59184, loss: 6.7960]\n",
            "Epoch [15/15], batch: [56554/59184, loss: 5.8535]\n",
            "Epoch [15/15], batch: [56555/59184, loss: 6.5764]\n",
            "Epoch [15/15], batch: [56556/59184, loss: 6.4702]\n",
            "Epoch [15/15], batch: [56557/59184, loss: 5.4521]\n",
            "Epoch [15/15], batch: [56558/59184, loss: 7.8117]\n",
            "Epoch [15/15], batch: [56559/59184, loss: 5.8530]\n",
            "Epoch [15/15], batch: [56560/59184, loss: 6.6640]\n",
            "Epoch [15/15], batch: [56561/59184, loss: 6.7148]\n",
            "Epoch [15/15], batch: [56562/59184, loss: 4.7351]\n",
            "Epoch [15/15], batch: [56563/59184, loss: 5.6411]\n",
            "Epoch [15/15], batch: [56564/59184, loss: 5.4359]\n",
            "Epoch [15/15], batch: [56565/59184, loss: 4.2931]\n",
            "Epoch [15/15], batch: [56566/59184, loss: 5.1164]\n",
            "Epoch [15/15], batch: [56567/59184, loss: 5.1638]\n",
            "Epoch [15/15], batch: [56568/59184, loss: 6.9596]\n",
            "Epoch [15/15], batch: [56569/59184, loss: 5.2352]\n",
            "Epoch [15/15], batch: [56570/59184, loss: 6.4625]\n",
            "Epoch [15/15], batch: [56571/59184, loss: 5.7791]\n",
            "Epoch [15/15], batch: [56572/59184, loss: 5.8559]\n",
            "Epoch [15/15], batch: [56573/59184, loss: 5.4920]\n",
            "Epoch [15/15], batch: [56574/59184, loss: 5.2723]\n",
            "Epoch [15/15], batch: [56575/59184, loss: 5.1129]\n",
            "Epoch [15/15], batch: [56576/59184, loss: 2.8702]\n",
            "Epoch [15/15], batch: [56577/59184, loss: 6.1214]\n",
            "Epoch [15/15], batch: [56578/59184, loss: 5.9758]\n",
            "Epoch [15/15], batch: [56579/59184, loss: 7.1755]\n",
            "Epoch [15/15], batch: [56580/59184, loss: 5.8944]\n",
            "Epoch [15/15], batch: [56581/59184, loss: 6.7031]\n",
            "Epoch [15/15], batch: [56582/59184, loss: 6.0195]\n",
            "Epoch [15/15], batch: [56583/59184, loss: 4.6550]\n",
            "Epoch [15/15], batch: [56584/59184, loss: 5.2861]\n",
            "Epoch [15/15], batch: [56585/59184, loss: 4.0264]\n",
            "Epoch [15/15], batch: [56586/59184, loss: 3.6416]\n",
            "Epoch [15/15], batch: [56587/59184, loss: 5.5279]\n",
            "Epoch [15/15], batch: [56588/59184, loss: 7.7399]\n",
            "Epoch [15/15], batch: [56589/59184, loss: 6.9358]\n",
            "Epoch [15/15], batch: [56590/59184, loss: 7.5027]\n",
            "Epoch [15/15], batch: [56591/59184, loss: 7.4800]\n",
            "Epoch [15/15], batch: [56592/59184, loss: 5.8038]\n",
            "Epoch [15/15], batch: [56593/59184, loss: 7.3338]\n",
            "Epoch [15/15], batch: [56594/59184, loss: 4.8065]\n",
            "Epoch [15/15], batch: [56595/59184, loss: 4.8868]\n",
            "Epoch [15/15], batch: [56596/59184, loss: 6.9876]\n",
            "Epoch [15/15], batch: [56597/59184, loss: 6.3795]\n",
            "Epoch [15/15], batch: [56598/59184, loss: 5.8549]\n",
            "Epoch [15/15], batch: [56599/59184, loss: 5.5787]\n",
            "Epoch [15/15], batch: [56600/59184, loss: 5.8169]\n",
            "Epoch [15/15], batch: [56601/59184, loss: 5.0003]\n",
            "Epoch [15/15], batch: [56602/59184, loss: 7.7552]\n",
            "Epoch [15/15], batch: [56603/59184, loss: 6.2151]\n",
            "Epoch [15/15], batch: [56604/59184, loss: 6.7635]\n",
            "Epoch [15/15], batch: [56605/59184, loss: 4.7260]\n",
            "Epoch [15/15], batch: [56606/59184, loss: 6.3943]\n",
            "Epoch [15/15], batch: [56607/59184, loss: 6.9524]\n",
            "Epoch [15/15], batch: [56608/59184, loss: 4.7631]\n",
            "Epoch [15/15], batch: [56609/59184, loss: 5.3601]\n",
            "Epoch [15/15], batch: [56610/59184, loss: 4.4708]\n",
            "Epoch [15/15], batch: [56611/59184, loss: 5.8351]\n",
            "Epoch [15/15], batch: [56612/59184, loss: 7.1949]\n",
            "Epoch [15/15], batch: [56613/59184, loss: 6.2807]\n",
            "Epoch [15/15], batch: [56614/59184, loss: 7.1232]\n",
            "Epoch [15/15], batch: [56615/59184, loss: 5.0688]\n",
            "Epoch [15/15], batch: [56616/59184, loss: 5.8169]\n",
            "Epoch [15/15], batch: [56617/59184, loss: 5.9064]\n",
            "Epoch [15/15], batch: [56618/59184, loss: 4.4206]\n",
            "Epoch [15/15], batch: [56619/59184, loss: 5.2654]\n",
            "Epoch [15/15], batch: [56620/59184, loss: 6.7557]\n",
            "Epoch [15/15], batch: [56621/59184, loss: 4.4235]\n",
            "Epoch [15/15], batch: [56622/59184, loss: 6.0756]\n",
            "Epoch [15/15], batch: [56623/59184, loss: 4.4325]\n",
            "Epoch [15/15], batch: [56624/59184, loss: 7.2837]\n",
            "Epoch [15/15], batch: [56625/59184, loss: 6.5290]\n",
            "Epoch [15/15], batch: [56626/59184, loss: 6.1457]\n",
            "Epoch [15/15], batch: [56627/59184, loss: 5.7133]\n",
            "Epoch [15/15], batch: [56628/59184, loss: 6.6390]\n",
            "Epoch [15/15], batch: [56629/59184, loss: 6.4516]\n",
            "Epoch [15/15], batch: [56630/59184, loss: 6.1852]\n",
            "Epoch [15/15], batch: [56631/59184, loss: 6.1808]\n",
            "Epoch [15/15], batch: [56632/59184, loss: 5.1008]\n",
            "Epoch [15/15], batch: [56633/59184, loss: 5.7645]\n",
            "Epoch [15/15], batch: [56634/59184, loss: 6.3145]\n",
            "Epoch [15/15], batch: [56635/59184, loss: 5.1441]\n",
            "Epoch [15/15], batch: [56636/59184, loss: 4.7660]\n",
            "Epoch [15/15], batch: [56637/59184, loss: 4.5929]\n",
            "Epoch [15/15], batch: [56638/59184, loss: 6.7275]\n",
            "Epoch [15/15], batch: [56639/59184, loss: 6.3180]\n",
            "Epoch [15/15], batch: [56640/59184, loss: 6.4597]\n",
            "Epoch [15/15], batch: [56641/59184, loss: 6.2738]\n",
            "Epoch [15/15], batch: [56642/59184, loss: 4.1109]\n",
            "Epoch [15/15], batch: [56643/59184, loss: 6.0030]\n",
            "Epoch [15/15], batch: [56644/59184, loss: 4.9745]\n",
            "Epoch [15/15], batch: [56645/59184, loss: 4.9013]\n",
            "Epoch [15/15], batch: [56646/59184, loss: 4.5754]\n",
            "Epoch [15/15], batch: [56647/59184, loss: 4.1406]\n",
            "Epoch [15/15], batch: [56648/59184, loss: 6.0591]\n",
            "Epoch [15/15], batch: [56649/59184, loss: 5.2614]\n",
            "Epoch [15/15], batch: [56650/59184, loss: 5.2675]\n",
            "Epoch [15/15], batch: [56651/59184, loss: 6.6555]\n",
            "Epoch [15/15], batch: [56652/59184, loss: 5.6602]\n",
            "Epoch [15/15], batch: [56653/59184, loss: 4.7989]\n",
            "Epoch [15/15], batch: [56654/59184, loss: 6.2022]\n",
            "Epoch [15/15], batch: [56655/59184, loss: 6.6366]\n",
            "Epoch [15/15], batch: [56656/59184, loss: 6.2132]\n",
            "Epoch [15/15], batch: [56657/59184, loss: 6.7080]\n",
            "Epoch [15/15], batch: [56658/59184, loss: 5.4201]\n",
            "Epoch [15/15], batch: [56659/59184, loss: 5.3736]\n",
            "Epoch [15/15], batch: [56660/59184, loss: 7.0836]\n",
            "Epoch [15/15], batch: [56661/59184, loss: 5.7475]\n",
            "Epoch [15/15], batch: [56662/59184, loss: 4.3578]\n",
            "Epoch [15/15], batch: [56663/59184, loss: 4.1602]\n",
            "Epoch [15/15], batch: [56664/59184, loss: 4.7551]\n",
            "Epoch [15/15], batch: [56665/59184, loss: 5.4612]\n",
            "Epoch [15/15], batch: [56666/59184, loss: 4.1282]\n",
            "Epoch [15/15], batch: [56667/59184, loss: 6.1622]\n",
            "Epoch [15/15], batch: [56668/59184, loss: 6.1607]\n",
            "Epoch [15/15], batch: [56669/59184, loss: 4.8024]\n",
            "Epoch [15/15], batch: [56670/59184, loss: 7.5329]\n",
            "Epoch [15/15], batch: [56671/59184, loss: 4.0870]\n",
            "Epoch [15/15], batch: [56672/59184, loss: 5.9952]\n",
            "Epoch [15/15], batch: [56673/59184, loss: 6.9593]\n",
            "Epoch [15/15], batch: [56674/59184, loss: 4.2266]\n",
            "Epoch [15/15], batch: [56675/59184, loss: 5.1834]\n",
            "Epoch [15/15], batch: [56676/59184, loss: 4.3754]\n",
            "Epoch [15/15], batch: [56677/59184, loss: 5.7873]\n",
            "Epoch [15/15], batch: [56678/59184, loss: 4.9023]\n",
            "Epoch [15/15], batch: [56679/59184, loss: 5.8354]\n",
            "Epoch [15/15], batch: [56680/59184, loss: 5.8389]\n",
            "Epoch [15/15], batch: [56681/59184, loss: 5.5329]\n",
            "Epoch [15/15], batch: [56682/59184, loss: 5.5255]\n",
            "Epoch [15/15], batch: [56683/59184, loss: 5.4046]\n",
            "Epoch [15/15], batch: [56684/59184, loss: 5.4192]\n",
            "Epoch [15/15], batch: [56685/59184, loss: 6.0734]\n",
            "Epoch [15/15], batch: [56686/59184, loss: 5.6956]\n",
            "Epoch [15/15], batch: [56687/59184, loss: 6.7788]\n",
            "Epoch [15/15], batch: [56688/59184, loss: 5.7951]\n",
            "Epoch [15/15], batch: [56689/59184, loss: 2.5892]\n",
            "Epoch [15/15], batch: [56690/59184, loss: 5.9316]\n",
            "Epoch [15/15], batch: [56691/59184, loss: 5.5332]\n",
            "Epoch [15/15], batch: [56692/59184, loss: 5.8574]\n",
            "Epoch [15/15], batch: [56693/59184, loss: 5.7014]\n",
            "Epoch [15/15], batch: [56694/59184, loss: 4.6507]\n",
            "Epoch [15/15], batch: [56695/59184, loss: 5.5977]\n",
            "Epoch [15/15], batch: [56696/59184, loss: 5.7360]\n",
            "Epoch [15/15], batch: [56697/59184, loss: 7.0070]\n",
            "Epoch [15/15], batch: [56698/59184, loss: 5.2542]\n",
            "Epoch [15/15], batch: [56699/59184, loss: 7.1556]\n",
            "Epoch [15/15], batch: [56700/59184, loss: 7.0161]\n",
            "Epoch [15/15], batch: [56701/59184, loss: 5.4254]\n",
            "Epoch [15/15], batch: [56702/59184, loss: 5.4084]\n",
            "Epoch [15/15], batch: [56703/59184, loss: 3.7851]\n",
            "Epoch [15/15], batch: [56704/59184, loss: 5.2447]\n",
            "Epoch [15/15], batch: [56705/59184, loss: 4.2843]\n",
            "Epoch [15/15], batch: [56706/59184, loss: 6.4845]\n",
            "Epoch [15/15], batch: [56707/59184, loss: 5.1205]\n",
            "Epoch [15/15], batch: [56708/59184, loss: 5.5468]\n",
            "Epoch [15/15], batch: [56709/59184, loss: 4.5151]\n",
            "Epoch [15/15], batch: [56710/59184, loss: 5.5902]\n",
            "Epoch [15/15], batch: [56711/59184, loss: 4.4948]\n",
            "Epoch [15/15], batch: [56712/59184, loss: 4.6938]\n",
            "Epoch [15/15], batch: [56713/59184, loss: 5.7686]\n",
            "Epoch [15/15], batch: [56714/59184, loss: 5.9536]\n",
            "Epoch [15/15], batch: [56715/59184, loss: 5.6099]\n",
            "Epoch [15/15], batch: [56716/59184, loss: 6.8460]\n",
            "Epoch [15/15], batch: [56717/59184, loss: 5.8390]\n",
            "Epoch [15/15], batch: [56718/59184, loss: 6.5559]\n",
            "Epoch [15/15], batch: [56719/59184, loss: 5.7961]\n",
            "Epoch [15/15], batch: [56720/59184, loss: 6.0171]\n",
            "Epoch [15/15], batch: [56721/59184, loss: 6.0424]\n",
            "Epoch [15/15], batch: [56722/59184, loss: 6.0772]\n",
            "Epoch [15/15], batch: [56723/59184, loss: 4.9163]\n",
            "Epoch [15/15], batch: [56724/59184, loss: 4.1407]\n",
            "Epoch [15/15], batch: [56725/59184, loss: 6.9821]\n",
            "Epoch [15/15], batch: [56726/59184, loss: 5.9832]\n",
            "Epoch [15/15], batch: [56727/59184, loss: 5.9856]\n",
            "Epoch [15/15], batch: [56728/59184, loss: 5.3563]\n",
            "Epoch [15/15], batch: [56729/59184, loss: 5.3453]\n",
            "Epoch [15/15], batch: [56730/59184, loss: 6.3260]\n",
            "Epoch [15/15], batch: [56731/59184, loss: 5.9171]\n",
            "Epoch [15/15], batch: [56732/59184, loss: 6.3450]\n",
            "Epoch [15/15], batch: [56733/59184, loss: 6.7364]\n",
            "Epoch [15/15], batch: [56734/59184, loss: 5.7965]\n",
            "Epoch [15/15], batch: [56735/59184, loss: 7.0626]\n",
            "Epoch [15/15], batch: [56736/59184, loss: 5.9072]\n",
            "Epoch [15/15], batch: [56737/59184, loss: 5.4075]\n",
            "Epoch [15/15], batch: [56738/59184, loss: 6.2775]\n",
            "Epoch [15/15], batch: [56739/59184, loss: 6.4353]\n",
            "Epoch [15/15], batch: [56740/59184, loss: 5.0927]\n",
            "Epoch [15/15], batch: [56741/59184, loss: 6.1819]\n",
            "Epoch [15/15], batch: [56742/59184, loss: 7.7587]\n",
            "Epoch [15/15], batch: [56743/59184, loss: 7.5416]\n",
            "Epoch [15/15], batch: [56744/59184, loss: 6.8166]\n",
            "Epoch [15/15], batch: [56745/59184, loss: 4.6730]\n",
            "Epoch [15/15], batch: [56746/59184, loss: 5.2998]\n",
            "Epoch [15/15], batch: [56747/59184, loss: 6.4933]\n",
            "Epoch [15/15], batch: [56748/59184, loss: 4.5720]\n",
            "Epoch [15/15], batch: [56749/59184, loss: 5.5398]\n",
            "Epoch [15/15], batch: [56750/59184, loss: 4.8355]\n",
            "Epoch [15/15], batch: [56751/59184, loss: 4.0671]\n",
            "Epoch [15/15], batch: [56752/59184, loss: 5.8806]\n",
            "Epoch [15/15], batch: [56753/59184, loss: 5.9861]\n",
            "Epoch [15/15], batch: [56754/59184, loss: 5.7788]\n",
            "Epoch [15/15], batch: [56755/59184, loss: 5.8734]\n",
            "Epoch [15/15], batch: [56756/59184, loss: 6.3790]\n",
            "Epoch [15/15], batch: [56757/59184, loss: 6.6409]\n",
            "Epoch [15/15], batch: [56758/59184, loss: 5.1308]\n",
            "Epoch [15/15], batch: [56759/59184, loss: 5.8547]\n",
            "Epoch [15/15], batch: [56760/59184, loss: 6.5490]\n",
            "Epoch [15/15], batch: [56761/59184, loss: 5.2442]\n",
            "Epoch [15/15], batch: [56762/59184, loss: 4.1562]\n",
            "Epoch [15/15], batch: [56763/59184, loss: 5.2267]\n",
            "Epoch [15/15], batch: [56764/59184, loss: 6.8878]\n",
            "Epoch [15/15], batch: [56765/59184, loss: 5.8473]\n",
            "Epoch [15/15], batch: [56766/59184, loss: 6.1374]\n",
            "Epoch [15/15], batch: [56767/59184, loss: 6.6632]\n",
            "Epoch [15/15], batch: [56768/59184, loss: 5.5511]\n",
            "Epoch [15/15], batch: [56769/59184, loss: 5.8117]\n",
            "Epoch [15/15], batch: [56770/59184, loss: 6.5210]\n",
            "Epoch [15/15], batch: [56771/59184, loss: 6.3539]\n",
            "Epoch [15/15], batch: [56772/59184, loss: 5.9616]\n",
            "Epoch [15/15], batch: [56773/59184, loss: 6.6932]\n",
            "Epoch [15/15], batch: [56774/59184, loss: 5.6330]\n",
            "Epoch [15/15], batch: [56775/59184, loss: 7.1706]\n",
            "Epoch [15/15], batch: [56776/59184, loss: 6.7909]\n",
            "Epoch [15/15], batch: [56777/59184, loss: 5.5851]\n",
            "Epoch [15/15], batch: [56778/59184, loss: 5.1705]\n",
            "Epoch [15/15], batch: [56779/59184, loss: 6.5668]\n",
            "Epoch [15/15], batch: [56780/59184, loss: 7.0066]\n",
            "Epoch [15/15], batch: [56781/59184, loss: 5.8920]\n",
            "Epoch [15/15], batch: [56782/59184, loss: 7.8742]\n",
            "Epoch [15/15], batch: [56783/59184, loss: 5.3772]\n",
            "Epoch [15/15], batch: [56784/59184, loss: 6.0940]\n",
            "Epoch [15/15], batch: [56785/59184, loss: 4.9063]\n",
            "Epoch [15/15], batch: [56786/59184, loss: 7.6443]\n",
            "Epoch [15/15], batch: [56787/59184, loss: 5.9382]\n",
            "Epoch [15/15], batch: [56788/59184, loss: 7.9657]\n",
            "Epoch [15/15], batch: [56789/59184, loss: 6.7177]\n",
            "Epoch [15/15], batch: [56790/59184, loss: 6.1749]\n",
            "Epoch [15/15], batch: [56791/59184, loss: 5.6402]\n",
            "Epoch [15/15], batch: [56792/59184, loss: 5.5608]\n",
            "Epoch [15/15], batch: [56793/59184, loss: 4.0308]\n",
            "Epoch [15/15], batch: [56794/59184, loss: 5.9452]\n",
            "Epoch [15/15], batch: [56795/59184, loss: 6.5526]\n",
            "Epoch [15/15], batch: [56796/59184, loss: 5.8646]\n",
            "Epoch [15/15], batch: [56797/59184, loss: 6.0852]\n",
            "Epoch [15/15], batch: [56798/59184, loss: 6.3206]\n",
            "Epoch [15/15], batch: [56799/59184, loss: 5.8207]\n",
            "Epoch [15/15], batch: [56800/59184, loss: 6.4995]\n",
            "Epoch [15/15], batch: [56801/59184, loss: 5.2857]\n",
            "Epoch [15/15], batch: [56802/59184, loss: 5.7534]\n",
            "Epoch [15/15], batch: [56803/59184, loss: 6.0172]\n",
            "Epoch [15/15], batch: [56804/59184, loss: 5.4829]\n",
            "Epoch [15/15], batch: [56805/59184, loss: 5.5337]\n",
            "Epoch [15/15], batch: [56806/59184, loss: 6.5012]\n",
            "Epoch [15/15], batch: [56807/59184, loss: 6.4759]\n",
            "Epoch [15/15], batch: [56808/59184, loss: 6.7469]\n",
            "Epoch [15/15], batch: [56809/59184, loss: 6.8025]\n",
            "Epoch [15/15], batch: [56810/59184, loss: 5.4851]\n",
            "Epoch [15/15], batch: [56811/59184, loss: 6.5435]\n",
            "Epoch [15/15], batch: [56812/59184, loss: 5.6949]\n",
            "Epoch [15/15], batch: [56813/59184, loss: 6.7939]\n",
            "Epoch [15/15], batch: [56814/59184, loss: 5.6091]\n",
            "Epoch [15/15], batch: [56815/59184, loss: 6.9754]\n",
            "Epoch [15/15], batch: [56816/59184, loss: 6.9887]\n",
            "Epoch [15/15], batch: [56817/59184, loss: 7.6143]\n",
            "Epoch [15/15], batch: [56818/59184, loss: 5.4045]\n",
            "Epoch [15/15], batch: [56819/59184, loss: 6.1795]\n",
            "Epoch [15/15], batch: [56820/59184, loss: 6.9909]\n",
            "Epoch [15/15], batch: [56821/59184, loss: 4.6626]\n",
            "Epoch [15/15], batch: [56822/59184, loss: 5.3257]\n",
            "Epoch [15/15], batch: [56823/59184, loss: 5.1509]\n",
            "Epoch [15/15], batch: [56824/59184, loss: 6.8376]\n",
            "Epoch [15/15], batch: [56825/59184, loss: 7.3375]\n",
            "Epoch [15/15], batch: [56826/59184, loss: 4.5214]\n",
            "Epoch [15/15], batch: [56827/59184, loss: 6.8277]\n",
            "Epoch [15/15], batch: [56828/59184, loss: 5.5656]\n",
            "Epoch [15/15], batch: [56829/59184, loss: 3.8447]\n",
            "Epoch [15/15], batch: [56830/59184, loss: 6.0002]\n",
            "Epoch [15/15], batch: [56831/59184, loss: 6.5910]\n",
            "Epoch [15/15], batch: [56832/59184, loss: 4.3500]\n",
            "Epoch [15/15], batch: [56833/59184, loss: 4.9967]\n",
            "Epoch [15/15], batch: [56834/59184, loss: 6.1372]\n",
            "Epoch [15/15], batch: [56835/59184, loss: 4.6723]\n",
            "Epoch [15/15], batch: [56836/59184, loss: 6.4895]\n",
            "Epoch [15/15], batch: [56837/59184, loss: 6.9671]\n",
            "Epoch [15/15], batch: [56838/59184, loss: 6.1906]\n",
            "Epoch [15/15], batch: [56839/59184, loss: 5.8974]\n",
            "Epoch [15/15], batch: [56840/59184, loss: 5.8442]\n",
            "Epoch [15/15], batch: [56841/59184, loss: 5.8265]\n",
            "Epoch [15/15], batch: [56842/59184, loss: 6.3264]\n",
            "Epoch [15/15], batch: [56843/59184, loss: 6.0087]\n",
            "Epoch [15/15], batch: [56844/59184, loss: 4.2318]\n",
            "Epoch [15/15], batch: [56845/59184, loss: 4.8374]\n",
            "Epoch [15/15], batch: [56846/59184, loss: 5.3987]\n",
            "Epoch [15/15], batch: [56847/59184, loss: 6.6211]\n",
            "Epoch [15/15], batch: [56848/59184, loss: 6.5677]\n",
            "Epoch [15/15], batch: [56849/59184, loss: 5.4185]\n",
            "Epoch [15/15], batch: [56850/59184, loss: 7.4907]\n",
            "Epoch [15/15], batch: [56851/59184, loss: 7.2749]\n",
            "Epoch [15/15], batch: [56852/59184, loss: 5.4442]\n",
            "Epoch [15/15], batch: [56853/59184, loss: 5.3748]\n",
            "Epoch [15/15], batch: [56854/59184, loss: 6.5149]\n",
            "Epoch [15/15], batch: [56855/59184, loss: 6.2587]\n",
            "Epoch [15/15], batch: [56856/59184, loss: 4.3662]\n",
            "Epoch [15/15], batch: [56857/59184, loss: 6.4119]\n",
            "Epoch [15/15], batch: [56858/59184, loss: 5.4272]\n",
            "Epoch [15/15], batch: [56859/59184, loss: 5.7985]\n",
            "Epoch [15/15], batch: [56860/59184, loss: 4.5255]\n",
            "Epoch [15/15], batch: [56861/59184, loss: 4.1815]\n",
            "Epoch [15/15], batch: [56862/59184, loss: 3.9263]\n",
            "Epoch [15/15], batch: [56863/59184, loss: 7.3934]\n",
            "Epoch [15/15], batch: [56864/59184, loss: 4.9247]\n",
            "Epoch [15/15], batch: [56865/59184, loss: 6.8269]\n",
            "Epoch [15/15], batch: [56866/59184, loss: 6.3217]\n",
            "Epoch [15/15], batch: [56867/59184, loss: 7.1236]\n",
            "Epoch [15/15], batch: [56868/59184, loss: 5.9592]\n",
            "Epoch [15/15], batch: [56869/59184, loss: 6.4740]\n",
            "Epoch [15/15], batch: [56870/59184, loss: 4.5577]\n",
            "Epoch [15/15], batch: [56871/59184, loss: 6.1334]\n",
            "Epoch [15/15], batch: [56872/59184, loss: 7.2547]\n",
            "Epoch [15/15], batch: [56873/59184, loss: 3.9416]\n",
            "Epoch [15/15], batch: [56874/59184, loss: 4.5144]\n",
            "Epoch [15/15], batch: [56875/59184, loss: 5.2484]\n",
            "Epoch [15/15], batch: [56876/59184, loss: 5.7267]\n",
            "Epoch [15/15], batch: [56877/59184, loss: 6.2271]\n",
            "Epoch [15/15], batch: [56878/59184, loss: 4.8073]\n",
            "Epoch [15/15], batch: [56879/59184, loss: 6.1066]\n",
            "Epoch [15/15], batch: [56880/59184, loss: 5.2480]\n",
            "Epoch [15/15], batch: [56881/59184, loss: 6.0860]\n",
            "Epoch [15/15], batch: [56882/59184, loss: 5.7272]\n",
            "Epoch [15/15], batch: [56883/59184, loss: 5.6402]\n",
            "Epoch [15/15], batch: [56884/59184, loss: 5.8261]\n",
            "Epoch [15/15], batch: [56885/59184, loss: 5.9502]\n",
            "Epoch [15/15], batch: [56886/59184, loss: 6.2057]\n",
            "Epoch [15/15], batch: [56887/59184, loss: 7.1873]\n",
            "Epoch [15/15], batch: [56888/59184, loss: 6.0267]\n",
            "Epoch [15/15], batch: [56889/59184, loss: 6.6728]\n",
            "Epoch [15/15], batch: [56890/59184, loss: 5.3755]\n",
            "Epoch [15/15], batch: [56891/59184, loss: 5.6037]\n",
            "Epoch [15/15], batch: [56892/59184, loss: 5.9662]\n",
            "Epoch [15/15], batch: [56893/59184, loss: 5.2627]\n",
            "Epoch [15/15], batch: [56894/59184, loss: 5.7219]\n",
            "Epoch [15/15], batch: [56895/59184, loss: 8.0301]\n",
            "Epoch [15/15], batch: [56896/59184, loss: 5.3117]\n",
            "Epoch [15/15], batch: [56897/59184, loss: 6.1302]\n",
            "Epoch [15/15], batch: [56898/59184, loss: 6.8433]\n",
            "Epoch [15/15], batch: [56899/59184, loss: 6.0169]\n",
            "Epoch [15/15], batch: [56900/59184, loss: 5.9266]\n",
            "Epoch [15/15], batch: [56901/59184, loss: 5.0619]\n",
            "Epoch [15/15], batch: [56902/59184, loss: 4.8623]\n",
            "Epoch [15/15], batch: [56903/59184, loss: 6.1589]\n",
            "Epoch [15/15], batch: [56904/59184, loss: 5.4252]\n",
            "Epoch [15/15], batch: [56905/59184, loss: 6.1833]\n",
            "Epoch [15/15], batch: [56906/59184, loss: 5.4604]\n",
            "Epoch [15/15], batch: [56907/59184, loss: 6.8842]\n",
            "Epoch [15/15], batch: [56908/59184, loss: 5.1066]\n",
            "Epoch [15/15], batch: [56909/59184, loss: 5.9315]\n",
            "Epoch [15/15], batch: [56910/59184, loss: 4.8078]\n",
            "Epoch [15/15], batch: [56911/59184, loss: 5.1869]\n",
            "Epoch [15/15], batch: [56912/59184, loss: 7.1359]\n",
            "Epoch [15/15], batch: [56913/59184, loss: 6.6636]\n",
            "Epoch [15/15], batch: [56914/59184, loss: 5.1697]\n",
            "Epoch [15/15], batch: [56915/59184, loss: 5.8353]\n",
            "Epoch [15/15], batch: [56916/59184, loss: 5.7129]\n",
            "Epoch [15/15], batch: [56917/59184, loss: 5.1996]\n",
            "Epoch [15/15], batch: [56918/59184, loss: 5.3972]\n",
            "Epoch [15/15], batch: [56919/59184, loss: 6.7638]\n",
            "Epoch [15/15], batch: [56920/59184, loss: 5.9622]\n",
            "Epoch [15/15], batch: [56921/59184, loss: 6.0274]\n",
            "Epoch [15/15], batch: [56922/59184, loss: 5.8918]\n",
            "Epoch [15/15], batch: [56923/59184, loss: 5.9077]\n",
            "Epoch [15/15], batch: [56924/59184, loss: 6.1990]\n",
            "Epoch [15/15], batch: [56925/59184, loss: 4.6853]\n",
            "Epoch [15/15], batch: [56926/59184, loss: 6.3365]\n",
            "Epoch [15/15], batch: [56927/59184, loss: 5.9862]\n",
            "Epoch [15/15], batch: [56928/59184, loss: 6.3310]\n",
            "Epoch [15/15], batch: [56929/59184, loss: 4.9391]\n",
            "Epoch [15/15], batch: [56930/59184, loss: 6.3459]\n",
            "Epoch [15/15], batch: [56931/59184, loss: 5.7751]\n",
            "Epoch [15/15], batch: [56932/59184, loss: 5.9377]\n",
            "Epoch [15/15], batch: [56933/59184, loss: 5.8981]\n",
            "Epoch [15/15], batch: [56934/59184, loss: 5.6021]\n",
            "Epoch [15/15], batch: [56935/59184, loss: 6.3658]\n",
            "Epoch [15/15], batch: [56936/59184, loss: 4.9845]\n",
            "Epoch [15/15], batch: [56937/59184, loss: 5.7445]\n",
            "Epoch [15/15], batch: [56938/59184, loss: 6.3446]\n",
            "Epoch [15/15], batch: [56939/59184, loss: 6.4202]\n",
            "Epoch [15/15], batch: [56940/59184, loss: 5.5112]\n",
            "Epoch [15/15], batch: [56941/59184, loss: 6.8025]\n",
            "Epoch [15/15], batch: [56942/59184, loss: 5.3809]\n",
            "Epoch [15/15], batch: [56943/59184, loss: 6.0078]\n",
            "Epoch [15/15], batch: [56944/59184, loss: 6.8049]\n",
            "Epoch [15/15], batch: [56945/59184, loss: 7.2953]\n",
            "Epoch [15/15], batch: [56946/59184, loss: 6.3258]\n",
            "Epoch [15/15], batch: [56947/59184, loss: 6.7153]\n",
            "Epoch [15/15], batch: [56948/59184, loss: 3.9272]\n",
            "Epoch [15/15], batch: [56949/59184, loss: 7.2572]\n",
            "Epoch [15/15], batch: [56950/59184, loss: 5.9519]\n",
            "Epoch [15/15], batch: [56951/59184, loss: 6.5891]\n",
            "Epoch [15/15], batch: [56952/59184, loss: 5.8014]\n",
            "Epoch [15/15], batch: [56953/59184, loss: 4.9105]\n",
            "Epoch [15/15], batch: [56954/59184, loss: 5.5480]\n",
            "Epoch [15/15], batch: [56955/59184, loss: 6.1664]\n",
            "Epoch [15/15], batch: [56956/59184, loss: 4.4067]\n",
            "Epoch [15/15], batch: [56957/59184, loss: 7.0562]\n",
            "Epoch [15/15], batch: [56958/59184, loss: 5.1390]\n",
            "Epoch [15/15], batch: [56959/59184, loss: 5.5366]\n",
            "Epoch [15/15], batch: [56960/59184, loss: 6.0749]\n",
            "Epoch [15/15], batch: [56961/59184, loss: 5.4208]\n",
            "Epoch [15/15], batch: [56962/59184, loss: 5.6576]\n",
            "Epoch [15/15], batch: [56963/59184, loss: 6.0791]\n",
            "Epoch [15/15], batch: [56964/59184, loss: 6.5877]\n",
            "Epoch [15/15], batch: [56965/59184, loss: 4.5667]\n",
            "Epoch [15/15], batch: [56966/59184, loss: 6.5596]\n",
            "Epoch [15/15], batch: [56967/59184, loss: 5.6402]\n",
            "Epoch [15/15], batch: [56968/59184, loss: 4.5409]\n",
            "Epoch [15/15], batch: [56969/59184, loss: 4.1984]\n",
            "Epoch [15/15], batch: [56970/59184, loss: 5.7159]\n",
            "Epoch [15/15], batch: [56971/59184, loss: 4.4724]\n",
            "Epoch [15/15], batch: [56972/59184, loss: 6.9526]\n",
            "Epoch [15/15], batch: [56973/59184, loss: 6.0117]\n",
            "Epoch [15/15], batch: [56974/59184, loss: 4.4864]\n",
            "Epoch [15/15], batch: [56975/59184, loss: 5.2333]\n",
            "Epoch [15/15], batch: [56976/59184, loss: 6.4998]\n",
            "Epoch [15/15], batch: [56977/59184, loss: 5.3051]\n",
            "Epoch [15/15], batch: [56978/59184, loss: 4.8142]\n",
            "Epoch [15/15], batch: [56979/59184, loss: 6.3215]\n",
            "Epoch [15/15], batch: [56980/59184, loss: 6.7878]\n",
            "Epoch [15/15], batch: [56981/59184, loss: 5.5545]\n",
            "Epoch [15/15], batch: [56982/59184, loss: 4.4045]\n",
            "Epoch [15/15], batch: [56983/59184, loss: 4.2209]\n",
            "Epoch [15/15], batch: [56984/59184, loss: 4.1753]\n",
            "Epoch [15/15], batch: [56985/59184, loss: 7.2399]\n",
            "Epoch [15/15], batch: [56986/59184, loss: 5.9109]\n",
            "Epoch [15/15], batch: [56987/59184, loss: 5.4731]\n",
            "Epoch [15/15], batch: [56988/59184, loss: 6.2022]\n",
            "Epoch [15/15], batch: [56989/59184, loss: 5.8741]\n",
            "Epoch [15/15], batch: [56990/59184, loss: 6.8644]\n",
            "Epoch [15/15], batch: [56991/59184, loss: 4.4411]\n",
            "Epoch [15/15], batch: [56992/59184, loss: 5.2730]\n",
            "Epoch [15/15], batch: [56993/59184, loss: 5.6961]\n",
            "Epoch [15/15], batch: [56994/59184, loss: 5.4654]\n",
            "Epoch [15/15], batch: [56995/59184, loss: 5.3005]\n",
            "Epoch [15/15], batch: [56996/59184, loss: 4.7873]\n",
            "Epoch [15/15], batch: [56997/59184, loss: 7.3211]\n",
            "Epoch [15/15], batch: [56998/59184, loss: 4.7643]\n",
            "Epoch [15/15], batch: [56999/59184, loss: 4.0334]\n",
            "Epoch [15/15], batch: [57000/59184, loss: 5.9660]\n",
            "Epoch [15/15], batch: [57001/59184, loss: 4.9299]\n",
            "Epoch [15/15], batch: [57002/59184, loss: 5.3187]\n",
            "Epoch [15/15], batch: [57003/59184, loss: 6.2041]\n",
            "Epoch [15/15], batch: [57004/59184, loss: 4.6813]\n",
            "Epoch [15/15], batch: [57005/59184, loss: 5.3492]\n",
            "Epoch [15/15], batch: [57006/59184, loss: 3.4365]\n",
            "Epoch [15/15], batch: [57007/59184, loss: 5.9868]\n",
            "Epoch [15/15], batch: [57008/59184, loss: 4.5793]\n",
            "Epoch [15/15], batch: [57009/59184, loss: 6.7237]\n",
            "Epoch [15/15], batch: [57010/59184, loss: 6.6357]\n",
            "Epoch [15/15], batch: [57011/59184, loss: 5.5738]\n",
            "Epoch [15/15], batch: [57012/59184, loss: 4.8704]\n",
            "Epoch [15/15], batch: [57013/59184, loss: 5.1518]\n",
            "Epoch [15/15], batch: [57014/59184, loss: 4.5401]\n",
            "Epoch [15/15], batch: [57015/59184, loss: 6.8532]\n",
            "Epoch [15/15], batch: [57016/59184, loss: 5.9862]\n",
            "Epoch [15/15], batch: [57017/59184, loss: 6.3464]\n",
            "Epoch [15/15], batch: [57018/59184, loss: 6.0968]\n",
            "Epoch [15/15], batch: [57019/59184, loss: 6.8484]\n",
            "Epoch [15/15], batch: [57020/59184, loss: 7.0173]\n",
            "Epoch [15/15], batch: [57021/59184, loss: 4.0037]\n",
            "Epoch [15/15], batch: [57022/59184, loss: 6.8051]\n",
            "Epoch [15/15], batch: [57023/59184, loss: 5.5926]\n",
            "Epoch [15/15], batch: [57024/59184, loss: 4.4420]\n",
            "Epoch [15/15], batch: [57025/59184, loss: 6.0393]\n",
            "Epoch [15/15], batch: [57026/59184, loss: 4.2323]\n",
            "Epoch [15/15], batch: [57027/59184, loss: 4.3544]\n",
            "Epoch [15/15], batch: [57028/59184, loss: 5.1128]\n",
            "Epoch [15/15], batch: [57029/59184, loss: 6.9847]\n",
            "Epoch [15/15], batch: [57030/59184, loss: 7.0221]\n",
            "Epoch [15/15], batch: [57031/59184, loss: 6.4333]\n",
            "Epoch [15/15], batch: [57032/59184, loss: 5.4404]\n",
            "Epoch [15/15], batch: [57033/59184, loss: 5.0865]\n",
            "Epoch [15/15], batch: [57034/59184, loss: 5.1966]\n",
            "Epoch [15/15], batch: [57035/59184, loss: 5.3640]\n",
            "Epoch [15/15], batch: [57036/59184, loss: 6.2409]\n",
            "Epoch [15/15], batch: [57037/59184, loss: 6.6480]\n",
            "Epoch [15/15], batch: [57038/59184, loss: 5.5026]\n",
            "Epoch [15/15], batch: [57039/59184, loss: 8.0609]\n",
            "Epoch [15/15], batch: [57040/59184, loss: 4.3042]\n",
            "Epoch [15/15], batch: [57041/59184, loss: 6.5289]\n",
            "Epoch [15/15], batch: [57042/59184, loss: 5.8289]\n",
            "Epoch [15/15], batch: [57043/59184, loss: 6.8601]\n",
            "Epoch [15/15], batch: [57044/59184, loss: 6.2168]\n",
            "Epoch [15/15], batch: [57045/59184, loss: 3.8457]\n",
            "Epoch [15/15], batch: [57046/59184, loss: 4.7731]\n",
            "Epoch [15/15], batch: [57047/59184, loss: 4.0239]\n",
            "Epoch [15/15], batch: [57048/59184, loss: 6.8689]\n",
            "Epoch [15/15], batch: [57049/59184, loss: 5.4143]\n",
            "Epoch [15/15], batch: [57050/59184, loss: 5.0497]\n",
            "Epoch [15/15], batch: [57051/59184, loss: 5.3572]\n",
            "Epoch [15/15], batch: [57052/59184, loss: 5.9241]\n",
            "Epoch [15/15], batch: [57053/59184, loss: 6.7645]\n",
            "Epoch [15/15], batch: [57054/59184, loss: 5.1978]\n",
            "Epoch [15/15], batch: [57055/59184, loss: 7.8782]\n",
            "Epoch [15/15], batch: [57056/59184, loss: 5.2797]\n",
            "Epoch [15/15], batch: [57057/59184, loss: 6.3140]\n",
            "Epoch [15/15], batch: [57058/59184, loss: 5.5909]\n",
            "Epoch [15/15], batch: [57059/59184, loss: 6.5616]\n",
            "Epoch [15/15], batch: [57060/59184, loss: 6.0008]\n",
            "Epoch [15/15], batch: [57061/59184, loss: 6.7352]\n",
            "Epoch [15/15], batch: [57062/59184, loss: 6.9106]\n",
            "Epoch [15/15], batch: [57063/59184, loss: 4.3433]\n",
            "Epoch [15/15], batch: [57064/59184, loss: 5.8017]\n",
            "Epoch [15/15], batch: [57065/59184, loss: 4.1406]\n",
            "Epoch [15/15], batch: [57066/59184, loss: 5.0813]\n",
            "Epoch [15/15], batch: [57067/59184, loss: 4.7568]\n",
            "Epoch [15/15], batch: [57068/59184, loss: 5.4352]\n",
            "Epoch [15/15], batch: [57069/59184, loss: 3.1782]\n",
            "Epoch [15/15], batch: [57070/59184, loss: 5.0910]\n",
            "Epoch [15/15], batch: [57071/59184, loss: 6.0268]\n",
            "Epoch [15/15], batch: [57072/59184, loss: 5.5126]\n",
            "Epoch [15/15], batch: [57073/59184, loss: 5.6580]\n",
            "Epoch [15/15], batch: [57074/59184, loss: 4.1048]\n",
            "Epoch [15/15], batch: [57075/59184, loss: 6.0131]\n",
            "Epoch [15/15], batch: [57076/59184, loss: 4.8005]\n",
            "Epoch [15/15], batch: [57077/59184, loss: 6.6265]\n",
            "Epoch [15/15], batch: [57078/59184, loss: 5.8711]\n",
            "Epoch [15/15], batch: [57079/59184, loss: 6.0991]\n",
            "Epoch [15/15], batch: [57080/59184, loss: 6.8579]\n",
            "Epoch [15/15], batch: [57081/59184, loss: 5.5566]\n",
            "Epoch [15/15], batch: [57082/59184, loss: 5.5074]\n",
            "Epoch [15/15], batch: [57083/59184, loss: 4.2816]\n",
            "Epoch [15/15], batch: [57084/59184, loss: 5.6000]\n",
            "Epoch [15/15], batch: [57085/59184, loss: 5.5464]\n",
            "Epoch [15/15], batch: [57086/59184, loss: 4.7597]\n",
            "Epoch [15/15], batch: [57087/59184, loss: 5.3057]\n",
            "Epoch [15/15], batch: [57088/59184, loss: 7.6128]\n",
            "Epoch [15/15], batch: [57089/59184, loss: 6.1838]\n",
            "Epoch [15/15], batch: [57090/59184, loss: 5.9305]\n",
            "Epoch [15/15], batch: [57091/59184, loss: 5.1145]\n",
            "Epoch [15/15], batch: [57092/59184, loss: 6.7141]\n",
            "Epoch [15/15], batch: [57093/59184, loss: 5.3695]\n",
            "Epoch [15/15], batch: [57094/59184, loss: 5.9739]\n",
            "Epoch [15/15], batch: [57095/59184, loss: 6.7632]\n",
            "Epoch [15/15], batch: [57096/59184, loss: 6.3064]\n",
            "Epoch [15/15], batch: [57097/59184, loss: 4.2971]\n",
            "Epoch [15/15], batch: [57098/59184, loss: 4.1264]\n",
            "Epoch [15/15], batch: [57099/59184, loss: 6.3547]\n",
            "Epoch [15/15], batch: [57100/59184, loss: 5.8206]\n",
            "Epoch [15/15], batch: [57101/59184, loss: 6.5412]\n",
            "Epoch [15/15], batch: [57102/59184, loss: 5.7300]\n",
            "Epoch [15/15], batch: [57103/59184, loss: 6.2916]\n",
            "Epoch [15/15], batch: [57104/59184, loss: 5.5290]\n",
            "Epoch [15/15], batch: [57105/59184, loss: 5.1334]\n",
            "Epoch [15/15], batch: [57106/59184, loss: 6.6906]\n",
            "Epoch [15/15], batch: [57107/59184, loss: 5.8142]\n",
            "Epoch [15/15], batch: [57108/59184, loss: 6.0678]\n",
            "Epoch [15/15], batch: [57109/59184, loss: 5.9195]\n",
            "Epoch [15/15], batch: [57110/59184, loss: 5.9823]\n",
            "Epoch [15/15], batch: [57111/59184, loss: 5.1974]\n",
            "Epoch [15/15], batch: [57112/59184, loss: 6.1975]\n",
            "Epoch [15/15], batch: [57113/59184, loss: 6.0420]\n",
            "Epoch [15/15], batch: [57114/59184, loss: 5.2553]\n",
            "Epoch [15/15], batch: [57115/59184, loss: 4.9196]\n",
            "Epoch [15/15], batch: [57116/59184, loss: 4.4805]\n",
            "Epoch [15/15], batch: [57117/59184, loss: 6.1901]\n",
            "Epoch [15/15], batch: [57118/59184, loss: 5.6152]\n",
            "Epoch [15/15], batch: [57119/59184, loss: 6.0902]\n",
            "Epoch [15/15], batch: [57120/59184, loss: 6.6798]\n",
            "Epoch [15/15], batch: [57121/59184, loss: 5.0845]\n",
            "Epoch [15/15], batch: [57122/59184, loss: 4.8983]\n",
            "Epoch [15/15], batch: [57123/59184, loss: 5.0525]\n",
            "Epoch [15/15], batch: [57124/59184, loss: 4.1876]\n",
            "Epoch [15/15], batch: [57125/59184, loss: 4.8639]\n",
            "Epoch [15/15], batch: [57126/59184, loss: 6.2681]\n",
            "Epoch [15/15], batch: [57127/59184, loss: 3.6852]\n",
            "Epoch [15/15], batch: [57128/59184, loss: 6.8777]\n",
            "Epoch [15/15], batch: [57129/59184, loss: 6.2303]\n",
            "Epoch [15/15], batch: [57130/59184, loss: 4.0743]\n",
            "Epoch [15/15], batch: [57131/59184, loss: 6.1100]\n",
            "Epoch [15/15], batch: [57132/59184, loss: 4.8251]\n",
            "Epoch [15/15], batch: [57133/59184, loss: 4.3457]\n",
            "Epoch [15/15], batch: [57134/59184, loss: 5.0333]\n",
            "Epoch [15/15], batch: [57135/59184, loss: 5.5278]\n",
            "Epoch [15/15], batch: [57136/59184, loss: 6.2926]\n",
            "Epoch [15/15], batch: [57137/59184, loss: 5.5638]\n",
            "Epoch [15/15], batch: [57138/59184, loss: 2.8551]\n",
            "Epoch [15/15], batch: [57139/59184, loss: 6.3814]\n",
            "Epoch [15/15], batch: [57140/59184, loss: 7.3841]\n",
            "Epoch [15/15], batch: [57141/59184, loss: 8.0229]\n",
            "Epoch [15/15], batch: [57142/59184, loss: 6.0081]\n",
            "Epoch [15/15], batch: [57143/59184, loss: 6.8750]\n",
            "Epoch [15/15], batch: [57144/59184, loss: 6.1836]\n",
            "Epoch [15/15], batch: [57145/59184, loss: 7.2785]\n",
            "Epoch [15/15], batch: [57146/59184, loss: 7.1890]\n",
            "Epoch [15/15], batch: [57147/59184, loss: 4.7480]\n",
            "Epoch [15/15], batch: [57148/59184, loss: 5.6758]\n",
            "Epoch [15/15], batch: [57149/59184, loss: 4.8030]\n",
            "Epoch [15/15], batch: [57150/59184, loss: 4.5871]\n",
            "Epoch [15/15], batch: [57151/59184, loss: 5.1604]\n",
            "Epoch [15/15], batch: [57152/59184, loss: 7.0287]\n",
            "Epoch [15/15], batch: [57153/59184, loss: 5.5040]\n",
            "Epoch [15/15], batch: [57154/59184, loss: 6.3651]\n",
            "Epoch [15/15], batch: [57155/59184, loss: 6.9619]\n",
            "Epoch [15/15], batch: [57156/59184, loss: 4.8563]\n",
            "Epoch [15/15], batch: [57157/59184, loss: 4.3222]\n",
            "Epoch [15/15], batch: [57158/59184, loss: 5.6949]\n",
            "Epoch [15/15], batch: [57159/59184, loss: 4.9193]\n",
            "Epoch [15/15], batch: [57160/59184, loss: 4.8097]\n",
            "Epoch [15/15], batch: [57161/59184, loss: 4.6820]\n",
            "Epoch [15/15], batch: [57162/59184, loss: 6.2708]\n",
            "Epoch [15/15], batch: [57163/59184, loss: 6.1882]\n",
            "Epoch [15/15], batch: [57164/59184, loss: 5.2256]\n",
            "Epoch [15/15], batch: [57165/59184, loss: 6.9395]\n",
            "Epoch [15/15], batch: [57166/59184, loss: 4.6796]\n",
            "Epoch [15/15], batch: [57167/59184, loss: 5.2314]\n",
            "Epoch [15/15], batch: [57168/59184, loss: 6.0334]\n",
            "Epoch [15/15], batch: [57169/59184, loss: 5.1578]\n",
            "Epoch [15/15], batch: [57170/59184, loss: 7.3100]\n",
            "Epoch [15/15], batch: [57171/59184, loss: 4.8775]\n",
            "Epoch [15/15], batch: [57172/59184, loss: 6.8728]\n",
            "Epoch [15/15], batch: [57173/59184, loss: 5.3581]\n",
            "Epoch [15/15], batch: [57174/59184, loss: 4.8320]\n",
            "Epoch [15/15], batch: [57175/59184, loss: 6.2392]\n",
            "Epoch [15/15], batch: [57176/59184, loss: 6.5555]\n",
            "Epoch [15/15], batch: [57177/59184, loss: 6.9195]\n",
            "Epoch [15/15], batch: [57178/59184, loss: 6.7670]\n",
            "Epoch [15/15], batch: [57179/59184, loss: 6.3855]\n",
            "Epoch [15/15], batch: [57180/59184, loss: 7.6690]\n",
            "Epoch [15/15], batch: [57181/59184, loss: 5.9363]\n",
            "Epoch [15/15], batch: [57182/59184, loss: 7.4181]\n",
            "Epoch [15/15], batch: [57183/59184, loss: 6.0803]\n",
            "Epoch [15/15], batch: [57184/59184, loss: 6.8525]\n",
            "Epoch [15/15], batch: [57185/59184, loss: 6.6015]\n",
            "Epoch [15/15], batch: [57186/59184, loss: 7.5276]\n",
            "Epoch [15/15], batch: [57187/59184, loss: 7.1123]\n",
            "Epoch [15/15], batch: [57188/59184, loss: 7.0580]\n",
            "Epoch [15/15], batch: [57189/59184, loss: 7.6177]\n",
            "Epoch [15/15], batch: [57190/59184, loss: 8.6068]\n",
            "Epoch [15/15], batch: [57191/59184, loss: 5.9495]\n",
            "Epoch [15/15], batch: [57192/59184, loss: 7.7035]\n",
            "Epoch [15/15], batch: [57193/59184, loss: 7.8977]\n",
            "Epoch [15/15], batch: [57194/59184, loss: 5.8579]\n",
            "Epoch [15/15], batch: [57195/59184, loss: 6.6809]\n",
            "Epoch [15/15], batch: [57196/59184, loss: 5.8223]\n",
            "Epoch [15/15], batch: [57197/59184, loss: 6.3550]\n",
            "Epoch [15/15], batch: [57198/59184, loss: 6.5218]\n",
            "Epoch [15/15], batch: [57199/59184, loss: 6.9825]\n",
            "Epoch [15/15], batch: [57200/59184, loss: 6.4881]\n",
            "Epoch [15/15], batch: [57201/59184, loss: 6.5448]\n",
            "Epoch [15/15], batch: [57202/59184, loss: 5.5334]\n",
            "Epoch [15/15], batch: [57203/59184, loss: 5.2605]\n",
            "Epoch [15/15], batch: [57204/59184, loss: 7.1505]\n",
            "Epoch [15/15], batch: [57205/59184, loss: 7.6167]\n",
            "Epoch [15/15], batch: [57206/59184, loss: 6.2078]\n",
            "Epoch [15/15], batch: [57207/59184, loss: 6.9666]\n",
            "Epoch [15/15], batch: [57208/59184, loss: 7.4360]\n",
            "Epoch [15/15], batch: [57209/59184, loss: 5.7572]\n",
            "Epoch [15/15], batch: [57210/59184, loss: 7.9227]\n",
            "Epoch [15/15], batch: [57211/59184, loss: 4.8727]\n",
            "Epoch [15/15], batch: [57212/59184, loss: 6.5134]\n",
            "Epoch [15/15], batch: [57213/59184, loss: 5.2681]\n",
            "Epoch [15/15], batch: [57214/59184, loss: 4.6936]\n",
            "Epoch [15/15], batch: [57215/59184, loss: 5.2946]\n",
            "Epoch [15/15], batch: [57216/59184, loss: 5.4623]\n",
            "Epoch [15/15], batch: [57217/59184, loss: 6.2946]\n",
            "Epoch [15/15], batch: [57218/59184, loss: 7.2321]\n",
            "Epoch [15/15], batch: [57219/59184, loss: 5.7541]\n",
            "Epoch [15/15], batch: [57220/59184, loss: 5.4096]\n",
            "Epoch [15/15], batch: [57221/59184, loss: 6.6887]\n",
            "Epoch [15/15], batch: [57222/59184, loss: 4.2429]\n",
            "Epoch [15/15], batch: [57223/59184, loss: 5.8920]\n",
            "Epoch [15/15], batch: [57224/59184, loss: 6.0598]\n",
            "Epoch [15/15], batch: [57225/59184, loss: 6.3211]\n",
            "Epoch [15/15], batch: [57226/59184, loss: 5.6490]\n",
            "Epoch [15/15], batch: [57227/59184, loss: 6.7525]\n",
            "Epoch [15/15], batch: [57228/59184, loss: 5.2003]\n",
            "Epoch [15/15], batch: [57229/59184, loss: 6.6230]\n",
            "Epoch [15/15], batch: [57230/59184, loss: 7.0038]\n",
            "Epoch [15/15], batch: [57231/59184, loss: 6.7004]\n",
            "Epoch [15/15], batch: [57232/59184, loss: 7.0816]\n",
            "Epoch [15/15], batch: [57233/59184, loss: 6.2885]\n",
            "Epoch [15/15], batch: [57234/59184, loss: 7.0562]\n",
            "Epoch [15/15], batch: [57235/59184, loss: 4.4515]\n",
            "Epoch [15/15], batch: [57236/59184, loss: 6.2100]\n",
            "Epoch [15/15], batch: [57237/59184, loss: 6.1557]\n",
            "Epoch [15/15], batch: [57238/59184, loss: 5.7304]\n",
            "Epoch [15/15], batch: [57239/59184, loss: 5.3706]\n",
            "Epoch [15/15], batch: [57240/59184, loss: 4.9748]\n",
            "Epoch [15/15], batch: [57241/59184, loss: 3.8625]\n",
            "Epoch [15/15], batch: [57242/59184, loss: 4.5713]\n",
            "Epoch [15/15], batch: [57243/59184, loss: 6.5182]\n",
            "Epoch [15/15], batch: [57244/59184, loss: 6.0765]\n",
            "Epoch [15/15], batch: [57245/59184, loss: 5.6570]\n",
            "Epoch [15/15], batch: [57246/59184, loss: 5.0955]\n",
            "Epoch [15/15], batch: [57247/59184, loss: 4.8298]\n",
            "Epoch [15/15], batch: [57248/59184, loss: 5.7268]\n",
            "Epoch [15/15], batch: [57249/59184, loss: 4.6470]\n",
            "Epoch [15/15], batch: [57250/59184, loss: 7.0383]\n",
            "Epoch [15/15], batch: [57251/59184, loss: 6.9793]\n",
            "Epoch [15/15], batch: [57252/59184, loss: 6.2349]\n",
            "Epoch [15/15], batch: [57253/59184, loss: 6.9211]\n",
            "Epoch [15/15], batch: [57254/59184, loss: 6.6942]\n",
            "Epoch [15/15], batch: [57255/59184, loss: 5.6962]\n",
            "Epoch [15/15], batch: [57256/59184, loss: 4.1672]\n",
            "Epoch [15/15], batch: [57257/59184, loss: 6.5116]\n",
            "Epoch [15/15], batch: [57258/59184, loss: 6.0920]\n",
            "Epoch [15/15], batch: [57259/59184, loss: 6.6448]\n",
            "Epoch [15/15], batch: [57260/59184, loss: 4.9008]\n",
            "Epoch [15/15], batch: [57261/59184, loss: 5.4408]\n",
            "Epoch [15/15], batch: [57262/59184, loss: 6.5240]\n",
            "Epoch [15/15], batch: [57263/59184, loss: 4.9418]\n",
            "Epoch [15/15], batch: [57264/59184, loss: 6.6244]\n",
            "Epoch [15/15], batch: [57265/59184, loss: 5.9532]\n",
            "Epoch [15/15], batch: [57266/59184, loss: 6.3490]\n",
            "Epoch [15/15], batch: [57267/59184, loss: 6.5928]\n",
            "Epoch [15/15], batch: [57268/59184, loss: 5.3655]\n",
            "Epoch [15/15], batch: [57269/59184, loss: 6.0279]\n",
            "Epoch [15/15], batch: [57270/59184, loss: 4.7443]\n",
            "Epoch [15/15], batch: [57271/59184, loss: 5.8511]\n",
            "Epoch [15/15], batch: [57272/59184, loss: 5.1729]\n",
            "Epoch [15/15], batch: [57273/59184, loss: 7.2089]\n",
            "Epoch [15/15], batch: [57274/59184, loss: 6.5778]\n",
            "Epoch [15/15], batch: [57275/59184, loss: 4.9292]\n",
            "Epoch [15/15], batch: [57276/59184, loss: 4.7591]\n",
            "Epoch [15/15], batch: [57277/59184, loss: 4.7851]\n",
            "Epoch [15/15], batch: [57278/59184, loss: 5.9148]\n",
            "Epoch [15/15], batch: [57279/59184, loss: 5.1264]\n",
            "Epoch [15/15], batch: [57280/59184, loss: 5.9308]\n",
            "Epoch [15/15], batch: [57281/59184, loss: 5.8371]\n",
            "Epoch [15/15], batch: [57282/59184, loss: 6.4362]\n",
            "Epoch [15/15], batch: [57283/59184, loss: 4.7245]\n",
            "Epoch [15/15], batch: [57284/59184, loss: 6.5413]\n",
            "Epoch [15/15], batch: [57285/59184, loss: 5.1822]\n",
            "Epoch [15/15], batch: [57286/59184, loss: 4.8112]\n",
            "Epoch [15/15], batch: [57287/59184, loss: 5.1581]\n",
            "Epoch [15/15], batch: [57288/59184, loss: 5.1921]\n",
            "Epoch [15/15], batch: [57289/59184, loss: 4.7405]\n",
            "Epoch [15/15], batch: [57290/59184, loss: 7.4630]\n",
            "Epoch [15/15], batch: [57291/59184, loss: 6.2893]\n",
            "Epoch [15/15], batch: [57292/59184, loss: 4.4487]\n",
            "Epoch [15/15], batch: [57293/59184, loss: 6.8279]\n",
            "Epoch [15/15], batch: [57294/59184, loss: 6.5806]\n",
            "Epoch [15/15], batch: [57295/59184, loss: 5.4236]\n",
            "Epoch [15/15], batch: [57296/59184, loss: 5.0246]\n",
            "Epoch [15/15], batch: [57297/59184, loss: 6.7137]\n",
            "Epoch [15/15], batch: [57298/59184, loss: 6.8534]\n",
            "Epoch [15/15], batch: [57299/59184, loss: 6.4354]\n",
            "Epoch [15/15], batch: [57300/59184, loss: 7.5205]\n",
            "Epoch [15/15], batch: [57301/59184, loss: 6.7308]\n",
            "Epoch [15/15], batch: [57302/59184, loss: 6.0547]\n",
            "Epoch [15/15], batch: [57303/59184, loss: 6.5946]\n",
            "Epoch [15/15], batch: [57304/59184, loss: 6.3496]\n",
            "Epoch [15/15], batch: [57305/59184, loss: 5.9236]\n",
            "Epoch [15/15], batch: [57306/59184, loss: 5.8371]\n",
            "Epoch [15/15], batch: [57307/59184, loss: 7.4232]\n",
            "Epoch [15/15], batch: [57308/59184, loss: 6.8917]\n",
            "Epoch [15/15], batch: [57309/59184, loss: 7.1698]\n",
            "Epoch [15/15], batch: [57310/59184, loss: 4.8678]\n",
            "Epoch [15/15], batch: [57311/59184, loss: 6.4261]\n",
            "Epoch [15/15], batch: [57312/59184, loss: 6.5306]\n",
            "Epoch [15/15], batch: [57313/59184, loss: 3.6568]\n",
            "Epoch [15/15], batch: [57314/59184, loss: 6.9859]\n",
            "Epoch [15/15], batch: [57315/59184, loss: 5.4502]\n",
            "Epoch [15/15], batch: [57316/59184, loss: 7.5005]\n",
            "Epoch [15/15], batch: [57317/59184, loss: 6.3215]\n",
            "Epoch [15/15], batch: [57318/59184, loss: 5.9143]\n",
            "Epoch [15/15], batch: [57319/59184, loss: 6.2611]\n",
            "Epoch [15/15], batch: [57320/59184, loss: 7.0739]\n",
            "Epoch [15/15], batch: [57321/59184, loss: 6.0483]\n",
            "Epoch [15/15], batch: [57322/59184, loss: 5.8879]\n",
            "Epoch [15/15], batch: [57323/59184, loss: 5.9316]\n",
            "Epoch [15/15], batch: [57324/59184, loss: 6.4656]\n",
            "Epoch [15/15], batch: [57325/59184, loss: 5.3508]\n",
            "Epoch [15/15], batch: [57326/59184, loss: 5.3187]\n",
            "Epoch [15/15], batch: [57327/59184, loss: 6.8784]\n",
            "Epoch [15/15], batch: [57328/59184, loss: 7.0576]\n",
            "Epoch [15/15], batch: [57329/59184, loss: 6.0386]\n",
            "Epoch [15/15], batch: [57330/59184, loss: 6.5174]\n",
            "Epoch [15/15], batch: [57331/59184, loss: 6.3650]\n",
            "Epoch [15/15], batch: [57332/59184, loss: 6.6782]\n",
            "Epoch [15/15], batch: [57333/59184, loss: 4.7927]\n",
            "Epoch [15/15], batch: [57334/59184, loss: 4.5781]\n",
            "Epoch [15/15], batch: [57335/59184, loss: 4.9508]\n",
            "Epoch [15/15], batch: [57336/59184, loss: 6.4527]\n",
            "Epoch [15/15], batch: [57337/59184, loss: 6.9983]\n",
            "Epoch [15/15], batch: [57338/59184, loss: 5.5478]\n",
            "Epoch [15/15], batch: [57339/59184, loss: 5.5430]\n",
            "Epoch [15/15], batch: [57340/59184, loss: 6.2981]\n",
            "Epoch [15/15], batch: [57341/59184, loss: 5.6806]\n",
            "Epoch [15/15], batch: [57342/59184, loss: 5.2181]\n",
            "Epoch [15/15], batch: [57343/59184, loss: 6.3777]\n",
            "Epoch [15/15], batch: [57344/59184, loss: 4.8419]\n",
            "Epoch [15/15], batch: [57345/59184, loss: 6.6964]\n",
            "Epoch [15/15], batch: [57346/59184, loss: 6.8677]\n",
            "Epoch [15/15], batch: [57347/59184, loss: 5.9461]\n",
            "Epoch [15/15], batch: [57348/59184, loss: 4.8952]\n",
            "Epoch [15/15], batch: [57349/59184, loss: 4.5033]\n",
            "Epoch [15/15], batch: [57350/59184, loss: 5.8877]\n",
            "Epoch [15/15], batch: [57351/59184, loss: 4.1132]\n",
            "Epoch [15/15], batch: [57352/59184, loss: 5.3955]\n",
            "Epoch [15/15], batch: [57353/59184, loss: 5.0879]\n",
            "Epoch [15/15], batch: [57354/59184, loss: 4.9613]\n",
            "Epoch [15/15], batch: [57355/59184, loss: 5.1975]\n",
            "Epoch [15/15], batch: [57356/59184, loss: 5.3869]\n",
            "Epoch [15/15], batch: [57357/59184, loss: 6.1310]\n",
            "Epoch [15/15], batch: [57358/59184, loss: 6.0282]\n",
            "Epoch [15/15], batch: [57359/59184, loss: 5.0367]\n",
            "Epoch [15/15], batch: [57360/59184, loss: 4.8720]\n",
            "Epoch [15/15], batch: [57361/59184, loss: 7.0420]\n",
            "Epoch [15/15], batch: [57362/59184, loss: 6.1448]\n",
            "Epoch [15/15], batch: [57363/59184, loss: 6.9754]\n",
            "Epoch [15/15], batch: [57364/59184, loss: 6.9917]\n",
            "Epoch [15/15], batch: [57365/59184, loss: 6.1922]\n",
            "Epoch [15/15], batch: [57366/59184, loss: 4.0361]\n",
            "Epoch [15/15], batch: [57367/59184, loss: 7.0258]\n",
            "Epoch [15/15], batch: [57368/59184, loss: 7.8075]\n",
            "Epoch [15/15], batch: [57369/59184, loss: 6.6765]\n",
            "Epoch [15/15], batch: [57370/59184, loss: 6.3841]\n",
            "Epoch [15/15], batch: [57371/59184, loss: 3.8760]\n",
            "Epoch [15/15], batch: [57372/59184, loss: 3.8494]\n",
            "Epoch [15/15], batch: [57373/59184, loss: 6.0778]\n",
            "Epoch [15/15], batch: [57374/59184, loss: 6.4218]\n",
            "Epoch [15/15], batch: [57375/59184, loss: 4.3850]\n",
            "Epoch [15/15], batch: [57376/59184, loss: 3.8238]\n",
            "Epoch [15/15], batch: [57377/59184, loss: 5.3719]\n",
            "Epoch [15/15], batch: [57378/59184, loss: 4.7039]\n",
            "Epoch [15/15], batch: [57379/59184, loss: 5.9029]\n",
            "Epoch [15/15], batch: [57380/59184, loss: 6.5977]\n",
            "Epoch [15/15], batch: [57381/59184, loss: 5.8338]\n",
            "Epoch [15/15], batch: [57382/59184, loss: 6.0746]\n",
            "Epoch [15/15], batch: [57383/59184, loss: 7.0567]\n",
            "Epoch [15/15], batch: [57384/59184, loss: 5.1873]\n",
            "Epoch [15/15], batch: [57385/59184, loss: 5.2263]\n",
            "Epoch [15/15], batch: [57386/59184, loss: 4.6965]\n",
            "Epoch [15/15], batch: [57387/59184, loss: 5.7223]\n",
            "Epoch [15/15], batch: [57388/59184, loss: 5.3461]\n",
            "Epoch [15/15], batch: [57389/59184, loss: 3.8882]\n",
            "Epoch [15/15], batch: [57390/59184, loss: 7.6113]\n",
            "Epoch [15/15], batch: [57391/59184, loss: 6.7218]\n",
            "Epoch [15/15], batch: [57392/59184, loss: 4.7146]\n",
            "Epoch [15/15], batch: [57393/59184, loss: 4.7260]\n",
            "Epoch [15/15], batch: [57394/59184, loss: 5.6838]\n",
            "Epoch [15/15], batch: [57395/59184, loss: 5.3245]\n",
            "Epoch [15/15], batch: [57396/59184, loss: 6.3343]\n",
            "Epoch [15/15], batch: [57397/59184, loss: 5.8652]\n",
            "Epoch [15/15], batch: [57398/59184, loss: 3.8767]\n",
            "Epoch [15/15], batch: [57399/59184, loss: 4.2799]\n",
            "Epoch [15/15], batch: [57400/59184, loss: 5.0269]\n",
            "Epoch [15/15], batch: [57401/59184, loss: 5.7900]\n",
            "Epoch [15/15], batch: [57402/59184, loss: 5.4985]\n",
            "Epoch [15/15], batch: [57403/59184, loss: 6.7320]\n",
            "Epoch [15/15], batch: [57404/59184, loss: 5.3538]\n",
            "Epoch [15/15], batch: [57405/59184, loss: 4.9202]\n",
            "Epoch [15/15], batch: [57406/59184, loss: 5.5924]\n",
            "Epoch [15/15], batch: [57407/59184, loss: 4.5100]\n",
            "Epoch [15/15], batch: [57408/59184, loss: 6.1365]\n",
            "Epoch [15/15], batch: [57409/59184, loss: 5.2152]\n",
            "Epoch [15/15], batch: [57410/59184, loss: 5.5182]\n",
            "Epoch [15/15], batch: [57411/59184, loss: 6.3903]\n",
            "Epoch [15/15], batch: [57412/59184, loss: 5.2250]\n",
            "Epoch [15/15], batch: [57413/59184, loss: 6.0626]\n",
            "Epoch [15/15], batch: [57414/59184, loss: 4.7710]\n",
            "Epoch [15/15], batch: [57415/59184, loss: 5.1493]\n",
            "Epoch [15/15], batch: [57416/59184, loss: 5.4905]\n",
            "Epoch [15/15], batch: [57417/59184, loss: 5.7665]\n",
            "Epoch [15/15], batch: [57418/59184, loss: 5.1840]\n",
            "Epoch [15/15], batch: [57419/59184, loss: 4.4779]\n",
            "Epoch [15/15], batch: [57420/59184, loss: 3.1415]\n",
            "Epoch [15/15], batch: [57421/59184, loss: 5.1971]\n",
            "Epoch [15/15], batch: [57422/59184, loss: 5.2228]\n",
            "Epoch [15/15], batch: [57423/59184, loss: 5.6638]\n",
            "Epoch [15/15], batch: [57424/59184, loss: 4.4850]\n",
            "Epoch [15/15], batch: [57425/59184, loss: 5.8211]\n",
            "Epoch [15/15], batch: [57426/59184, loss: 7.2898]\n",
            "Epoch [15/15], batch: [57427/59184, loss: 4.6812]\n",
            "Epoch [15/15], batch: [57428/59184, loss: 7.3470]\n",
            "Epoch [15/15], batch: [57429/59184, loss: 6.2476]\n",
            "Epoch [15/15], batch: [57430/59184, loss: 7.4338]\n",
            "Epoch [15/15], batch: [57431/59184, loss: 4.2638]\n",
            "Epoch [15/15], batch: [57432/59184, loss: 4.4803]\n",
            "Epoch [15/15], batch: [57433/59184, loss: 4.9815]\n",
            "Epoch [15/15], batch: [57434/59184, loss: 5.4266]\n",
            "Epoch [15/15], batch: [57435/59184, loss: 4.8637]\n",
            "Epoch [15/15], batch: [57436/59184, loss: 7.0457]\n",
            "Epoch [15/15], batch: [57437/59184, loss: 5.4875]\n",
            "Epoch [15/15], batch: [57438/59184, loss: 5.2626]\n",
            "Epoch [15/15], batch: [57439/59184, loss: 4.6248]\n",
            "Epoch [15/15], batch: [57440/59184, loss: 5.2396]\n",
            "Epoch [15/15], batch: [57441/59184, loss: 6.3252]\n",
            "Epoch [15/15], batch: [57442/59184, loss: 7.6538]\n",
            "Epoch [15/15], batch: [57443/59184, loss: 5.6216]\n",
            "Epoch [15/15], batch: [57444/59184, loss: 6.0402]\n",
            "Epoch [15/15], batch: [57445/59184, loss: 4.8359]\n",
            "Epoch [15/15], batch: [57446/59184, loss: 5.5881]\n",
            "Epoch [15/15], batch: [57447/59184, loss: 4.9150]\n",
            "Epoch [15/15], batch: [57448/59184, loss: 5.0714]\n",
            "Epoch [15/15], batch: [57449/59184, loss: 4.0505]\n",
            "Epoch [15/15], batch: [57450/59184, loss: 5.6424]\n",
            "Epoch [15/15], batch: [57451/59184, loss: 5.7953]\n",
            "Epoch [15/15], batch: [57452/59184, loss: 8.2875]\n",
            "Epoch [15/15], batch: [57453/59184, loss: 5.2015]\n",
            "Epoch [15/15], batch: [57454/59184, loss: 7.3993]\n",
            "Epoch [15/15], batch: [57455/59184, loss: 5.5158]\n",
            "Epoch [15/15], batch: [57456/59184, loss: 6.9101]\n",
            "Epoch [15/15], batch: [57457/59184, loss: 5.6920]\n",
            "Epoch [15/15], batch: [57458/59184, loss: 5.1436]\n",
            "Epoch [15/15], batch: [57459/59184, loss: 6.3428]\n",
            "Epoch [15/15], batch: [57460/59184, loss: 6.1392]\n",
            "Epoch [15/15], batch: [57461/59184, loss: 7.0502]\n",
            "Epoch [15/15], batch: [57462/59184, loss: 7.0215]\n",
            "Epoch [15/15], batch: [57463/59184, loss: 5.8884]\n",
            "Epoch [15/15], batch: [57464/59184, loss: 6.3332]\n",
            "Epoch [15/15], batch: [57465/59184, loss: 6.6130]\n",
            "Epoch [15/15], batch: [57466/59184, loss: 4.9793]\n",
            "Epoch [15/15], batch: [57467/59184, loss: 5.5691]\n",
            "Epoch [15/15], batch: [57468/59184, loss: 5.7469]\n",
            "Epoch [15/15], batch: [57469/59184, loss: 5.0879]\n",
            "Epoch [15/15], batch: [57470/59184, loss: 5.6803]\n",
            "Epoch [15/15], batch: [57471/59184, loss: 6.2963]\n",
            "Epoch [15/15], batch: [57472/59184, loss: 5.3260]\n",
            "Epoch [15/15], batch: [57473/59184, loss: 4.2859]\n",
            "Epoch [15/15], batch: [57474/59184, loss: 6.6198]\n",
            "Epoch [15/15], batch: [57475/59184, loss: 7.0420]\n",
            "Epoch [15/15], batch: [57476/59184, loss: 6.0366]\n",
            "Epoch [15/15], batch: [57477/59184, loss: 6.9156]\n",
            "Epoch [15/15], batch: [57478/59184, loss: 6.1940]\n",
            "Epoch [15/15], batch: [57479/59184, loss: 7.1169]\n",
            "Epoch [15/15], batch: [57480/59184, loss: 4.8089]\n",
            "Epoch [15/15], batch: [57481/59184, loss: 5.8620]\n",
            "Epoch [15/15], batch: [57482/59184, loss: 6.6092]\n",
            "Epoch [15/15], batch: [57483/59184, loss: 4.6025]\n",
            "Epoch [15/15], batch: [57484/59184, loss: 4.3277]\n",
            "Epoch [15/15], batch: [57485/59184, loss: 5.7526]\n",
            "Epoch [15/15], batch: [57486/59184, loss: 5.3487]\n",
            "Epoch [15/15], batch: [57487/59184, loss: 5.7406]\n",
            "Epoch [15/15], batch: [57488/59184, loss: 5.8927]\n",
            "Epoch [15/15], batch: [57489/59184, loss: 4.8372]\n",
            "Epoch [15/15], batch: [57490/59184, loss: 6.1469]\n",
            "Epoch [15/15], batch: [57491/59184, loss: 6.5153]\n",
            "Epoch [15/15], batch: [57492/59184, loss: 4.7201]\n",
            "Epoch [15/15], batch: [57493/59184, loss: 6.7057]\n",
            "Epoch [15/15], batch: [57494/59184, loss: 6.6369]\n",
            "Epoch [15/15], batch: [57495/59184, loss: 5.8638]\n",
            "Epoch [15/15], batch: [57496/59184, loss: 4.7662]\n",
            "Epoch [15/15], batch: [57497/59184, loss: 5.2788]\n",
            "Epoch [15/15], batch: [57498/59184, loss: 5.1057]\n",
            "Epoch [15/15], batch: [57499/59184, loss: 5.6346]\n",
            "Epoch [15/15], batch: [57500/59184, loss: 6.0517]\n",
            "Epoch [15/15], batch: [57501/59184, loss: 7.6992]\n",
            "Epoch [15/15], batch: [57502/59184, loss: 6.4806]\n",
            "Epoch [15/15], batch: [57503/59184, loss: 7.4295]\n",
            "Epoch [15/15], batch: [57504/59184, loss: 4.2023]\n",
            "Epoch [15/15], batch: [57505/59184, loss: 5.6658]\n",
            "Epoch [15/15], batch: [57506/59184, loss: 5.3369]\n",
            "Epoch [15/15], batch: [57507/59184, loss: 4.3924]\n",
            "Epoch [15/15], batch: [57508/59184, loss: 6.1571]\n",
            "Epoch [15/15], batch: [57509/59184, loss: 5.4497]\n",
            "Epoch [15/15], batch: [57510/59184, loss: 5.8818]\n",
            "Epoch [15/15], batch: [57511/59184, loss: 5.6208]\n",
            "Epoch [15/15], batch: [57512/59184, loss: 6.1571]\n",
            "Epoch [15/15], batch: [57513/59184, loss: 5.4777]\n",
            "Epoch [15/15], batch: [57514/59184, loss: 5.8300]\n",
            "Epoch [15/15], batch: [57515/59184, loss: 3.8122]\n",
            "Epoch [15/15], batch: [57516/59184, loss: 6.7163]\n",
            "Epoch [15/15], batch: [57517/59184, loss: 6.2287]\n",
            "Epoch [15/15], batch: [57518/59184, loss: 7.0195]\n",
            "Epoch [15/15], batch: [57519/59184, loss: 4.2462]\n",
            "Epoch [15/15], batch: [57520/59184, loss: 2.1655]\n",
            "Epoch [15/15], batch: [57521/59184, loss: 5.6528]\n",
            "Epoch [15/15], batch: [57522/59184, loss: 5.6914]\n",
            "Epoch [15/15], batch: [57523/59184, loss: 6.3785]\n",
            "Epoch [15/15], batch: [57524/59184, loss: 5.8703]\n",
            "Epoch [15/15], batch: [57525/59184, loss: 5.8513]\n",
            "Epoch [15/15], batch: [57526/59184, loss: 5.5463]\n",
            "Epoch [15/15], batch: [57527/59184, loss: 5.7572]\n",
            "Epoch [15/15], batch: [57528/59184, loss: 7.2714]\n",
            "Epoch [15/15], batch: [57529/59184, loss: 4.7900]\n",
            "Epoch [15/15], batch: [57530/59184, loss: 6.9873]\n",
            "Epoch [15/15], batch: [57531/59184, loss: 6.2012]\n",
            "Epoch [15/15], batch: [57532/59184, loss: 5.4175]\n",
            "Epoch [15/15], batch: [57533/59184, loss: 5.1339]\n",
            "Epoch [15/15], batch: [57534/59184, loss: 4.9504]\n",
            "Epoch [15/15], batch: [57535/59184, loss: 5.5407]\n",
            "Epoch [15/15], batch: [57536/59184, loss: 5.9319]\n",
            "Epoch [15/15], batch: [57537/59184, loss: 6.2899]\n",
            "Epoch [15/15], batch: [57538/59184, loss: 5.4702]\n",
            "Epoch [15/15], batch: [57539/59184, loss: 4.9859]\n",
            "Epoch [15/15], batch: [57540/59184, loss: 7.3456]\n",
            "Epoch [15/15], batch: [57541/59184, loss: 4.6667]\n",
            "Epoch [15/15], batch: [57542/59184, loss: 5.2422]\n",
            "Epoch [15/15], batch: [57543/59184, loss: 5.5074]\n",
            "Epoch [15/15], batch: [57544/59184, loss: 6.1828]\n",
            "Epoch [15/15], batch: [57545/59184, loss: 6.0991]\n",
            "Epoch [15/15], batch: [57546/59184, loss: 6.3319]\n",
            "Epoch [15/15], batch: [57547/59184, loss: 4.7339]\n",
            "Epoch [15/15], batch: [57548/59184, loss: 8.1905]\n",
            "Epoch [15/15], batch: [57549/59184, loss: 4.9289]\n",
            "Epoch [15/15], batch: [57550/59184, loss: 6.0520]\n",
            "Epoch [15/15], batch: [57551/59184, loss: 7.5207]\n",
            "Epoch [15/15], batch: [57552/59184, loss: 4.4339]\n",
            "Epoch [15/15], batch: [57553/59184, loss: 7.1048]\n",
            "Epoch [15/15], batch: [57554/59184, loss: 7.4053]\n",
            "Epoch [15/15], batch: [57555/59184, loss: 6.6598]\n",
            "Epoch [15/15], batch: [57556/59184, loss: 5.1050]\n",
            "Epoch [15/15], batch: [57557/59184, loss: 5.3048]\n",
            "Epoch [15/15], batch: [57558/59184, loss: 5.4619]\n",
            "Epoch [15/15], batch: [57559/59184, loss: 5.3557]\n",
            "Epoch [15/15], batch: [57560/59184, loss: 5.7465]\n",
            "Epoch [15/15], batch: [57561/59184, loss: 5.9158]\n",
            "Epoch [15/15], batch: [57562/59184, loss: 3.3673]\n",
            "Epoch [15/15], batch: [57563/59184, loss: 5.3790]\n",
            "Epoch [15/15], batch: [57564/59184, loss: 5.0851]\n",
            "Epoch [15/15], batch: [57565/59184, loss: 3.7939]\n",
            "Epoch [15/15], batch: [57566/59184, loss: 5.4934]\n",
            "Epoch [15/15], batch: [57567/59184, loss: 6.3233]\n",
            "Epoch [15/15], batch: [57568/59184, loss: 5.0872]\n",
            "Epoch [15/15], batch: [57569/59184, loss: 3.5551]\n",
            "Epoch [15/15], batch: [57570/59184, loss: 5.8139]\n",
            "Epoch [15/15], batch: [57571/59184, loss: 6.5498]\n",
            "Epoch [15/15], batch: [57572/59184, loss: 5.5177]\n",
            "Epoch [15/15], batch: [57573/59184, loss: 4.7620]\n",
            "Epoch [15/15], batch: [57574/59184, loss: 6.1797]\n",
            "Epoch [15/15], batch: [57575/59184, loss: 3.9123]\n",
            "Epoch [15/15], batch: [57576/59184, loss: 7.5095]\n",
            "Epoch [15/15], batch: [57577/59184, loss: 6.6123]\n",
            "Epoch [15/15], batch: [57578/59184, loss: 6.7920]\n",
            "Epoch [15/15], batch: [57579/59184, loss: 7.3162]\n",
            "Epoch [15/15], batch: [57580/59184, loss: 6.5441]\n",
            "Epoch [15/15], batch: [57581/59184, loss: 5.9689]\n",
            "Epoch [15/15], batch: [57582/59184, loss: 5.7152]\n",
            "Epoch [15/15], batch: [57583/59184, loss: 6.6876]\n",
            "Epoch [15/15], batch: [57584/59184, loss: 7.0607]\n",
            "Epoch [15/15], batch: [57585/59184, loss: 7.0882]\n",
            "Epoch [15/15], batch: [57586/59184, loss: 5.7845]\n",
            "Epoch [15/15], batch: [57587/59184, loss: 5.6601]\n",
            "Epoch [15/15], batch: [57588/59184, loss: 6.9350]\n",
            "Epoch [15/15], batch: [57589/59184, loss: 6.5433]\n",
            "Epoch [15/15], batch: [57590/59184, loss: 4.6987]\n",
            "Epoch [15/15], batch: [57591/59184, loss: 4.3449]\n",
            "Epoch [15/15], batch: [57592/59184, loss: 6.0728]\n",
            "Epoch [15/15], batch: [57593/59184, loss: 3.7198]\n",
            "Epoch [15/15], batch: [57594/59184, loss: 3.1877]\n",
            "Epoch [15/15], batch: [57595/59184, loss: 5.7581]\n",
            "Epoch [15/15], batch: [57596/59184, loss: 3.5881]\n",
            "Epoch [15/15], batch: [57597/59184, loss: 5.7012]\n",
            "Epoch [15/15], batch: [57598/59184, loss: 5.8872]\n",
            "Epoch [15/15], batch: [57599/59184, loss: 4.7377]\n",
            "Epoch [15/15], batch: [57600/59184, loss: 7.1400]\n",
            "Epoch [15/15], batch: [57601/59184, loss: 6.1431]\n",
            "Epoch [15/15], batch: [57602/59184, loss: 5.0845]\n",
            "Epoch [15/15], batch: [57603/59184, loss: 5.1555]\n",
            "Epoch [15/15], batch: [57604/59184, loss: 5.2217]\n",
            "Epoch [15/15], batch: [57605/59184, loss: 4.8106]\n",
            "Epoch [15/15], batch: [57606/59184, loss: 4.6266]\n",
            "Epoch [15/15], batch: [57607/59184, loss: 6.4643]\n",
            "Epoch [15/15], batch: [57608/59184, loss: 5.7933]\n",
            "Epoch [15/15], batch: [57609/59184, loss: 5.9461]\n",
            "Epoch [15/15], batch: [57610/59184, loss: 5.7365]\n",
            "Epoch [15/15], batch: [57611/59184, loss: 5.7093]\n",
            "Epoch [15/15], batch: [57612/59184, loss: 5.4985]\n",
            "Epoch [15/15], batch: [57613/59184, loss: 5.8894]\n",
            "Epoch [15/15], batch: [57614/59184, loss: 7.4017]\n",
            "Epoch [15/15], batch: [57615/59184, loss: 5.4951]\n",
            "Epoch [15/15], batch: [57616/59184, loss: 6.8802]\n",
            "Epoch [15/15], batch: [57617/59184, loss: 6.6468]\n",
            "Epoch [15/15], batch: [57618/59184, loss: 7.3105]\n",
            "Epoch [15/15], batch: [57619/59184, loss: 5.9976]\n",
            "Epoch [15/15], batch: [57620/59184, loss: 6.6852]\n",
            "Epoch [15/15], batch: [57621/59184, loss: 3.7734]\n",
            "Epoch [15/15], batch: [57622/59184, loss: 6.0012]\n",
            "Epoch [15/15], batch: [57623/59184, loss: 4.9617]\n",
            "Epoch [15/15], batch: [57624/59184, loss: 5.6539]\n",
            "Epoch [15/15], batch: [57625/59184, loss: 6.1409]\n",
            "Epoch [15/15], batch: [57626/59184, loss: 5.5111]\n",
            "Epoch [15/15], batch: [57627/59184, loss: 4.6154]\n",
            "Epoch [15/15], batch: [57628/59184, loss: 6.4508]\n",
            "Epoch [15/15], batch: [57629/59184, loss: 5.5574]\n",
            "Epoch [15/15], batch: [57630/59184, loss: 7.1911]\n",
            "Epoch [15/15], batch: [57631/59184, loss: 6.1334]\n",
            "Epoch [15/15], batch: [57632/59184, loss: 4.3649]\n",
            "Epoch [15/15], batch: [57633/59184, loss: 6.1285]\n",
            "Epoch [15/15], batch: [57634/59184, loss: 4.5153]\n",
            "Epoch [15/15], batch: [57635/59184, loss: 5.2782]\n",
            "Epoch [15/15], batch: [57636/59184, loss: 6.0364]\n",
            "Epoch [15/15], batch: [57637/59184, loss: 5.2993]\n",
            "Epoch [15/15], batch: [57638/59184, loss: 6.2502]\n",
            "Epoch [15/15], batch: [57639/59184, loss: 5.5946]\n",
            "Epoch [15/15], batch: [57640/59184, loss: 6.0263]\n",
            "Epoch [15/15], batch: [57641/59184, loss: 5.7596]\n",
            "Epoch [15/15], batch: [57642/59184, loss: 7.2752]\n",
            "Epoch [15/15], batch: [57643/59184, loss: 5.3276]\n",
            "Epoch [15/15], batch: [57644/59184, loss: 3.1585]\n",
            "Epoch [15/15], batch: [57645/59184, loss: 5.1803]\n",
            "Epoch [15/15], batch: [57646/59184, loss: 5.3518]\n",
            "Epoch [15/15], batch: [57647/59184, loss: 5.3088]\n",
            "Epoch [15/15], batch: [57648/59184, loss: 5.1793]\n",
            "Epoch [15/15], batch: [57649/59184, loss: 6.3929]\n",
            "Epoch [15/15], batch: [57650/59184, loss: 5.5250]\n",
            "Epoch [15/15], batch: [57651/59184, loss: 4.1439]\n",
            "Epoch [15/15], batch: [57652/59184, loss: 5.8165]\n",
            "Epoch [15/15], batch: [57653/59184, loss: 5.0072]\n",
            "Epoch [15/15], batch: [57654/59184, loss: 6.6679]\n",
            "Epoch [15/15], batch: [57655/59184, loss: 6.0284]\n",
            "Epoch [15/15], batch: [57656/59184, loss: 5.9252]\n",
            "Epoch [15/15], batch: [57657/59184, loss: 5.5623]\n",
            "Epoch [15/15], batch: [57658/59184, loss: 5.9687]\n",
            "Epoch [15/15], batch: [57659/59184, loss: 7.8581]\n",
            "Epoch [15/15], batch: [57660/59184, loss: 7.4677]\n",
            "Epoch [15/15], batch: [57661/59184, loss: 6.0292]\n",
            "Epoch [15/15], batch: [57662/59184, loss: 5.1500]\n",
            "Epoch [15/15], batch: [57663/59184, loss: 5.8669]\n",
            "Epoch [15/15], batch: [57664/59184, loss: 6.6184]\n",
            "Epoch [15/15], batch: [57665/59184, loss: 6.0151]\n",
            "Epoch [15/15], batch: [57666/59184, loss: 7.0520]\n",
            "Epoch [15/15], batch: [57667/59184, loss: 6.0506]\n",
            "Epoch [15/15], batch: [57668/59184, loss: 5.3106]\n",
            "Epoch [15/15], batch: [57669/59184, loss: 4.8132]\n",
            "Epoch [15/15], batch: [57670/59184, loss: 6.6683]\n",
            "Epoch [15/15], batch: [57671/59184, loss: 5.7401]\n",
            "Epoch [15/15], batch: [57672/59184, loss: 7.5103]\n",
            "Epoch [15/15], batch: [57673/59184, loss: 5.8168]\n",
            "Epoch [15/15], batch: [57674/59184, loss: 5.5304]\n",
            "Epoch [15/15], batch: [57675/59184, loss: 4.9996]\n",
            "Epoch [15/15], batch: [57676/59184, loss: 5.8557]\n",
            "Epoch [15/15], batch: [57677/59184, loss: 5.6012]\n",
            "Epoch [15/15], batch: [57678/59184, loss: 5.8515]\n",
            "Epoch [15/15], batch: [57679/59184, loss: 4.8034]\n",
            "Epoch [15/15], batch: [57680/59184, loss: 6.3423]\n",
            "Epoch [15/15], batch: [57681/59184, loss: 6.8266]\n",
            "Epoch [15/15], batch: [57682/59184, loss: 6.0205]\n",
            "Epoch [15/15], batch: [57683/59184, loss: 5.6236]\n",
            "Epoch [15/15], batch: [57684/59184, loss: 7.0387]\n",
            "Epoch [15/15], batch: [57685/59184, loss: 5.3892]\n",
            "Epoch [15/15], batch: [57686/59184, loss: 5.4621]\n",
            "Epoch [15/15], batch: [57687/59184, loss: 7.0497]\n",
            "Epoch [15/15], batch: [57688/59184, loss: 5.4771]\n",
            "Epoch [15/15], batch: [57689/59184, loss: 5.0330]\n",
            "Epoch [15/15], batch: [57690/59184, loss: 5.8152]\n",
            "Epoch [15/15], batch: [57691/59184, loss: 3.9435]\n",
            "Epoch [15/15], batch: [57692/59184, loss: 4.2110]\n",
            "Epoch [15/15], batch: [57693/59184, loss: 4.7833]\n",
            "Epoch [15/15], batch: [57694/59184, loss: 6.0812]\n",
            "Epoch [15/15], batch: [57695/59184, loss: 5.2537]\n",
            "Epoch [15/15], batch: [57696/59184, loss: 5.4322]\n",
            "Epoch [15/15], batch: [57697/59184, loss: 4.1281]\n",
            "Epoch [15/15], batch: [57698/59184, loss: 4.4614]\n",
            "Epoch [15/15], batch: [57699/59184, loss: 6.1462]\n",
            "Epoch [15/15], batch: [57700/59184, loss: 5.2581]\n",
            "Epoch [15/15], batch: [57701/59184, loss: 5.3230]\n",
            "Epoch [15/15], batch: [57702/59184, loss: 4.4555]\n",
            "Epoch [15/15], batch: [57703/59184, loss: 7.3539]\n",
            "Epoch [15/15], batch: [57704/59184, loss: 6.5242]\n",
            "Epoch [15/15], batch: [57705/59184, loss: 4.6432]\n",
            "Epoch [15/15], batch: [57706/59184, loss: 6.7384]\n",
            "Epoch [15/15], batch: [57707/59184, loss: 5.2257]\n",
            "Epoch [15/15], batch: [57708/59184, loss: 6.6642]\n",
            "Epoch [15/15], batch: [57709/59184, loss: 7.6714]\n",
            "Epoch [15/15], batch: [57710/59184, loss: 5.3949]\n",
            "Epoch [15/15], batch: [57711/59184, loss: 4.2727]\n",
            "Epoch [15/15], batch: [57712/59184, loss: 4.5731]\n",
            "Epoch [15/15], batch: [57713/59184, loss: 4.1434]\n",
            "Epoch [15/15], batch: [57714/59184, loss: 7.0641]\n",
            "Epoch [15/15], batch: [57715/59184, loss: 5.2149]\n",
            "Epoch [15/15], batch: [57716/59184, loss: 6.6595]\n",
            "Epoch [15/15], batch: [57717/59184, loss: 6.9625]\n",
            "Epoch [15/15], batch: [57718/59184, loss: 5.3274]\n",
            "Epoch [15/15], batch: [57719/59184, loss: 4.6686]\n",
            "Epoch [15/15], batch: [57720/59184, loss: 4.3042]\n",
            "Epoch [15/15], batch: [57721/59184, loss: 5.8490]\n",
            "Epoch [15/15], batch: [57722/59184, loss: 7.1300]\n",
            "Epoch [15/15], batch: [57723/59184, loss: 6.5624]\n",
            "Epoch [15/15], batch: [57724/59184, loss: 5.1131]\n",
            "Epoch [15/15], batch: [57725/59184, loss: 4.0702]\n",
            "Epoch [15/15], batch: [57726/59184, loss: 5.1148]\n",
            "Epoch [15/15], batch: [57727/59184, loss: 6.0346]\n",
            "Epoch [15/15], batch: [57728/59184, loss: 4.1655]\n",
            "Epoch [15/15], batch: [57729/59184, loss: 4.5162]\n",
            "Epoch [15/15], batch: [57730/59184, loss: 5.0736]\n",
            "Epoch [15/15], batch: [57731/59184, loss: 6.0459]\n",
            "Epoch [15/15], batch: [57732/59184, loss: 4.7159]\n",
            "Epoch [15/15], batch: [57733/59184, loss: 5.6863]\n",
            "Epoch [15/15], batch: [57734/59184, loss: 5.5259]\n",
            "Epoch [15/15], batch: [57735/59184, loss: 6.2858]\n",
            "Epoch [15/15], batch: [57736/59184, loss: 5.6839]\n",
            "Epoch [15/15], batch: [57737/59184, loss: 4.5427]\n",
            "Epoch [15/15], batch: [57738/59184, loss: 6.8228]\n",
            "Epoch [15/15], batch: [57739/59184, loss: 4.0541]\n",
            "Epoch [15/15], batch: [57740/59184, loss: 5.3018]\n",
            "Epoch [15/15], batch: [57741/59184, loss: 5.1622]\n",
            "Epoch [15/15], batch: [57742/59184, loss: 4.7410]\n",
            "Epoch [15/15], batch: [57743/59184, loss: 6.3134]\n",
            "Epoch [15/15], batch: [57744/59184, loss: 5.1341]\n",
            "Epoch [15/15], batch: [57745/59184, loss: 5.8278]\n",
            "Epoch [15/15], batch: [57746/59184, loss: 6.2183]\n",
            "Epoch [15/15], batch: [57747/59184, loss: 6.9984]\n",
            "Epoch [15/15], batch: [57748/59184, loss: 4.9417]\n",
            "Epoch [15/15], batch: [57749/59184, loss: 5.4180]\n",
            "Epoch [15/15], batch: [57750/59184, loss: 5.2416]\n",
            "Epoch [15/15], batch: [57751/59184, loss: 5.8119]\n",
            "Epoch [15/15], batch: [57752/59184, loss: 6.4414]\n",
            "Epoch [15/15], batch: [57753/59184, loss: 6.0856]\n",
            "Epoch [15/15], batch: [57754/59184, loss: 5.0827]\n",
            "Epoch [15/15], batch: [57755/59184, loss: 6.1768]\n",
            "Epoch [15/15], batch: [57756/59184, loss: 7.0615]\n",
            "Epoch [15/15], batch: [57757/59184, loss: 5.6020]\n",
            "Epoch [15/15], batch: [57758/59184, loss: 6.2413]\n",
            "Epoch [15/15], batch: [57759/59184, loss: 5.8541]\n",
            "Epoch [15/15], batch: [57760/59184, loss: 6.1319]\n",
            "Epoch [15/15], batch: [57761/59184, loss: 5.3139]\n",
            "Epoch [15/15], batch: [57762/59184, loss: 6.0132]\n",
            "Epoch [15/15], batch: [57763/59184, loss: 6.2538]\n",
            "Epoch [15/15], batch: [57764/59184, loss: 4.0792]\n",
            "Epoch [15/15], batch: [57765/59184, loss: 3.9335]\n",
            "Epoch [15/15], batch: [57766/59184, loss: 3.7166]\n",
            "Epoch [15/15], batch: [57767/59184, loss: 6.1940]\n",
            "Epoch [15/15], batch: [57768/59184, loss: 6.1487]\n",
            "Epoch [15/15], batch: [57769/59184, loss: 4.8022]\n",
            "Epoch [15/15], batch: [57770/59184, loss: 3.4962]\n",
            "Epoch [15/15], batch: [57771/59184, loss: 3.4115]\n",
            "Epoch [15/15], batch: [57772/59184, loss: 4.6422]\n",
            "Epoch [15/15], batch: [57773/59184, loss: 5.8194]\n",
            "Epoch [15/15], batch: [57774/59184, loss: 7.5677]\n",
            "Epoch [15/15], batch: [57775/59184, loss: 5.7611]\n",
            "Epoch [15/15], batch: [57776/59184, loss: 7.1040]\n",
            "Epoch [15/15], batch: [57777/59184, loss: 5.5897]\n",
            "Epoch [15/15], batch: [57778/59184, loss: 5.7730]\n",
            "Epoch [15/15], batch: [57779/59184, loss: 4.8304]\n",
            "Epoch [15/15], batch: [57780/59184, loss: 7.0150]\n",
            "Epoch [15/15], batch: [57781/59184, loss: 7.4000]\n",
            "Epoch [15/15], batch: [57782/59184, loss: 6.6493]\n",
            "Epoch [15/15], batch: [57783/59184, loss: 5.3492]\n",
            "Epoch [15/15], batch: [57784/59184, loss: 4.5809]\n",
            "Epoch [15/15], batch: [57785/59184, loss: 6.3926]\n",
            "Epoch [15/15], batch: [57786/59184, loss: 6.4733]\n",
            "Epoch [15/15], batch: [57787/59184, loss: 6.2984]\n",
            "Epoch [15/15], batch: [57788/59184, loss: 6.8277]\n",
            "Epoch [15/15], batch: [57789/59184, loss: 4.2103]\n",
            "Epoch [15/15], batch: [57790/59184, loss: 7.9867]\n",
            "Epoch [15/15], batch: [57791/59184, loss: 6.8792]\n",
            "Epoch [15/15], batch: [57792/59184, loss: 7.1040]\n",
            "Epoch [15/15], batch: [57793/59184, loss: 5.4144]\n",
            "Epoch [15/15], batch: [57794/59184, loss: 5.5456]\n",
            "Epoch [15/15], batch: [57795/59184, loss: 6.1982]\n",
            "Epoch [15/15], batch: [57796/59184, loss: 6.2211]\n",
            "Epoch [15/15], batch: [57797/59184, loss: 7.1392]\n",
            "Epoch [15/15], batch: [57798/59184, loss: 3.5840]\n",
            "Epoch [15/15], batch: [57799/59184, loss: 5.8833]\n",
            "Epoch [15/15], batch: [57800/59184, loss: 6.1096]\n",
            "Epoch [15/15], batch: [57801/59184, loss: 5.6377]\n",
            "Epoch [15/15], batch: [57802/59184, loss: 4.8165]\n",
            "Epoch [15/15], batch: [57803/59184, loss: 6.2496]\n",
            "Epoch [15/15], batch: [57804/59184, loss: 6.1190]\n",
            "Epoch [15/15], batch: [57805/59184, loss: 5.5116]\n",
            "Epoch [15/15], batch: [57806/59184, loss: 4.0532]\n",
            "Epoch [15/15], batch: [57807/59184, loss: 6.1742]\n",
            "Epoch [15/15], batch: [57808/59184, loss: 5.3145]\n",
            "Epoch [15/15], batch: [57809/59184, loss: 6.0168]\n",
            "Epoch [15/15], batch: [57810/59184, loss: 5.3804]\n",
            "Epoch [15/15], batch: [57811/59184, loss: 4.4871]\n",
            "Epoch [15/15], batch: [57812/59184, loss: 5.8817]\n",
            "Epoch [15/15], batch: [57813/59184, loss: 6.9129]\n",
            "Epoch [15/15], batch: [57814/59184, loss: 5.4059]\n",
            "Epoch [15/15], batch: [57815/59184, loss: 6.5644]\n",
            "Epoch [15/15], batch: [57816/59184, loss: 6.8405]\n",
            "Epoch [15/15], batch: [57817/59184, loss: 6.3570]\n",
            "Epoch [15/15], batch: [57818/59184, loss: 7.1627]\n",
            "Epoch [15/15], batch: [57819/59184, loss: 5.8428]\n",
            "Epoch [15/15], batch: [57820/59184, loss: 6.7256]\n",
            "Epoch [15/15], batch: [57821/59184, loss: 6.4010]\n",
            "Epoch [15/15], batch: [57822/59184, loss: 6.2633]\n",
            "Epoch [15/15], batch: [57823/59184, loss: 6.1678]\n",
            "Epoch [15/15], batch: [57824/59184, loss: 7.0413]\n",
            "Epoch [15/15], batch: [57825/59184, loss: 3.6393]\n",
            "Epoch [15/15], batch: [57826/59184, loss: 7.1979]\n",
            "Epoch [15/15], batch: [57827/59184, loss: 6.1635]\n",
            "Epoch [15/15], batch: [57828/59184, loss: 7.2566]\n",
            "Epoch [15/15], batch: [57829/59184, loss: 7.5198]\n",
            "Epoch [15/15], batch: [57830/59184, loss: 7.1971]\n",
            "Epoch [15/15], batch: [57831/59184, loss: 6.9948]\n",
            "Epoch [15/15], batch: [57832/59184, loss: 6.0447]\n",
            "Epoch [15/15], batch: [57833/59184, loss: 3.2460]\n",
            "Epoch [15/15], batch: [57834/59184, loss: 5.1606]\n",
            "Epoch [15/15], batch: [57835/59184, loss: 4.8969]\n",
            "Epoch [15/15], batch: [57836/59184, loss: 5.0180]\n",
            "Epoch [15/15], batch: [57837/59184, loss: 6.7146]\n",
            "Epoch [15/15], batch: [57838/59184, loss: 4.4036]\n",
            "Epoch [15/15], batch: [57839/59184, loss: 4.3706]\n",
            "Epoch [15/15], batch: [57840/59184, loss: 6.9054]\n",
            "Epoch [15/15], batch: [57841/59184, loss: 5.2455]\n",
            "Epoch [15/15], batch: [57842/59184, loss: 5.2000]\n",
            "Epoch [15/15], batch: [57843/59184, loss: 4.1015]\n",
            "Epoch [15/15], batch: [57844/59184, loss: 4.2761]\n",
            "Epoch [15/15], batch: [57845/59184, loss: 4.7429]\n",
            "Epoch [15/15], batch: [57846/59184, loss: 4.4179]\n",
            "Epoch [15/15], batch: [57847/59184, loss: 4.3693]\n",
            "Epoch [15/15], batch: [57848/59184, loss: 6.0606]\n",
            "Epoch [15/15], batch: [57849/59184, loss: 4.7391]\n",
            "Epoch [15/15], batch: [57850/59184, loss: 6.1799]\n",
            "Epoch [15/15], batch: [57851/59184, loss: 5.6571]\n",
            "Epoch [15/15], batch: [57852/59184, loss: 5.3463]\n",
            "Epoch [15/15], batch: [57853/59184, loss: 4.2837]\n",
            "Epoch [15/15], batch: [57854/59184, loss: 4.1410]\n",
            "Epoch [15/15], batch: [57855/59184, loss: 5.0539]\n",
            "Epoch [15/15], batch: [57856/59184, loss: 5.6213]\n",
            "Epoch [15/15], batch: [57857/59184, loss: 5.5560]\n",
            "Epoch [15/15], batch: [57858/59184, loss: 6.1454]\n",
            "Epoch [15/15], batch: [57859/59184, loss: 6.8696]\n",
            "Epoch [15/15], batch: [57860/59184, loss: 5.5843]\n",
            "Epoch [15/15], batch: [57861/59184, loss: 5.5760]\n",
            "Epoch [15/15], batch: [57862/59184, loss: 6.6907]\n",
            "Epoch [15/15], batch: [57863/59184, loss: 7.3545]\n",
            "Epoch [15/15], batch: [57864/59184, loss: 7.2322]\n",
            "Epoch [15/15], batch: [57865/59184, loss: 7.0667]\n",
            "Epoch [15/15], batch: [57866/59184, loss: 4.5242]\n",
            "Epoch [15/15], batch: [57867/59184, loss: 5.5624]\n",
            "Epoch [15/15], batch: [57868/59184, loss: 6.7808]\n",
            "Epoch [15/15], batch: [57869/59184, loss: 5.2268]\n",
            "Epoch [15/15], batch: [57870/59184, loss: 6.7413]\n",
            "Epoch [15/15], batch: [57871/59184, loss: 3.4110]\n",
            "Epoch [15/15], batch: [57872/59184, loss: 5.5147]\n",
            "Epoch [15/15], batch: [57873/59184, loss: 3.9600]\n",
            "Epoch [15/15], batch: [57874/59184, loss: 6.1351]\n",
            "Epoch [15/15], batch: [57875/59184, loss: 7.1633]\n",
            "Epoch [15/15], batch: [57876/59184, loss: 7.7255]\n",
            "Epoch [15/15], batch: [57877/59184, loss: 6.0529]\n",
            "Epoch [15/15], batch: [57878/59184, loss: 4.6726]\n",
            "Epoch [15/15], batch: [57879/59184, loss: 4.4061]\n",
            "Epoch [15/15], batch: [57880/59184, loss: 5.6286]\n",
            "Epoch [15/15], batch: [57881/59184, loss: 5.9818]\n",
            "Epoch [15/15], batch: [57882/59184, loss: 5.3771]\n",
            "Epoch [15/15], batch: [57883/59184, loss: 4.4750]\n",
            "Epoch [15/15], batch: [57884/59184, loss: 4.7995]\n",
            "Epoch [15/15], batch: [57885/59184, loss: 6.6987]\n",
            "Epoch [15/15], batch: [57886/59184, loss: 6.7542]\n",
            "Epoch [15/15], batch: [57887/59184, loss: 3.8780]\n",
            "Epoch [15/15], batch: [57888/59184, loss: 3.6040]\n",
            "Epoch [15/15], batch: [57889/59184, loss: 3.7254]\n",
            "Epoch [15/15], batch: [57890/59184, loss: 5.1015]\n",
            "Epoch [15/15], batch: [57891/59184, loss: 5.1785]\n",
            "Epoch [15/15], batch: [57892/59184, loss: 4.5193]\n",
            "Epoch [15/15], batch: [57893/59184, loss: 4.7400]\n",
            "Epoch [15/15], batch: [57894/59184, loss: 4.6320]\n",
            "Epoch [15/15], batch: [57895/59184, loss: 5.8993]\n",
            "Epoch [15/15], batch: [57896/59184, loss: 6.2772]\n",
            "Epoch [15/15], batch: [57897/59184, loss: 5.7715]\n",
            "Epoch [15/15], batch: [57898/59184, loss: 5.7731]\n",
            "Epoch [15/15], batch: [57899/59184, loss: 4.1401]\n",
            "Epoch [15/15], batch: [57900/59184, loss: 5.8457]\n",
            "Epoch [15/15], batch: [57901/59184, loss: 5.7642]\n",
            "Epoch [15/15], batch: [57902/59184, loss: 7.4005]\n",
            "Epoch [15/15], batch: [57903/59184, loss: 6.9049]\n",
            "Epoch [15/15], batch: [57904/59184, loss: 5.8315]\n",
            "Epoch [15/15], batch: [57905/59184, loss: 5.4314]\n",
            "Epoch [15/15], batch: [57906/59184, loss: 5.3686]\n",
            "Epoch [15/15], batch: [57907/59184, loss: 4.2566]\n",
            "Epoch [15/15], batch: [57908/59184, loss: 5.9768]\n",
            "Epoch [15/15], batch: [57909/59184, loss: 4.1965]\n",
            "Epoch [15/15], batch: [57910/59184, loss: 4.5764]\n",
            "Epoch [15/15], batch: [57911/59184, loss: 3.7927]\n",
            "Epoch [15/15], batch: [57912/59184, loss: 4.9812]\n",
            "Epoch [15/15], batch: [57913/59184, loss: 6.7385]\n",
            "Epoch [15/15], batch: [57914/59184, loss: 7.1238]\n",
            "Epoch [15/15], batch: [57915/59184, loss: 6.3918]\n",
            "Epoch [15/15], batch: [57916/59184, loss: 6.3377]\n",
            "Epoch [15/15], batch: [57917/59184, loss: 5.4125]\n",
            "Epoch [15/15], batch: [57918/59184, loss: 5.9618]\n",
            "Epoch [15/15], batch: [57919/59184, loss: 7.1512]\n",
            "Epoch [15/15], batch: [57920/59184, loss: 5.2374]\n",
            "Epoch [15/15], batch: [57921/59184, loss: 5.5140]\n",
            "Epoch [15/15], batch: [57922/59184, loss: 4.5073]\n",
            "Epoch [15/15], batch: [57923/59184, loss: 2.8938]\n",
            "Epoch [15/15], batch: [57924/59184, loss: 4.6583]\n",
            "Epoch [15/15], batch: [57925/59184, loss: 6.2688]\n",
            "Epoch [15/15], batch: [57926/59184, loss: 5.3917]\n",
            "Epoch [15/15], batch: [57927/59184, loss: 6.3259]\n",
            "Epoch [15/15], batch: [57928/59184, loss: 4.8511]\n",
            "Epoch [15/15], batch: [57929/59184, loss: 4.3021]\n",
            "Epoch [15/15], batch: [57930/59184, loss: 5.8832]\n",
            "Epoch [15/15], batch: [57931/59184, loss: 7.2739]\n",
            "Epoch [15/15], batch: [57932/59184, loss: 6.0743]\n",
            "Epoch [15/15], batch: [57933/59184, loss: 6.4503]\n",
            "Epoch [15/15], batch: [57934/59184, loss: 5.4098]\n",
            "Epoch [15/15], batch: [57935/59184, loss: 6.2134]\n",
            "Epoch [15/15], batch: [57936/59184, loss: 6.1955]\n",
            "Epoch [15/15], batch: [57937/59184, loss: 4.4824]\n",
            "Epoch [15/15], batch: [57938/59184, loss: 4.3095]\n",
            "Epoch [15/15], batch: [57939/59184, loss: 5.6335]\n",
            "Epoch [15/15], batch: [57940/59184, loss: 5.6197]\n",
            "Epoch [15/15], batch: [57941/59184, loss: 5.3076]\n",
            "Epoch [15/15], batch: [57942/59184, loss: 4.5470]\n",
            "Epoch [15/15], batch: [57943/59184, loss: 6.9845]\n",
            "Epoch [15/15], batch: [57944/59184, loss: 3.7422]\n",
            "Epoch [15/15], batch: [57945/59184, loss: 4.5272]\n",
            "Epoch [15/15], batch: [57946/59184, loss: 4.2582]\n",
            "Epoch [15/15], batch: [57947/59184, loss: 5.3422]\n",
            "Epoch [15/15], batch: [57948/59184, loss: 3.0637]\n",
            "Epoch [15/15], batch: [57949/59184, loss: 6.2732]\n",
            "Epoch [15/15], batch: [57950/59184, loss: 4.6552]\n",
            "Epoch [15/15], batch: [57951/59184, loss: 5.0977]\n",
            "Epoch [15/15], batch: [57952/59184, loss: 2.0152]\n",
            "Epoch [15/15], batch: [57953/59184, loss: 5.6694]\n",
            "Epoch [15/15], batch: [57954/59184, loss: 7.2082]\n",
            "Epoch [15/15], batch: [57955/59184, loss: 4.3634]\n",
            "Epoch [15/15], batch: [57956/59184, loss: 5.8232]\n",
            "Epoch [15/15], batch: [57957/59184, loss: 5.6807]\n",
            "Epoch [15/15], batch: [57958/59184, loss: 5.4265]\n",
            "Epoch [15/15], batch: [57959/59184, loss: 4.3228]\n",
            "Epoch [15/15], batch: [57960/59184, loss: 3.8471]\n",
            "Epoch [15/15], batch: [57961/59184, loss: 4.7428]\n",
            "Epoch [15/15], batch: [57962/59184, loss: 4.7381]\n",
            "Epoch [15/15], batch: [57963/59184, loss: 4.4293]\n",
            "Epoch [15/15], batch: [57964/59184, loss: 5.5616]\n",
            "Epoch [15/15], batch: [57965/59184, loss: 5.2795]\n",
            "Epoch [15/15], batch: [57966/59184, loss: 5.0245]\n",
            "Epoch [15/15], batch: [57967/59184, loss: 4.7762]\n",
            "Epoch [15/15], batch: [57968/59184, loss: 3.4513]\n",
            "Epoch [15/15], batch: [57969/59184, loss: 4.2152]\n",
            "Epoch [15/15], batch: [57970/59184, loss: 3.7156]\n",
            "Epoch [15/15], batch: [57971/59184, loss: 5.3791]\n",
            "Epoch [15/15], batch: [57972/59184, loss: 5.1729]\n",
            "Epoch [15/15], batch: [57973/59184, loss: 5.1076]\n",
            "Epoch [15/15], batch: [57974/59184, loss: 4.4351]\n",
            "Epoch [15/15], batch: [57975/59184, loss: 5.5956]\n",
            "Epoch [15/15], batch: [57976/59184, loss: 6.1654]\n",
            "Epoch [15/15], batch: [57977/59184, loss: 5.9861]\n",
            "Epoch [15/15], batch: [57978/59184, loss: 6.2181]\n",
            "Epoch [15/15], batch: [57979/59184, loss: 6.2504]\n",
            "Epoch [15/15], batch: [57980/59184, loss: 6.5895]\n",
            "Epoch [15/15], batch: [57981/59184, loss: 5.6879]\n",
            "Epoch [15/15], batch: [57982/59184, loss: 4.7516]\n",
            "Epoch [15/15], batch: [57983/59184, loss: 5.9404]\n",
            "Epoch [15/15], batch: [57984/59184, loss: 5.9779]\n",
            "Epoch [15/15], batch: [57985/59184, loss: 5.5318]\n",
            "Epoch [15/15], batch: [57986/59184, loss: 5.3076]\n",
            "Epoch [15/15], batch: [57987/59184, loss: 4.6013]\n",
            "Epoch [15/15], batch: [57988/59184, loss: 6.9007]\n",
            "Epoch [15/15], batch: [57989/59184, loss: 5.5647]\n",
            "Epoch [15/15], batch: [57990/59184, loss: 4.7594]\n",
            "Epoch [15/15], batch: [57991/59184, loss: 4.9008]\n",
            "Epoch [15/15], batch: [57992/59184, loss: 6.7540]\n",
            "Epoch [15/15], batch: [57993/59184, loss: 6.5364]\n",
            "Epoch [15/15], batch: [57994/59184, loss: 5.7341]\n",
            "Epoch [15/15], batch: [57995/59184, loss: 6.3004]\n",
            "Epoch [15/15], batch: [57996/59184, loss: 5.9481]\n",
            "Epoch [15/15], batch: [57997/59184, loss: 5.4817]\n",
            "Epoch [15/15], batch: [57998/59184, loss: 5.0241]\n",
            "Epoch [15/15], batch: [57999/59184, loss: 5.0923]\n",
            "Epoch [15/15], batch: [58000/59184, loss: 5.9101]\n",
            "Epoch [15/15], batch: [58001/59184, loss: 7.0378]\n",
            "Epoch [15/15], batch: [58002/59184, loss: 6.8558]\n",
            "Epoch [15/15], batch: [58003/59184, loss: 6.4115]\n",
            "Epoch [15/15], batch: [58004/59184, loss: 6.7987]\n",
            "Epoch [15/15], batch: [58005/59184, loss: 5.7264]\n",
            "Epoch [15/15], batch: [58006/59184, loss: 6.4677]\n",
            "Epoch [15/15], batch: [58007/59184, loss: 5.3129]\n",
            "Epoch [15/15], batch: [58008/59184, loss: 5.9963]\n",
            "Epoch [15/15], batch: [58009/59184, loss: 6.7620]\n",
            "Epoch [15/15], batch: [58010/59184, loss: 6.2321]\n",
            "Epoch [15/15], batch: [58011/59184, loss: 5.0718]\n",
            "Epoch [15/15], batch: [58012/59184, loss: 5.4164]\n",
            "Epoch [15/15], batch: [58013/59184, loss: 5.0290]\n",
            "Epoch [15/15], batch: [58014/59184, loss: 5.1124]\n",
            "Epoch [15/15], batch: [58015/59184, loss: 7.3039]\n",
            "Epoch [15/15], batch: [58016/59184, loss: 6.1021]\n",
            "Epoch [15/15], batch: [58017/59184, loss: 4.2652]\n",
            "Epoch [15/15], batch: [58018/59184, loss: 5.9317]\n",
            "Epoch [15/15], batch: [58019/59184, loss: 5.8922]\n",
            "Epoch [15/15], batch: [58020/59184, loss: 6.6228]\n",
            "Epoch [15/15], batch: [58021/59184, loss: 5.9114]\n",
            "Epoch [15/15], batch: [58022/59184, loss: 5.0795]\n",
            "Epoch [15/15], batch: [58023/59184, loss: 6.1602]\n",
            "Epoch [15/15], batch: [58024/59184, loss: 4.6916]\n",
            "Epoch [15/15], batch: [58025/59184, loss: 5.3810]\n",
            "Epoch [15/15], batch: [58026/59184, loss: 4.7662]\n",
            "Epoch [15/15], batch: [58027/59184, loss: 3.2739]\n",
            "Epoch [15/15], batch: [58028/59184, loss: 3.4172]\n",
            "Epoch [15/15], batch: [58029/59184, loss: 4.9696]\n",
            "Epoch [15/15], batch: [58030/59184, loss: 5.2067]\n",
            "Epoch [15/15], batch: [58031/59184, loss: 6.6587]\n",
            "Epoch [15/15], batch: [58032/59184, loss: 4.8695]\n",
            "Epoch [15/15], batch: [58033/59184, loss: 4.6965]\n",
            "Epoch [15/15], batch: [58034/59184, loss: 5.1145]\n",
            "Epoch [15/15], batch: [58035/59184, loss: 4.2286]\n",
            "Epoch [15/15], batch: [58036/59184, loss: 5.1227]\n",
            "Epoch [15/15], batch: [58037/59184, loss: 5.7112]\n",
            "Epoch [15/15], batch: [58038/59184, loss: 6.0565]\n",
            "Epoch [15/15], batch: [58039/59184, loss: 6.5087]\n",
            "Epoch [15/15], batch: [58040/59184, loss: 5.6914]\n",
            "Epoch [15/15], batch: [58041/59184, loss: 5.4218]\n",
            "Epoch [15/15], batch: [58042/59184, loss: 5.9101]\n",
            "Epoch [15/15], batch: [58043/59184, loss: 4.2096]\n",
            "Epoch [15/15], batch: [58044/59184, loss: 6.3505]\n",
            "Epoch [15/15], batch: [58045/59184, loss: 6.5894]\n",
            "Epoch [15/15], batch: [58046/59184, loss: 5.5140]\n",
            "Epoch [15/15], batch: [58047/59184, loss: 4.5926]\n",
            "Epoch [15/15], batch: [58048/59184, loss: 5.4355]\n",
            "Epoch [15/15], batch: [58049/59184, loss: 4.3228]\n",
            "Epoch [15/15], batch: [58050/59184, loss: 7.5232]\n",
            "Epoch [15/15], batch: [58051/59184, loss: 6.1271]\n",
            "Epoch [15/15], batch: [58052/59184, loss: 6.4297]\n",
            "Epoch [15/15], batch: [58053/59184, loss: 5.4771]\n",
            "Epoch [15/15], batch: [58054/59184, loss: 5.5520]\n",
            "Epoch [15/15], batch: [58055/59184, loss: 5.8925]\n",
            "Epoch [15/15], batch: [58056/59184, loss: 4.3432]\n",
            "Epoch [15/15], batch: [58057/59184, loss: 4.5798]\n",
            "Epoch [15/15], batch: [58058/59184, loss: 7.2394]\n",
            "Epoch [15/15], batch: [58059/59184, loss: 5.8496]\n",
            "Epoch [15/15], batch: [58060/59184, loss: 7.7089]\n",
            "Epoch [15/15], batch: [58061/59184, loss: 6.6523]\n",
            "Epoch [15/15], batch: [58062/59184, loss: 5.5720]\n",
            "Epoch [15/15], batch: [58063/59184, loss: 5.2191]\n",
            "Epoch [15/15], batch: [58064/59184, loss: 6.5699]\n",
            "Epoch [15/15], batch: [58065/59184, loss: 5.3879]\n",
            "Epoch [15/15], batch: [58066/59184, loss: 5.6512]\n",
            "Epoch [15/15], batch: [58067/59184, loss: 4.7473]\n",
            "Epoch [15/15], batch: [58068/59184, loss: 5.6467]\n",
            "Epoch [15/15], batch: [58069/59184, loss: 6.3295]\n",
            "Epoch [15/15], batch: [58070/59184, loss: 4.9049]\n",
            "Epoch [15/15], batch: [58071/59184, loss: 7.4404]\n",
            "Epoch [15/15], batch: [58072/59184, loss: 5.9622]\n",
            "Epoch [15/15], batch: [58073/59184, loss: 5.4585]\n",
            "Epoch [15/15], batch: [58074/59184, loss: 6.1217]\n",
            "Epoch [15/15], batch: [58075/59184, loss: 6.9629]\n",
            "Epoch [15/15], batch: [58076/59184, loss: 6.0010]\n",
            "Epoch [15/15], batch: [58077/59184, loss: 7.0535]\n",
            "Epoch [15/15], batch: [58078/59184, loss: 5.6970]\n",
            "Epoch [15/15], batch: [58079/59184, loss: 5.8013]\n",
            "Epoch [15/15], batch: [58080/59184, loss: 6.5906]\n",
            "Epoch [15/15], batch: [58081/59184, loss: 5.8402]\n",
            "Epoch [15/15], batch: [58082/59184, loss: 6.5134]\n",
            "Epoch [15/15], batch: [58083/59184, loss: 4.6798]\n",
            "Epoch [15/15], batch: [58084/59184, loss: 5.5479]\n",
            "Epoch [15/15], batch: [58085/59184, loss: 5.3311]\n",
            "Epoch [15/15], batch: [58086/59184, loss: 7.2739]\n",
            "Epoch [15/15], batch: [58087/59184, loss: 5.8534]\n",
            "Epoch [15/15], batch: [58088/59184, loss: 4.8615]\n",
            "Epoch [15/15], batch: [58089/59184, loss: 6.0249]\n",
            "Epoch [15/15], batch: [58090/59184, loss: 6.1993]\n",
            "Epoch [15/15], batch: [58091/59184, loss: 5.5895]\n",
            "Epoch [15/15], batch: [58092/59184, loss: 5.0565]\n",
            "Epoch [15/15], batch: [58093/59184, loss: 5.8727]\n",
            "Epoch [15/15], batch: [58094/59184, loss: 6.2314]\n",
            "Epoch [15/15], batch: [58095/59184, loss: 4.8736]\n",
            "Epoch [15/15], batch: [58096/59184, loss: 4.9684]\n",
            "Epoch [15/15], batch: [58097/59184, loss: 6.1393]\n",
            "Epoch [15/15], batch: [58098/59184, loss: 6.0075]\n",
            "Epoch [15/15], batch: [58099/59184, loss: 6.0906]\n",
            "Epoch [15/15], batch: [58100/59184, loss: 6.1745]\n",
            "Epoch [15/15], batch: [58101/59184, loss: 5.6576]\n",
            "Epoch [15/15], batch: [58102/59184, loss: 6.0479]\n",
            "Epoch [15/15], batch: [58103/59184, loss: 5.3788]\n",
            "Epoch [15/15], batch: [58104/59184, loss: 7.0587]\n",
            "Epoch [15/15], batch: [58105/59184, loss: 6.3236]\n",
            "Epoch [15/15], batch: [58106/59184, loss: 4.6287]\n",
            "Epoch [15/15], batch: [58107/59184, loss: 5.8254]\n",
            "Epoch [15/15], batch: [58108/59184, loss: 6.0598]\n",
            "Epoch [15/15], batch: [58109/59184, loss: 4.9578]\n",
            "Epoch [15/15], batch: [58110/59184, loss: 5.3167]\n",
            "Epoch [15/15], batch: [58111/59184, loss: 4.9377]\n",
            "Epoch [15/15], batch: [58112/59184, loss: 5.5884]\n",
            "Epoch [15/15], batch: [58113/59184, loss: 6.9177]\n",
            "Epoch [15/15], batch: [58114/59184, loss: 6.1615]\n",
            "Epoch [15/15], batch: [58115/59184, loss: 7.2386]\n",
            "Epoch [15/15], batch: [58116/59184, loss: 6.7448]\n",
            "Epoch [15/15], batch: [58117/59184, loss: 5.1422]\n",
            "Epoch [15/15], batch: [58118/59184, loss: 3.2747]\n",
            "Epoch [15/15], batch: [58119/59184, loss: 4.1550]\n",
            "Epoch [15/15], batch: [58120/59184, loss: 4.7364]\n",
            "Epoch [15/15], batch: [58121/59184, loss: 5.7586]\n",
            "Epoch [15/15], batch: [58122/59184, loss: 4.0821]\n",
            "Epoch [15/15], batch: [58123/59184, loss: 2.1016]\n",
            "Epoch [15/15], batch: [58124/59184, loss: 3.7186]\n",
            "Epoch [15/15], batch: [58125/59184, loss: 3.8872]\n",
            "Epoch [15/15], batch: [58126/59184, loss: 6.2951]\n",
            "Epoch [15/15], batch: [58127/59184, loss: 4.6145]\n",
            "Epoch [15/15], batch: [58128/59184, loss: 5.4232]\n",
            "Epoch [15/15], batch: [58129/59184, loss: 4.0603]\n",
            "Epoch [15/15], batch: [58130/59184, loss: 3.9424]\n",
            "Epoch [15/15], batch: [58131/59184, loss: 6.0683]\n",
            "Epoch [15/15], batch: [58132/59184, loss: 6.0537]\n",
            "Epoch [15/15], batch: [58133/59184, loss: 6.1056]\n",
            "Epoch [15/15], batch: [58134/59184, loss: 5.2432]\n",
            "Epoch [15/15], batch: [58135/59184, loss: 6.6883]\n",
            "Epoch [15/15], batch: [58136/59184, loss: 6.7763]\n",
            "Epoch [15/15], batch: [58137/59184, loss: 7.0477]\n",
            "Epoch [15/15], batch: [58138/59184, loss: 5.8810]\n",
            "Epoch [15/15], batch: [58139/59184, loss: 6.2008]\n",
            "Epoch [15/15], batch: [58140/59184, loss: 3.8167]\n",
            "Epoch [15/15], batch: [58141/59184, loss: 5.2807]\n",
            "Epoch [15/15], batch: [58142/59184, loss: 6.0557]\n",
            "Epoch [15/15], batch: [58143/59184, loss: 6.0776]\n",
            "Epoch [15/15], batch: [58144/59184, loss: 6.7552]\n",
            "Epoch [15/15], batch: [58145/59184, loss: 3.5144]\n",
            "Epoch [15/15], batch: [58146/59184, loss: 5.0871]\n",
            "Epoch [15/15], batch: [58147/59184, loss: 4.5258]\n",
            "Epoch [15/15], batch: [58148/59184, loss: 5.0762]\n",
            "Epoch [15/15], batch: [58149/59184, loss: 5.1200]\n",
            "Epoch [15/15], batch: [58150/59184, loss: 4.1700]\n",
            "Epoch [15/15], batch: [58151/59184, loss: 4.4487]\n",
            "Epoch [15/15], batch: [58152/59184, loss: 5.3005]\n",
            "Epoch [15/15], batch: [58153/59184, loss: 5.2716]\n",
            "Epoch [15/15], batch: [58154/59184, loss: 5.1265]\n",
            "Epoch [15/15], batch: [58155/59184, loss: 5.3162]\n",
            "Epoch [15/15], batch: [58156/59184, loss: 5.7566]\n",
            "Epoch [15/15], batch: [58157/59184, loss: 4.7162]\n",
            "Epoch [15/15], batch: [58158/59184, loss: 6.8451]\n",
            "Epoch [15/15], batch: [58159/59184, loss: 5.2067]\n",
            "Epoch [15/15], batch: [58160/59184, loss: 6.9790]\n",
            "Epoch [15/15], batch: [58161/59184, loss: 5.6604]\n",
            "Epoch [15/15], batch: [58162/59184, loss: 5.4693]\n",
            "Epoch [15/15], batch: [58163/59184, loss: 5.4815]\n",
            "Epoch [15/15], batch: [58164/59184, loss: 6.8135]\n",
            "Epoch [15/15], batch: [58165/59184, loss: 6.1675]\n",
            "Epoch [15/15], batch: [58166/59184, loss: 5.1621]\n",
            "Epoch [15/15], batch: [58167/59184, loss: 4.8952]\n",
            "Epoch [15/15], batch: [58168/59184, loss: 6.2088]\n",
            "Epoch [15/15], batch: [58169/59184, loss: 6.7722]\n",
            "Epoch [15/15], batch: [58170/59184, loss: 4.3485]\n",
            "Epoch [15/15], batch: [58171/59184, loss: 4.3259]\n",
            "Epoch [15/15], batch: [58172/59184, loss: 7.1532]\n",
            "Epoch [15/15], batch: [58173/59184, loss: 6.6711]\n",
            "Epoch [15/15], batch: [58174/59184, loss: 6.3097]\n",
            "Epoch [15/15], batch: [58175/59184, loss: 5.7517]\n",
            "Epoch [15/15], batch: [58176/59184, loss: 5.6625]\n",
            "Epoch [15/15], batch: [58177/59184, loss: 6.0187]\n",
            "Epoch [15/15], batch: [58178/59184, loss: 4.8823]\n",
            "Epoch [15/15], batch: [58179/59184, loss: 4.1188]\n",
            "Epoch [15/15], batch: [58180/59184, loss: 3.9537]\n",
            "Epoch [15/15], batch: [58181/59184, loss: 5.8939]\n",
            "Epoch [15/15], batch: [58182/59184, loss: 5.2442]\n",
            "Epoch [15/15], batch: [58183/59184, loss: 6.4908]\n",
            "Epoch [15/15], batch: [58184/59184, loss: 4.6482]\n",
            "Epoch [15/15], batch: [58185/59184, loss: 5.8220]\n",
            "Epoch [15/15], batch: [58186/59184, loss: 6.0580]\n",
            "Epoch [15/15], batch: [58187/59184, loss: 5.3918]\n",
            "Epoch [15/15], batch: [58188/59184, loss: 5.2828]\n",
            "Epoch [15/15], batch: [58189/59184, loss: 5.7560]\n",
            "Epoch [15/15], batch: [58190/59184, loss: 5.6247]\n",
            "Epoch [15/15], batch: [58191/59184, loss: 6.2670]\n",
            "Epoch [15/15], batch: [58192/59184, loss: 5.9378]\n",
            "Epoch [15/15], batch: [58193/59184, loss: 5.8248]\n",
            "Epoch [15/15], batch: [58194/59184, loss: 6.6558]\n",
            "Epoch [15/15], batch: [58195/59184, loss: 4.8188]\n",
            "Epoch [15/15], batch: [58196/59184, loss: 5.7322]\n",
            "Epoch [15/15], batch: [58197/59184, loss: 7.2384]\n",
            "Epoch [15/15], batch: [58198/59184, loss: 4.8734]\n",
            "Epoch [15/15], batch: [58199/59184, loss: 5.6515]\n",
            "Epoch [15/15], batch: [58200/59184, loss: 6.5230]\n",
            "Epoch [15/15], batch: [58201/59184, loss: 5.8298]\n",
            "Epoch [15/15], batch: [58202/59184, loss: 6.2043]\n",
            "Epoch [15/15], batch: [58203/59184, loss: 5.6675]\n",
            "Epoch [15/15], batch: [58204/59184, loss: 5.9821]\n",
            "Epoch [15/15], batch: [58205/59184, loss: 6.2044]\n",
            "Epoch [15/15], batch: [58206/59184, loss: 7.3459]\n",
            "Epoch [15/15], batch: [58207/59184, loss: 7.2771]\n",
            "Epoch [15/15], batch: [58208/59184, loss: 5.6442]\n",
            "Epoch [15/15], batch: [58209/59184, loss: 5.9514]\n",
            "Epoch [15/15], batch: [58210/59184, loss: 4.3563]\n",
            "Epoch [15/15], batch: [58211/59184, loss: 3.5781]\n",
            "Epoch [15/15], batch: [58212/59184, loss: 5.6830]\n",
            "Epoch [15/15], batch: [58213/59184, loss: 6.6922]\n",
            "Epoch [15/15], batch: [58214/59184, loss: 6.3011]\n",
            "Epoch [15/15], batch: [58215/59184, loss: 6.8112]\n",
            "Epoch [15/15], batch: [58216/59184, loss: 7.6753]\n",
            "Epoch [15/15], batch: [58217/59184, loss: 7.3970]\n",
            "Epoch [15/15], batch: [58218/59184, loss: 5.7635]\n",
            "Epoch [15/15], batch: [58219/59184, loss: 5.6682]\n",
            "Epoch [15/15], batch: [58220/59184, loss: 4.5205]\n",
            "Epoch [15/15], batch: [58221/59184, loss: 6.0187]\n",
            "Epoch [15/15], batch: [58222/59184, loss: 4.0285]\n",
            "Epoch [15/15], batch: [58223/59184, loss: 4.6793]\n",
            "Epoch [15/15], batch: [58224/59184, loss: 6.3562]\n",
            "Epoch [15/15], batch: [58225/59184, loss: 4.7409]\n",
            "Epoch [15/15], batch: [58226/59184, loss: 5.3204]\n",
            "Epoch [15/15], batch: [58227/59184, loss: 5.8380]\n",
            "Epoch [15/15], batch: [58228/59184, loss: 3.9796]\n",
            "Epoch [15/15], batch: [58229/59184, loss: 5.2167]\n",
            "Epoch [15/15], batch: [58230/59184, loss: 5.6121]\n",
            "Epoch [15/15], batch: [58231/59184, loss: 6.1083]\n",
            "Epoch [15/15], batch: [58232/59184, loss: 4.4898]\n",
            "Epoch [15/15], batch: [58233/59184, loss: 5.8310]\n",
            "Epoch [15/15], batch: [58234/59184, loss: 4.8950]\n",
            "Epoch [15/15], batch: [58235/59184, loss: 4.3299]\n",
            "Epoch [15/15], batch: [58236/59184, loss: 6.4471]\n",
            "Epoch [15/15], batch: [58237/59184, loss: 5.1759]\n",
            "Epoch [15/15], batch: [58238/59184, loss: 4.3361]\n",
            "Epoch [15/15], batch: [58239/59184, loss: 6.1002]\n",
            "Epoch [15/15], batch: [58240/59184, loss: 3.6279]\n",
            "Epoch [15/15], batch: [58241/59184, loss: 5.4073]\n",
            "Epoch [15/15], batch: [58242/59184, loss: 7.2954]\n",
            "Epoch [15/15], batch: [58243/59184, loss: 6.8095]\n",
            "Epoch [15/15], batch: [58244/59184, loss: 5.9151]\n",
            "Epoch [15/15], batch: [58245/59184, loss: 5.0430]\n",
            "Epoch [15/15], batch: [58246/59184, loss: 6.0697]\n",
            "Epoch [15/15], batch: [58247/59184, loss: 6.2144]\n",
            "Epoch [15/15], batch: [58248/59184, loss: 5.9131]\n",
            "Epoch [15/15], batch: [58249/59184, loss: 5.8225]\n",
            "Epoch [15/15], batch: [58250/59184, loss: 5.6096]\n",
            "Epoch [15/15], batch: [58251/59184, loss: 5.7835]\n",
            "Epoch [15/15], batch: [58252/59184, loss: 6.0837]\n",
            "Epoch [15/15], batch: [58253/59184, loss: 5.9045]\n",
            "Epoch [15/15], batch: [58254/59184, loss: 6.0890]\n",
            "Epoch [15/15], batch: [58255/59184, loss: 6.5383]\n",
            "Epoch [15/15], batch: [58256/59184, loss: 5.9975]\n",
            "Epoch [15/15], batch: [58257/59184, loss: 6.6691]\n",
            "Epoch [15/15], batch: [58258/59184, loss: 6.7399]\n",
            "Epoch [15/15], batch: [58259/59184, loss: 7.7854]\n",
            "Epoch [15/15], batch: [58260/59184, loss: 7.6216]\n",
            "Epoch [15/15], batch: [58261/59184, loss: 7.4155]\n",
            "Epoch [15/15], batch: [58262/59184, loss: 6.4574]\n",
            "Epoch [15/15], batch: [58263/59184, loss: 6.9049]\n",
            "Epoch [15/15], batch: [58264/59184, loss: 7.2584]\n",
            "Epoch [15/15], batch: [58265/59184, loss: 5.7977]\n",
            "Epoch [15/15], batch: [58266/59184, loss: 6.2431]\n",
            "Epoch [15/15], batch: [58267/59184, loss: 6.8683]\n",
            "Epoch [15/15], batch: [58268/59184, loss: 5.0571]\n",
            "Epoch [15/15], batch: [58269/59184, loss: 4.5904]\n",
            "Epoch [15/15], batch: [58270/59184, loss: 6.1821]\n",
            "Epoch [15/15], batch: [58271/59184, loss: 8.2428]\n",
            "Epoch [15/15], batch: [58272/59184, loss: 4.8842]\n",
            "Epoch [15/15], batch: [58273/59184, loss: 7.3995]\n",
            "Epoch [15/15], batch: [58274/59184, loss: 7.9320]\n",
            "Epoch [15/15], batch: [58275/59184, loss: 6.4156]\n",
            "Epoch [15/15], batch: [58276/59184, loss: 7.1529]\n",
            "Epoch [15/15], batch: [58277/59184, loss: 4.7592]\n",
            "Epoch [15/15], batch: [58278/59184, loss: 4.5947]\n",
            "Epoch [15/15], batch: [58279/59184, loss: 4.1461]\n",
            "Epoch [15/15], batch: [58280/59184, loss: 6.1175]\n",
            "Epoch [15/15], batch: [58281/59184, loss: 4.4259]\n",
            "Epoch [15/15], batch: [58282/59184, loss: 4.2627]\n",
            "Epoch [15/15], batch: [58283/59184, loss: 5.3261]\n",
            "Epoch [15/15], batch: [58284/59184, loss: 5.9696]\n",
            "Epoch [15/15], batch: [58285/59184, loss: 5.9404]\n",
            "Epoch [15/15], batch: [58286/59184, loss: 4.1231]\n",
            "Epoch [15/15], batch: [58287/59184, loss: 5.6055]\n",
            "Epoch [15/15], batch: [58288/59184, loss: 4.8180]\n",
            "Epoch [15/15], batch: [58289/59184, loss: 5.4626]\n",
            "Epoch [15/15], batch: [58290/59184, loss: 4.3899]\n",
            "Epoch [15/15], batch: [58291/59184, loss: 6.5579]\n",
            "Epoch [15/15], batch: [58292/59184, loss: 5.4140]\n",
            "Epoch [15/15], batch: [58293/59184, loss: 4.7822]\n",
            "Epoch [15/15], batch: [58294/59184, loss: 5.0377]\n",
            "Epoch [15/15], batch: [58295/59184, loss: 6.1184]\n",
            "Epoch [15/15], batch: [58296/59184, loss: 5.2046]\n",
            "Epoch [15/15], batch: [58297/59184, loss: 6.1339]\n",
            "Epoch [15/15], batch: [58298/59184, loss: 4.5996]\n",
            "Epoch [15/15], batch: [58299/59184, loss: 5.4551]\n",
            "Epoch [15/15], batch: [58300/59184, loss: 4.8086]\n",
            "Epoch [15/15], batch: [58301/59184, loss: 6.6490]\n",
            "Epoch [15/15], batch: [58302/59184, loss: 6.9124]\n",
            "Epoch [15/15], batch: [58303/59184, loss: 4.5954]\n",
            "Epoch [15/15], batch: [58304/59184, loss: 6.0569]\n",
            "Epoch [15/15], batch: [58305/59184, loss: 5.1489]\n",
            "Epoch [15/15], batch: [58306/59184, loss: 5.3572]\n",
            "Epoch [15/15], batch: [58307/59184, loss: 2.8298]\n",
            "Epoch [15/15], batch: [58308/59184, loss: 6.2608]\n",
            "Epoch [15/15], batch: [58309/59184, loss: 4.7644]\n",
            "Epoch [15/15], batch: [58310/59184, loss: 5.6038]\n",
            "Epoch [15/15], batch: [58311/59184, loss: 4.5716]\n",
            "Epoch [15/15], batch: [58312/59184, loss: 5.7142]\n",
            "Epoch [15/15], batch: [58313/59184, loss: 5.6395]\n",
            "Epoch [15/15], batch: [58314/59184, loss: 6.8900]\n",
            "Epoch [15/15], batch: [58315/59184, loss: 5.6720]\n",
            "Epoch [15/15], batch: [58316/59184, loss: 5.7193]\n",
            "Epoch [15/15], batch: [58317/59184, loss: 5.9570]\n",
            "Epoch [15/15], batch: [58318/59184, loss: 7.0565]\n",
            "Epoch [15/15], batch: [58319/59184, loss: 6.0789]\n",
            "Epoch [15/15], batch: [58320/59184, loss: 7.0016]\n",
            "Epoch [15/15], batch: [58321/59184, loss: 4.3278]\n",
            "Epoch [15/15], batch: [58322/59184, loss: 4.9033]\n",
            "Epoch [15/15], batch: [58323/59184, loss: 4.9305]\n",
            "Epoch [15/15], batch: [58324/59184, loss: 7.2120]\n",
            "Epoch [15/15], batch: [58325/59184, loss: 5.4227]\n",
            "Epoch [15/15], batch: [58326/59184, loss: 5.1444]\n",
            "Epoch [15/15], batch: [58327/59184, loss: 7.5645]\n",
            "Epoch [15/15], batch: [58328/59184, loss: 4.1192]\n",
            "Epoch [15/15], batch: [58329/59184, loss: 5.2128]\n",
            "Epoch [15/15], batch: [58330/59184, loss: 6.1699]\n",
            "Epoch [15/15], batch: [58331/59184, loss: 7.1876]\n",
            "Epoch [15/15], batch: [58332/59184, loss: 6.2682]\n",
            "Epoch [15/15], batch: [58333/59184, loss: 5.3980]\n",
            "Epoch [15/15], batch: [58334/59184, loss: 6.5476]\n",
            "Epoch [15/15], batch: [58335/59184, loss: 6.0303]\n",
            "Epoch [15/15], batch: [58336/59184, loss: 7.1209]\n",
            "Epoch [15/15], batch: [58337/59184, loss: 6.5819]\n",
            "Epoch [15/15], batch: [58338/59184, loss: 6.3147]\n",
            "Epoch [15/15], batch: [58339/59184, loss: 4.9504]\n",
            "Epoch [15/15], batch: [58340/59184, loss: 5.9237]\n",
            "Epoch [15/15], batch: [58341/59184, loss: 6.7951]\n",
            "Epoch [15/15], batch: [58342/59184, loss: 6.5443]\n",
            "Epoch [15/15], batch: [58343/59184, loss: 5.9856]\n",
            "Epoch [15/15], batch: [58344/59184, loss: 2.5530]\n",
            "Epoch [15/15], batch: [58345/59184, loss: 4.9816]\n",
            "Epoch [15/15], batch: [58346/59184, loss: 5.9263]\n",
            "Epoch [15/15], batch: [58347/59184, loss: 5.2070]\n",
            "Epoch [15/15], batch: [58348/59184, loss: 6.4968]\n",
            "Epoch [15/15], batch: [58349/59184, loss: 6.3375]\n",
            "Epoch [15/15], batch: [58350/59184, loss: 5.5703]\n",
            "Epoch [15/15], batch: [58351/59184, loss: 5.9912]\n",
            "Epoch [15/15], batch: [58352/59184, loss: 5.4079]\n",
            "Epoch [15/15], batch: [58353/59184, loss: 5.4007]\n",
            "Epoch [15/15], batch: [58354/59184, loss: 3.9444]\n",
            "Epoch [15/15], batch: [58355/59184, loss: 5.4964]\n",
            "Epoch [15/15], batch: [58356/59184, loss: 5.1185]\n",
            "Epoch [15/15], batch: [58357/59184, loss: 5.0353]\n",
            "Epoch [15/15], batch: [58358/59184, loss: 5.8424]\n",
            "Epoch [15/15], batch: [58359/59184, loss: 5.5204]\n",
            "Epoch [15/15], batch: [58360/59184, loss: 6.9284]\n",
            "Epoch [15/15], batch: [58361/59184, loss: 7.0690]\n",
            "Epoch [15/15], batch: [58362/59184, loss: 4.5674]\n",
            "Epoch [15/15], batch: [58363/59184, loss: 5.2887]\n",
            "Epoch [15/15], batch: [58364/59184, loss: 6.2615]\n",
            "Epoch [15/15], batch: [58365/59184, loss: 5.4112]\n",
            "Epoch [15/15], batch: [58366/59184, loss: 4.4517]\n",
            "Epoch [15/15], batch: [58367/59184, loss: 6.0195]\n",
            "Epoch [15/15], batch: [58368/59184, loss: 6.8045]\n",
            "Epoch [15/15], batch: [58369/59184, loss: 4.5234]\n",
            "Epoch [15/15], batch: [58370/59184, loss: 5.5543]\n",
            "Epoch [15/15], batch: [58371/59184, loss: 6.7850]\n",
            "Epoch [15/15], batch: [58372/59184, loss: 4.9479]\n",
            "Epoch [15/15], batch: [58373/59184, loss: 6.5586]\n",
            "Epoch [15/15], batch: [58374/59184, loss: 6.6103]\n",
            "Epoch [15/15], batch: [58375/59184, loss: 5.2555]\n",
            "Epoch [15/15], batch: [58376/59184, loss: 2.8590]\n",
            "Epoch [15/15], batch: [58377/59184, loss: 6.2999]\n",
            "Epoch [15/15], batch: [58378/59184, loss: 5.4889]\n",
            "Epoch [15/15], batch: [58379/59184, loss: 5.3549]\n",
            "Epoch [15/15], batch: [58380/59184, loss: 6.7044]\n",
            "Epoch [15/15], batch: [58381/59184, loss: 7.2481]\n",
            "Epoch [15/15], batch: [58382/59184, loss: 5.4993]\n",
            "Epoch [15/15], batch: [58383/59184, loss: 5.7663]\n",
            "Epoch [15/15], batch: [58384/59184, loss: 5.0498]\n",
            "Epoch [15/15], batch: [58385/59184, loss: 4.4232]\n",
            "Epoch [15/15], batch: [58386/59184, loss: 5.3814]\n",
            "Epoch [15/15], batch: [58387/59184, loss: 5.8518]\n",
            "Epoch [15/15], batch: [58388/59184, loss: 6.1155]\n",
            "Epoch [15/15], batch: [58389/59184, loss: 6.1378]\n",
            "Epoch [15/15], batch: [58390/59184, loss: 7.3039]\n",
            "Epoch [15/15], batch: [58391/59184, loss: 6.4262]\n",
            "Epoch [15/15], batch: [58392/59184, loss: 5.1628]\n",
            "Epoch [15/15], batch: [58393/59184, loss: 4.5897]\n",
            "Epoch [15/15], batch: [58394/59184, loss: 4.6336]\n",
            "Epoch [15/15], batch: [58395/59184, loss: 5.7937]\n",
            "Epoch [15/15], batch: [58396/59184, loss: 6.0401]\n",
            "Epoch [15/15], batch: [58397/59184, loss: 5.8543]\n",
            "Epoch [15/15], batch: [58398/59184, loss: 4.9424]\n",
            "Epoch [15/15], batch: [58399/59184, loss: 7.7312]\n",
            "Epoch [15/15], batch: [58400/59184, loss: 6.6405]\n",
            "Epoch [15/15], batch: [58401/59184, loss: 6.8504]\n",
            "Epoch [15/15], batch: [58402/59184, loss: 6.4823]\n",
            "Epoch [15/15], batch: [58403/59184, loss: 4.4563]\n",
            "Epoch [15/15], batch: [58404/59184, loss: 5.5650]\n",
            "Epoch [15/15], batch: [58405/59184, loss: 5.8110]\n",
            "Epoch [15/15], batch: [58406/59184, loss: 6.6253]\n",
            "Epoch [15/15], batch: [58407/59184, loss: 7.0335]\n",
            "Epoch [15/15], batch: [58408/59184, loss: 6.8975]\n",
            "Epoch [15/15], batch: [58409/59184, loss: 4.5103]\n",
            "Epoch [15/15], batch: [58410/59184, loss: 5.7099]\n",
            "Epoch [15/15], batch: [58411/59184, loss: 6.2404]\n",
            "Epoch [15/15], batch: [58412/59184, loss: 6.1508]\n",
            "Epoch [15/15], batch: [58413/59184, loss: 6.0710]\n",
            "Epoch [15/15], batch: [58414/59184, loss: 5.6581]\n",
            "Epoch [15/15], batch: [58415/59184, loss: 5.5334]\n",
            "Epoch [15/15], batch: [58416/59184, loss: 5.7069]\n",
            "Epoch [15/15], batch: [58417/59184, loss: 6.7804]\n",
            "Epoch [15/15], batch: [58418/59184, loss: 6.7391]\n",
            "Epoch [15/15], batch: [58419/59184, loss: 6.3265]\n",
            "Epoch [15/15], batch: [58420/59184, loss: 8.1436]\n",
            "Epoch [15/15], batch: [58421/59184, loss: 6.5608]\n",
            "Epoch [15/15], batch: [58422/59184, loss: 6.6283]\n",
            "Epoch [15/15], batch: [58423/59184, loss: 6.3062]\n",
            "Epoch [15/15], batch: [58424/59184, loss: 5.5951]\n",
            "Epoch [15/15], batch: [58425/59184, loss: 6.7110]\n",
            "Epoch [15/15], batch: [58426/59184, loss: 6.8787]\n",
            "Epoch [15/15], batch: [58427/59184, loss: 6.3850]\n",
            "Epoch [15/15], batch: [58428/59184, loss: 7.5786]\n",
            "Epoch [15/15], batch: [58429/59184, loss: 6.1417]\n",
            "Epoch [15/15], batch: [58430/59184, loss: 6.7809]\n",
            "Epoch [15/15], batch: [58431/59184, loss: 6.3948]\n",
            "Epoch [15/15], batch: [58432/59184, loss: 6.6783]\n",
            "Epoch [15/15], batch: [58433/59184, loss: 7.0050]\n",
            "Epoch [15/15], batch: [58434/59184, loss: 5.3669]\n",
            "Epoch [15/15], batch: [58435/59184, loss: 6.3278]\n",
            "Epoch [15/15], batch: [58436/59184, loss: 6.8093]\n",
            "Epoch [15/15], batch: [58437/59184, loss: 6.7547]\n",
            "Epoch [15/15], batch: [58438/59184, loss: 6.9783]\n",
            "Epoch [15/15], batch: [58439/59184, loss: 5.3581]\n",
            "Epoch [15/15], batch: [58440/59184, loss: 6.2102]\n",
            "Epoch [15/15], batch: [58441/59184, loss: 4.7007]\n",
            "Epoch [15/15], batch: [58442/59184, loss: 5.9100]\n",
            "Epoch [15/15], batch: [58443/59184, loss: 4.5857]\n",
            "Epoch [15/15], batch: [58444/59184, loss: 5.3490]\n",
            "Epoch [15/15], batch: [58445/59184, loss: 6.2995]\n",
            "Epoch [15/15], batch: [58446/59184, loss: 6.6240]\n",
            "Epoch [15/15], batch: [58447/59184, loss: 5.9483]\n",
            "Epoch [15/15], batch: [58448/59184, loss: 6.1257]\n",
            "Epoch [15/15], batch: [58449/59184, loss: 6.4534]\n",
            "Epoch [15/15], batch: [58450/59184, loss: 6.1944]\n",
            "Epoch [15/15], batch: [58451/59184, loss: 6.6455]\n",
            "Epoch [15/15], batch: [58452/59184, loss: 5.9388]\n",
            "Epoch [15/15], batch: [58453/59184, loss: 6.4295]\n",
            "Epoch [15/15], batch: [58454/59184, loss: 6.0707]\n",
            "Epoch [15/15], batch: [58455/59184, loss: 7.0245]\n",
            "Epoch [15/15], batch: [58456/59184, loss: 5.7131]\n",
            "Epoch [15/15], batch: [58457/59184, loss: 5.6636]\n",
            "Epoch [15/15], batch: [58458/59184, loss: 6.3103]\n",
            "Epoch [15/15], batch: [58459/59184, loss: 6.2603]\n",
            "Epoch [15/15], batch: [58460/59184, loss: 5.2943]\n",
            "Epoch [15/15], batch: [58461/59184, loss: 4.6783]\n",
            "Epoch [15/15], batch: [58462/59184, loss: 6.1254]\n",
            "Epoch [15/15], batch: [58463/59184, loss: 5.1763]\n",
            "Epoch [15/15], batch: [58464/59184, loss: 6.5669]\n",
            "Epoch [15/15], batch: [58465/59184, loss: 6.4537]\n",
            "Epoch [15/15], batch: [58466/59184, loss: 6.1305]\n",
            "Epoch [15/15], batch: [58467/59184, loss: 7.3783]\n",
            "Epoch [15/15], batch: [58468/59184, loss: 5.6517]\n",
            "Epoch [15/15], batch: [58469/59184, loss: 7.2800]\n",
            "Epoch [15/15], batch: [58470/59184, loss: 6.6429]\n",
            "Epoch [15/15], batch: [58471/59184, loss: 6.5569]\n",
            "Epoch [15/15], batch: [58472/59184, loss: 3.5432]\n",
            "Epoch [15/15], batch: [58473/59184, loss: 6.5476]\n",
            "Epoch [15/15], batch: [58474/59184, loss: 4.8122]\n",
            "Epoch [15/15], batch: [58475/59184, loss: 5.1869]\n",
            "Epoch [15/15], batch: [58476/59184, loss: 5.1381]\n",
            "Epoch [15/15], batch: [58477/59184, loss: 3.2552]\n",
            "Epoch [15/15], batch: [58478/59184, loss: 3.8079]\n",
            "Epoch [15/15], batch: [58479/59184, loss: 6.1993]\n",
            "Epoch [15/15], batch: [58480/59184, loss: 6.4809]\n",
            "Epoch [15/15], batch: [58481/59184, loss: 6.2480]\n",
            "Epoch [15/15], batch: [58482/59184, loss: 6.8141]\n",
            "Epoch [15/15], batch: [58483/59184, loss: 6.1062]\n",
            "Epoch [15/15], batch: [58484/59184, loss: 6.8911]\n",
            "Epoch [15/15], batch: [58485/59184, loss: 5.0657]\n",
            "Epoch [15/15], batch: [58486/59184, loss: 5.9168]\n",
            "Epoch [15/15], batch: [58487/59184, loss: 6.4635]\n",
            "Epoch [15/15], batch: [58488/59184, loss: 5.9293]\n",
            "Epoch [15/15], batch: [58489/59184, loss: 5.5681]\n",
            "Epoch [15/15], batch: [58490/59184, loss: 5.5868]\n",
            "Epoch [15/15], batch: [58491/59184, loss: 7.0317]\n",
            "Epoch [15/15], batch: [58492/59184, loss: 5.9791]\n",
            "Epoch [15/15], batch: [58493/59184, loss: 5.9124]\n",
            "Epoch [15/15], batch: [58494/59184, loss: 5.2889]\n",
            "Epoch [15/15], batch: [58495/59184, loss: 6.6900]\n",
            "Epoch [15/15], batch: [58496/59184, loss: 6.1598]\n",
            "Epoch [15/15], batch: [58497/59184, loss: 6.5230]\n",
            "Epoch [15/15], batch: [58498/59184, loss: 6.0581]\n",
            "Epoch [15/15], batch: [58499/59184, loss: 5.0729]\n",
            "Epoch [15/15], batch: [58500/59184, loss: 5.6119]\n",
            "Epoch [15/15], batch: [58501/59184, loss: 6.4587]\n",
            "Epoch [15/15], batch: [58502/59184, loss: 6.0241]\n",
            "Epoch [15/15], batch: [58503/59184, loss: 6.1525]\n",
            "Epoch [15/15], batch: [58504/59184, loss: 5.9773]\n",
            "Epoch [15/15], batch: [58505/59184, loss: 6.5361]\n",
            "Epoch [15/15], batch: [58506/59184, loss: 6.6837]\n",
            "Epoch [15/15], batch: [58507/59184, loss: 5.4863]\n",
            "Epoch [15/15], batch: [58508/59184, loss: 3.6429]\n",
            "Epoch [15/15], batch: [58509/59184, loss: 5.5450]\n",
            "Epoch [15/15], batch: [58510/59184, loss: 4.8538]\n",
            "Epoch [15/15], batch: [58511/59184, loss: 4.4866]\n",
            "Epoch [15/15], batch: [58512/59184, loss: 5.4662]\n",
            "Epoch [15/15], batch: [58513/59184, loss: 6.5665]\n",
            "Epoch [15/15], batch: [58514/59184, loss: 5.5059]\n",
            "Epoch [15/15], batch: [58515/59184, loss: 6.0563]\n",
            "Epoch [15/15], batch: [58516/59184, loss: 6.3415]\n",
            "Epoch [15/15], batch: [58517/59184, loss: 5.6776]\n",
            "Epoch [15/15], batch: [58518/59184, loss: 6.6388]\n",
            "Epoch [15/15], batch: [58519/59184, loss: 6.2032]\n",
            "Epoch [15/15], batch: [58520/59184, loss: 7.4523]\n",
            "Epoch [15/15], batch: [58521/59184, loss: 7.1275]\n",
            "Epoch [15/15], batch: [58522/59184, loss: 4.9103]\n",
            "Epoch [15/15], batch: [58523/59184, loss: 5.7528]\n",
            "Epoch [15/15], batch: [58524/59184, loss: 5.9369]\n",
            "Epoch [15/15], batch: [58525/59184, loss: 5.5932]\n",
            "Epoch [15/15], batch: [58526/59184, loss: 6.2430]\n",
            "Epoch [15/15], batch: [58527/59184, loss: 7.5723]\n",
            "Epoch [15/15], batch: [58528/59184, loss: 7.4602]\n",
            "Epoch [15/15], batch: [58529/59184, loss: 4.1328]\n",
            "Epoch [15/15], batch: [58530/59184, loss: 4.9667]\n",
            "Epoch [15/15], batch: [58531/59184, loss: 4.1664]\n",
            "Epoch [15/15], batch: [58532/59184, loss: 5.4026]\n",
            "Epoch [15/15], batch: [58533/59184, loss: 6.6070]\n",
            "Epoch [15/15], batch: [58534/59184, loss: 6.1047]\n",
            "Epoch [15/15], batch: [58535/59184, loss: 5.4035]\n",
            "Epoch [15/15], batch: [58536/59184, loss: 5.3961]\n",
            "Epoch [15/15], batch: [58537/59184, loss: 5.4523]\n",
            "Epoch [15/15], batch: [58538/59184, loss: 4.7410]\n",
            "Epoch [15/15], batch: [58539/59184, loss: 4.5569]\n",
            "Epoch [15/15], batch: [58540/59184, loss: 4.5489]\n",
            "Epoch [15/15], batch: [58541/59184, loss: 5.9655]\n",
            "Epoch [15/15], batch: [58542/59184, loss: 6.5731]\n",
            "Epoch [15/15], batch: [58543/59184, loss: 4.7515]\n",
            "Epoch [15/15], batch: [58544/59184, loss: 7.0559]\n",
            "Epoch [15/15], batch: [58545/59184, loss: 5.9204]\n",
            "Epoch [15/15], batch: [58546/59184, loss: 7.1194]\n",
            "Epoch [15/15], batch: [58547/59184, loss: 5.9826]\n",
            "Epoch [15/15], batch: [58548/59184, loss: 4.2803]\n",
            "Epoch [15/15], batch: [58549/59184, loss: 4.9664]\n",
            "Epoch [15/15], batch: [58550/59184, loss: 5.1363]\n",
            "Epoch [15/15], batch: [58551/59184, loss: 4.4325]\n",
            "Epoch [15/15], batch: [58552/59184, loss: 5.5922]\n",
            "Epoch [15/15], batch: [58553/59184, loss: 6.1219]\n",
            "Epoch [15/15], batch: [58554/59184, loss: 4.5073]\n",
            "Epoch [15/15], batch: [58555/59184, loss: 4.6417]\n",
            "Epoch [15/15], batch: [58556/59184, loss: 5.7509]\n",
            "Epoch [15/15], batch: [58557/59184, loss: 5.6151]\n",
            "Epoch [15/15], batch: [58558/59184, loss: 5.3936]\n",
            "Epoch [15/15], batch: [58559/59184, loss: 6.1273]\n",
            "Epoch [15/15], batch: [58560/59184, loss: 6.2764]\n",
            "Epoch [15/15], batch: [58561/59184, loss: 6.8379]\n",
            "Epoch [15/15], batch: [58562/59184, loss: 6.7170]\n",
            "Epoch [15/15], batch: [58563/59184, loss: 4.6235]\n",
            "Epoch [15/15], batch: [58564/59184, loss: 5.7414]\n",
            "Epoch [15/15], batch: [58565/59184, loss: 5.2020]\n",
            "Epoch [15/15], batch: [58566/59184, loss: 6.6679]\n",
            "Epoch [15/15], batch: [58567/59184, loss: 4.9461]\n",
            "Epoch [15/15], batch: [58568/59184, loss: 5.7175]\n",
            "Epoch [15/15], batch: [58569/59184, loss: 5.3021]\n",
            "Epoch [15/15], batch: [58570/59184, loss: 5.5084]\n",
            "Epoch [15/15], batch: [58571/59184, loss: 6.6752]\n",
            "Epoch [15/15], batch: [58572/59184, loss: 5.2558]\n",
            "Epoch [15/15], batch: [58573/59184, loss: 6.9202]\n",
            "Epoch [15/15], batch: [58574/59184, loss: 5.4249]\n",
            "Epoch [15/15], batch: [58575/59184, loss: 5.5551]\n",
            "Epoch [15/15], batch: [58576/59184, loss: 6.8736]\n",
            "Epoch [15/15], batch: [58577/59184, loss: 7.0240]\n",
            "Epoch [15/15], batch: [58578/59184, loss: 5.0412]\n",
            "Epoch [15/15], batch: [58579/59184, loss: 5.0330]\n",
            "Epoch [15/15], batch: [58580/59184, loss: 6.2208]\n",
            "Epoch [15/15], batch: [58581/59184, loss: 2.7440]\n",
            "Epoch [15/15], batch: [58582/59184, loss: 5.6187]\n",
            "Epoch [15/15], batch: [58583/59184, loss: 5.1914]\n",
            "Epoch [15/15], batch: [58584/59184, loss: 7.7624]\n",
            "Epoch [15/15], batch: [58585/59184, loss: 5.8700]\n",
            "Epoch [15/15], batch: [58586/59184, loss: 4.4943]\n",
            "Epoch [15/15], batch: [58587/59184, loss: 5.9084]\n",
            "Epoch [15/15], batch: [58588/59184, loss: 5.8005]\n",
            "Epoch [15/15], batch: [58589/59184, loss: 3.2148]\n",
            "Epoch [15/15], batch: [58590/59184, loss: 5.4199]\n",
            "Epoch [15/15], batch: [58591/59184, loss: 5.2122]\n",
            "Epoch [15/15], batch: [58592/59184, loss: 5.7334]\n",
            "Epoch [15/15], batch: [58593/59184, loss: 7.4405]\n",
            "Epoch [15/15], batch: [58594/59184, loss: 7.2271]\n",
            "Epoch [15/15], batch: [58595/59184, loss: 4.7225]\n",
            "Epoch [15/15], batch: [58596/59184, loss: 4.5274]\n",
            "Epoch [15/15], batch: [58597/59184, loss: 5.8745]\n",
            "Epoch [15/15], batch: [58598/59184, loss: 4.3339]\n",
            "Epoch [15/15], batch: [58599/59184, loss: 6.2236]\n",
            "Epoch [15/15], batch: [58600/59184, loss: 5.6478]\n",
            "Epoch [15/15], batch: [58601/59184, loss: 6.1898]\n",
            "Epoch [15/15], batch: [58602/59184, loss: 5.4716]\n",
            "Epoch [15/15], batch: [58603/59184, loss: 3.9735]\n",
            "Epoch [15/15], batch: [58604/59184, loss: 6.7979]\n",
            "Epoch [15/15], batch: [58605/59184, loss: 5.0797]\n",
            "Epoch [15/15], batch: [58606/59184, loss: 6.2543]\n",
            "Epoch [15/15], batch: [58607/59184, loss: 4.3216]\n",
            "Epoch [15/15], batch: [58608/59184, loss: 6.1488]\n",
            "Epoch [15/15], batch: [58609/59184, loss: 5.8603]\n",
            "Epoch [15/15], batch: [58610/59184, loss: 5.8975]\n",
            "Epoch [15/15], batch: [58611/59184, loss: 4.8191]\n",
            "Epoch [15/15], batch: [58612/59184, loss: 4.6293]\n",
            "Epoch [15/15], batch: [58613/59184, loss: 7.0441]\n",
            "Epoch [15/15], batch: [58614/59184, loss: 4.4281]\n",
            "Epoch [15/15], batch: [58615/59184, loss: 4.3571]\n",
            "Epoch [15/15], batch: [58616/59184, loss: 4.9035]\n",
            "Epoch [15/15], batch: [58617/59184, loss: 4.0816]\n",
            "Epoch [15/15], batch: [58618/59184, loss: 4.0628]\n",
            "Epoch [15/15], batch: [58619/59184, loss: 4.8743]\n",
            "Epoch [15/15], batch: [58620/59184, loss: 3.9695]\n",
            "Epoch [15/15], batch: [58621/59184, loss: 3.5842]\n",
            "Epoch [15/15], batch: [58622/59184, loss: 6.5148]\n",
            "Epoch [15/15], batch: [58623/59184, loss: 3.1093]\n",
            "Epoch [15/15], batch: [58624/59184, loss: 5.0235]\n",
            "Epoch [15/15], batch: [58625/59184, loss: 5.6409]\n",
            "Epoch [15/15], batch: [58626/59184, loss: 5.4355]\n",
            "Epoch [15/15], batch: [58627/59184, loss: 6.2114]\n",
            "Epoch [15/15], batch: [58628/59184, loss: 6.2454]\n",
            "Epoch [15/15], batch: [58629/59184, loss: 4.7733]\n",
            "Epoch [15/15], batch: [58630/59184, loss: 6.1459]\n",
            "Epoch [15/15], batch: [58631/59184, loss: 6.7539]\n",
            "Epoch [15/15], batch: [58632/59184, loss: 7.3406]\n",
            "Epoch [15/15], batch: [58633/59184, loss: 7.4429]\n",
            "Epoch [15/15], batch: [58634/59184, loss: 4.6719]\n",
            "Epoch [15/15], batch: [58635/59184, loss: 6.5311]\n",
            "Epoch [15/15], batch: [58636/59184, loss: 6.9205]\n",
            "Epoch [15/15], batch: [58637/59184, loss: 4.6354]\n",
            "Epoch [15/15], batch: [58638/59184, loss: 7.0275]\n",
            "Epoch [15/15], batch: [58639/59184, loss: 6.9620]\n",
            "Epoch [15/15], batch: [58640/59184, loss: 6.4135]\n",
            "Epoch [15/15], batch: [58641/59184, loss: 7.0131]\n",
            "Epoch [15/15], batch: [58642/59184, loss: 6.1659]\n",
            "Epoch [15/15], batch: [58643/59184, loss: 6.5575]\n",
            "Epoch [15/15], batch: [58644/59184, loss: 6.9392]\n",
            "Epoch [15/15], batch: [58645/59184, loss: 4.8397]\n",
            "Epoch [15/15], batch: [58646/59184, loss: 4.4424]\n",
            "Epoch [15/15], batch: [58647/59184, loss: 5.9553]\n",
            "Epoch [15/15], batch: [58648/59184, loss: 5.5559]\n",
            "Epoch [15/15], batch: [58649/59184, loss: 6.5159]\n",
            "Epoch [15/15], batch: [58650/59184, loss: 5.3335]\n",
            "Epoch [15/15], batch: [58651/59184, loss: 5.9323]\n",
            "Epoch [15/15], batch: [58652/59184, loss: 4.6334]\n",
            "Epoch [15/15], batch: [58653/59184, loss: 3.5192]\n",
            "Epoch [15/15], batch: [58654/59184, loss: 6.0738]\n",
            "Epoch [15/15], batch: [58655/59184, loss: 7.2102]\n",
            "Epoch [15/15], batch: [58656/59184, loss: 6.1501]\n",
            "Epoch [15/15], batch: [58657/59184, loss: 5.0023]\n",
            "Epoch [15/15], batch: [58658/59184, loss: 6.0803]\n",
            "Epoch [15/15], batch: [58659/59184, loss: 5.6577]\n",
            "Epoch [15/15], batch: [58660/59184, loss: 6.4571]\n",
            "Epoch [15/15], batch: [58661/59184, loss: 6.0281]\n",
            "Epoch [15/15], batch: [58662/59184, loss: 5.4214]\n",
            "Epoch [15/15], batch: [58663/59184, loss: 6.3977]\n",
            "Epoch [15/15], batch: [58664/59184, loss: 5.1092]\n",
            "Epoch [15/15], batch: [58665/59184, loss: 5.0690]\n",
            "Epoch [15/15], batch: [58666/59184, loss: 4.3976]\n",
            "Epoch [15/15], batch: [58667/59184, loss: 4.4639]\n",
            "Epoch [15/15], batch: [58668/59184, loss: 5.5791]\n",
            "Epoch [15/15], batch: [58669/59184, loss: 5.3925]\n",
            "Epoch [15/15], batch: [58670/59184, loss: 5.8755]\n",
            "Epoch [15/15], batch: [58671/59184, loss: 5.1080]\n",
            "Epoch [15/15], batch: [58672/59184, loss: 5.9859]\n",
            "Epoch [15/15], batch: [58673/59184, loss: 6.0833]\n",
            "Epoch [15/15], batch: [58674/59184, loss: 5.9702]\n",
            "Epoch [15/15], batch: [58675/59184, loss: 5.8262]\n",
            "Epoch [15/15], batch: [58676/59184, loss: 4.6892]\n",
            "Epoch [15/15], batch: [58677/59184, loss: 4.8736]\n",
            "Epoch [15/15], batch: [58678/59184, loss: 5.3333]\n",
            "Epoch [15/15], batch: [58679/59184, loss: 6.8012]\n",
            "Epoch [15/15], batch: [58680/59184, loss: 6.3192]\n",
            "Epoch [15/15], batch: [58681/59184, loss: 4.3999]\n",
            "Epoch [15/15], batch: [58682/59184, loss: 4.0671]\n",
            "Epoch [15/15], batch: [58683/59184, loss: 5.7855]\n",
            "Epoch [15/15], batch: [58684/59184, loss: 5.2602]\n",
            "Epoch [15/15], batch: [58685/59184, loss: 5.1114]\n",
            "Epoch [15/15], batch: [58686/59184, loss: 5.2209]\n",
            "Epoch [15/15], batch: [58687/59184, loss: 3.2590]\n",
            "Epoch [15/15], batch: [58688/59184, loss: 4.8118]\n",
            "Epoch [15/15], batch: [58689/59184, loss: 3.1765]\n",
            "Epoch [15/15], batch: [58690/59184, loss: 4.3398]\n",
            "Epoch [15/15], batch: [58691/59184, loss: 5.7636]\n",
            "Epoch [15/15], batch: [58692/59184, loss: 4.2477]\n",
            "Epoch [15/15], batch: [58693/59184, loss: 6.0308]\n",
            "Epoch [15/15], batch: [58694/59184, loss: 6.1639]\n",
            "Epoch [15/15], batch: [58695/59184, loss: 5.4865]\n",
            "Epoch [15/15], batch: [58696/59184, loss: 5.1727]\n",
            "Epoch [15/15], batch: [58697/59184, loss: 4.5485]\n",
            "Epoch [15/15], batch: [58698/59184, loss: 4.7924]\n",
            "Epoch [15/15], batch: [58699/59184, loss: 4.8850]\n",
            "Epoch [15/15], batch: [58700/59184, loss: 5.3975]\n",
            "Epoch [15/15], batch: [58701/59184, loss: 7.0342]\n",
            "Epoch [15/15], batch: [58702/59184, loss: 5.4271]\n",
            "Epoch [15/15], batch: [58703/59184, loss: 7.1546]\n",
            "Epoch [15/15], batch: [58704/59184, loss: 5.6208]\n",
            "Epoch [15/15], batch: [58705/59184, loss: 5.5053]\n",
            "Epoch [15/15], batch: [58706/59184, loss: 6.2978]\n",
            "Epoch [15/15], batch: [58707/59184, loss: 6.7277]\n",
            "Epoch [15/15], batch: [58708/59184, loss: 6.3884]\n",
            "Epoch [15/15], batch: [58709/59184, loss: 5.1460]\n",
            "Epoch [15/15], batch: [58710/59184, loss: 4.6751]\n",
            "Epoch [15/15], batch: [58711/59184, loss: 5.8973]\n",
            "Epoch [15/15], batch: [58712/59184, loss: 6.3835]\n",
            "Epoch [15/15], batch: [58713/59184, loss: 6.4986]\n",
            "Epoch [15/15], batch: [58714/59184, loss: 6.3101]\n",
            "Epoch [15/15], batch: [58715/59184, loss: 6.1965]\n",
            "Epoch [15/15], batch: [58716/59184, loss: 5.4287]\n",
            "Epoch [15/15], batch: [58717/59184, loss: 6.1906]\n",
            "Epoch [15/15], batch: [58718/59184, loss: 7.8252]\n",
            "Epoch [15/15], batch: [58719/59184, loss: 4.9653]\n",
            "Epoch [15/15], batch: [58720/59184, loss: 6.7964]\n",
            "Epoch [15/15], batch: [58721/59184, loss: 6.7368]\n",
            "Epoch [15/15], batch: [58722/59184, loss: 6.7418]\n",
            "Epoch [15/15], batch: [58723/59184, loss: 5.8605]\n",
            "Epoch [15/15], batch: [58724/59184, loss: 5.4868]\n",
            "Epoch [15/15], batch: [58725/59184, loss: 5.4894]\n",
            "Epoch [15/15], batch: [58726/59184, loss: 4.3973]\n",
            "Epoch [15/15], batch: [58727/59184, loss: 4.1375]\n",
            "Epoch [15/15], batch: [58728/59184, loss: 6.2125]\n",
            "Epoch [15/15], batch: [58729/59184, loss: 6.0554]\n",
            "Epoch [15/15], batch: [58730/59184, loss: 6.6175]\n",
            "Epoch [15/15], batch: [58731/59184, loss: 6.0407]\n",
            "Epoch [15/15], batch: [58732/59184, loss: 5.8825]\n",
            "Epoch [15/15], batch: [58733/59184, loss: 6.3583]\n",
            "Epoch [15/15], batch: [58734/59184, loss: 5.4998]\n",
            "Epoch [15/15], batch: [58735/59184, loss: 5.8944]\n",
            "Epoch [15/15], batch: [58736/59184, loss: 6.6640]\n",
            "Epoch [15/15], batch: [58737/59184, loss: 5.8956]\n",
            "Epoch [15/15], batch: [58738/59184, loss: 6.1015]\n",
            "Epoch [15/15], batch: [58739/59184, loss: 6.4548]\n",
            "Epoch [15/15], batch: [58740/59184, loss: 7.6900]\n",
            "Epoch [15/15], batch: [58741/59184, loss: 4.8664]\n",
            "Epoch [15/15], batch: [58742/59184, loss: 5.5803]\n",
            "Epoch [15/15], batch: [58743/59184, loss: 5.1345]\n",
            "Epoch [15/15], batch: [58744/59184, loss: 3.8683]\n",
            "Epoch [15/15], batch: [58745/59184, loss: 4.7825]\n",
            "Epoch [15/15], batch: [58746/59184, loss: 5.6988]\n",
            "Epoch [15/15], batch: [58747/59184, loss: 5.0689]\n",
            "Epoch [15/15], batch: [58748/59184, loss: 4.9617]\n",
            "Epoch [15/15], batch: [58749/59184, loss: 4.9614]\n",
            "Epoch [15/15], batch: [58750/59184, loss: 7.4843]\n",
            "Epoch [15/15], batch: [58751/59184, loss: 6.6140]\n",
            "Epoch [15/15], batch: [58752/59184, loss: 7.2457]\n",
            "Epoch [15/15], batch: [58753/59184, loss: 6.5888]\n",
            "Epoch [15/15], batch: [58754/59184, loss: 6.5821]\n",
            "Epoch [15/15], batch: [58755/59184, loss: 5.4855]\n",
            "Epoch [15/15], batch: [58756/59184, loss: 5.8584]\n",
            "Epoch [15/15], batch: [58757/59184, loss: 5.1941]\n",
            "Epoch [15/15], batch: [58758/59184, loss: 5.8319]\n",
            "Epoch [15/15], batch: [58759/59184, loss: 4.1625]\n",
            "Epoch [15/15], batch: [58760/59184, loss: 4.6650]\n",
            "Epoch [15/15], batch: [58761/59184, loss: 5.0070]\n",
            "Epoch [15/15], batch: [58762/59184, loss: 5.8042]\n",
            "Epoch [15/15], batch: [58763/59184, loss: 6.0644]\n",
            "Epoch [15/15], batch: [58764/59184, loss: 6.6535]\n",
            "Epoch [15/15], batch: [58765/59184, loss: 5.5538]\n",
            "Epoch [15/15], batch: [58766/59184, loss: 6.7504]\n",
            "Epoch [15/15], batch: [58767/59184, loss: 6.0252]\n",
            "Epoch [15/15], batch: [58768/59184, loss: 5.5998]\n",
            "Epoch [15/15], batch: [58769/59184, loss: 5.9817]\n",
            "Epoch [15/15], batch: [58770/59184, loss: 5.9780]\n",
            "Epoch [15/15], batch: [58771/59184, loss: 6.3678]\n",
            "Epoch [15/15], batch: [58772/59184, loss: 5.1722]\n",
            "Epoch [15/15], batch: [58773/59184, loss: 6.0904]\n",
            "Epoch [15/15], batch: [58774/59184, loss: 5.5778]\n",
            "Epoch [15/15], batch: [58775/59184, loss: 5.8092]\n",
            "Epoch [15/15], batch: [58776/59184, loss: 5.2926]\n",
            "Epoch [15/15], batch: [58777/59184, loss: 5.3245]\n",
            "Epoch [15/15], batch: [58778/59184, loss: 6.2318]\n",
            "Epoch [15/15], batch: [58779/59184, loss: 5.0271]\n",
            "Epoch [15/15], batch: [58780/59184, loss: 5.4238]\n",
            "Epoch [15/15], batch: [58781/59184, loss: 4.8153]\n",
            "Epoch [15/15], batch: [58782/59184, loss: 5.9845]\n",
            "Epoch [15/15], batch: [58783/59184, loss: 4.7214]\n",
            "Epoch [15/15], batch: [58784/59184, loss: 5.6706]\n",
            "Epoch [15/15], batch: [58785/59184, loss: 5.5006]\n",
            "Epoch [15/15], batch: [58786/59184, loss: 4.8862]\n",
            "Epoch [15/15], batch: [58787/59184, loss: 6.0569]\n",
            "Epoch [15/15], batch: [58788/59184, loss: 5.1003]\n",
            "Epoch [15/15], batch: [58789/59184, loss: 5.4882]\n",
            "Epoch [15/15], batch: [58790/59184, loss: 4.6219]\n",
            "Epoch [15/15], batch: [58791/59184, loss: 6.6728]\n",
            "Epoch [15/15], batch: [58792/59184, loss: 6.4715]\n",
            "Epoch [15/15], batch: [58793/59184, loss: 5.8829]\n",
            "Epoch [15/15], batch: [58794/59184, loss: 6.1651]\n",
            "Epoch [15/15], batch: [58795/59184, loss: 5.4089]\n",
            "Epoch [15/15], batch: [58796/59184, loss: 4.2589]\n",
            "Epoch [15/15], batch: [58797/59184, loss: 6.6769]\n",
            "Epoch [15/15], batch: [58798/59184, loss: 3.8823]\n",
            "Epoch [15/15], batch: [58799/59184, loss: 5.1584]\n",
            "Epoch [15/15], batch: [58800/59184, loss: 5.7949]\n",
            "Epoch [15/15], batch: [58801/59184, loss: 7.9568]\n",
            "Epoch [15/15], batch: [58802/59184, loss: 6.2454]\n",
            "Epoch [15/15], batch: [58803/59184, loss: 6.2519]\n",
            "Epoch [15/15], batch: [58804/59184, loss: 5.8277]\n",
            "Epoch [15/15], batch: [58805/59184, loss: 4.8834]\n",
            "Epoch [15/15], batch: [58806/59184, loss: 5.2881]\n",
            "Epoch [15/15], batch: [58807/59184, loss: 7.1120]\n",
            "Epoch [15/15], batch: [58808/59184, loss: 5.9893]\n",
            "Epoch [15/15], batch: [58809/59184, loss: 5.5649]\n",
            "Epoch [15/15], batch: [58810/59184, loss: 5.5125]\n",
            "Epoch [15/15], batch: [58811/59184, loss: 7.1375]\n",
            "Epoch [15/15], batch: [58812/59184, loss: 6.4893]\n",
            "Epoch [15/15], batch: [58813/59184, loss: 4.4986]\n",
            "Epoch [15/15], batch: [58814/59184, loss: 6.0287]\n",
            "Epoch [15/15], batch: [58815/59184, loss: 5.7287]\n",
            "Epoch [15/15], batch: [58816/59184, loss: 6.5792]\n",
            "Epoch [15/15], batch: [58817/59184, loss: 7.7920]\n",
            "Epoch [15/15], batch: [58818/59184, loss: 4.3952]\n",
            "Epoch [15/15], batch: [58819/59184, loss: 6.9993]\n",
            "Epoch [15/15], batch: [58820/59184, loss: 5.6354]\n",
            "Epoch [15/15], batch: [58821/59184, loss: 5.0240]\n",
            "Epoch [15/15], batch: [58822/59184, loss: 4.7232]\n",
            "Epoch [15/15], batch: [58823/59184, loss: 5.1711]\n",
            "Epoch [15/15], batch: [58824/59184, loss: 4.5866]\n",
            "Epoch [15/15], batch: [58825/59184, loss: 6.5403]\n",
            "Epoch [15/15], batch: [58826/59184, loss: 5.4390]\n",
            "Epoch [15/15], batch: [58827/59184, loss: 5.4549]\n",
            "Epoch [15/15], batch: [58828/59184, loss: 5.5101]\n",
            "Epoch [15/15], batch: [58829/59184, loss: 4.8736]\n",
            "Epoch [15/15], batch: [58830/59184, loss: 4.8331]\n",
            "Epoch [15/15], batch: [58831/59184, loss: 5.1054]\n",
            "Epoch [15/15], batch: [58832/59184, loss: 6.8031]\n",
            "Epoch [15/15], batch: [58833/59184, loss: 5.5997]\n",
            "Epoch [15/15], batch: [58834/59184, loss: 6.3805]\n",
            "Epoch [15/15], batch: [58835/59184, loss: 3.0578]\n",
            "Epoch [15/15], batch: [58836/59184, loss: 4.0020]\n",
            "Epoch [15/15], batch: [58837/59184, loss: 5.6802]\n",
            "Epoch [15/15], batch: [58838/59184, loss: 4.1998]\n",
            "Epoch [15/15], batch: [58839/59184, loss: 5.8917]\n",
            "Epoch [15/15], batch: [58840/59184, loss: 6.7447]\n",
            "Epoch [15/15], batch: [58841/59184, loss: 6.0613]\n",
            "Epoch [15/15], batch: [58842/59184, loss: 5.0366]\n",
            "Epoch [15/15], batch: [58843/59184, loss: 5.0212]\n",
            "Epoch [15/15], batch: [58844/59184, loss: 6.7131]\n",
            "Epoch [15/15], batch: [58845/59184, loss: 5.5826]\n",
            "Epoch [15/15], batch: [58846/59184, loss: 5.5943]\n",
            "Epoch [15/15], batch: [58847/59184, loss: 5.0294]\n",
            "Epoch [15/15], batch: [58848/59184, loss: 5.2545]\n",
            "Epoch [15/15], batch: [58849/59184, loss: 4.7269]\n",
            "Epoch [15/15], batch: [58850/59184, loss: 4.0641]\n",
            "Epoch [15/15], batch: [58851/59184, loss: 6.2071]\n",
            "Epoch [15/15], batch: [58852/59184, loss: 6.6737]\n",
            "Epoch [15/15], batch: [58853/59184, loss: 7.0288]\n",
            "Epoch [15/15], batch: [58854/59184, loss: 7.0602]\n",
            "Epoch [15/15], batch: [58855/59184, loss: 7.2358]\n",
            "Epoch [15/15], batch: [58856/59184, loss: 6.8137]\n",
            "Epoch [15/15], batch: [58857/59184, loss: 6.4788]\n",
            "Epoch [15/15], batch: [58858/59184, loss: 7.6839]\n",
            "Epoch [15/15], batch: [58859/59184, loss: 6.0701]\n",
            "Epoch [15/15], batch: [58860/59184, loss: 5.9587]\n",
            "Epoch [15/15], batch: [58861/59184, loss: 6.3936]\n",
            "Epoch [15/15], batch: [58862/59184, loss: 6.1194]\n",
            "Epoch [15/15], batch: [58863/59184, loss: 5.0412]\n",
            "Epoch [15/15], batch: [58864/59184, loss: 6.3715]\n",
            "Epoch [15/15], batch: [58865/59184, loss: 6.2489]\n",
            "Epoch [15/15], batch: [58866/59184, loss: 7.0334]\n",
            "Epoch [15/15], batch: [58867/59184, loss: 5.6946]\n",
            "Epoch [15/15], batch: [58868/59184, loss: 6.3814]\n",
            "Epoch [15/15], batch: [58869/59184, loss: 4.0998]\n",
            "Epoch [15/15], batch: [58870/59184, loss: 6.4172]\n",
            "Epoch [15/15], batch: [58871/59184, loss: 5.0068]\n",
            "Epoch [15/15], batch: [58872/59184, loss: 6.3186]\n",
            "Epoch [15/15], batch: [58873/59184, loss: 7.3774]\n",
            "Epoch [15/15], batch: [58874/59184, loss: 5.9875]\n",
            "Epoch [15/15], batch: [58875/59184, loss: 5.1359]\n",
            "Epoch [15/15], batch: [58876/59184, loss: 5.5669]\n",
            "Epoch [15/15], batch: [58877/59184, loss: 6.9340]\n",
            "Epoch [15/15], batch: [58878/59184, loss: 6.6136]\n",
            "Epoch [15/15], batch: [58879/59184, loss: 6.6327]\n",
            "Epoch [15/15], batch: [58880/59184, loss: 6.1259]\n",
            "Epoch [15/15], batch: [58881/59184, loss: 7.0315]\n",
            "Epoch [15/15], batch: [58882/59184, loss: 6.0054]\n",
            "Epoch [15/15], batch: [58883/59184, loss: 7.4900]\n",
            "Epoch [15/15], batch: [58884/59184, loss: 7.1769]\n",
            "Epoch [15/15], batch: [58885/59184, loss: 6.7002]\n",
            "Epoch [15/15], batch: [58886/59184, loss: 6.0814]\n",
            "Epoch [15/15], batch: [58887/59184, loss: 6.4333]\n",
            "Epoch [15/15], batch: [58888/59184, loss: 6.5418]\n",
            "Epoch [15/15], batch: [58889/59184, loss: 5.1157]\n",
            "Epoch [15/15], batch: [58890/59184, loss: 6.0810]\n",
            "Epoch [15/15], batch: [58891/59184, loss: 6.0724]\n",
            "Epoch [15/15], batch: [58892/59184, loss: 5.9249]\n",
            "Epoch [15/15], batch: [58893/59184, loss: 7.7068]\n",
            "Epoch [15/15], batch: [58894/59184, loss: 6.7057]\n",
            "Epoch [15/15], batch: [58895/59184, loss: 5.3499]\n",
            "Epoch [15/15], batch: [58896/59184, loss: 6.0264]\n",
            "Epoch [15/15], batch: [58897/59184, loss: 4.9702]\n",
            "Epoch [15/15], batch: [58898/59184, loss: 5.5179]\n",
            "Epoch [15/15], batch: [58899/59184, loss: 7.1450]\n",
            "Epoch [15/15], batch: [58900/59184, loss: 4.9666]\n",
            "Epoch [15/15], batch: [58901/59184, loss: 5.7557]\n",
            "Epoch [15/15], batch: [58902/59184, loss: 3.8904]\n",
            "Epoch [15/15], batch: [58903/59184, loss: 6.9898]\n",
            "Epoch [15/15], batch: [58904/59184, loss: 5.8721]\n",
            "Epoch [15/15], batch: [58905/59184, loss: 6.7920]\n",
            "Epoch [15/15], batch: [58906/59184, loss: 2.9756]\n",
            "Epoch [15/15], batch: [58907/59184, loss: 3.7988]\n",
            "Epoch [15/15], batch: [58908/59184, loss: 5.2824]\n",
            "Epoch [15/15], batch: [58909/59184, loss: 3.2471]\n",
            "Epoch [15/15], batch: [58910/59184, loss: 4.8168]\n",
            "Epoch [15/15], batch: [58911/59184, loss: 5.6236]\n",
            "Epoch [15/15], batch: [58912/59184, loss: 5.8576]\n",
            "Epoch [15/15], batch: [58913/59184, loss: 5.5548]\n",
            "Epoch [15/15], batch: [58914/59184, loss: 4.9846]\n",
            "Epoch [15/15], batch: [58915/59184, loss: 5.7627]\n",
            "Epoch [15/15], batch: [58916/59184, loss: 4.7970]\n",
            "Epoch [15/15], batch: [58917/59184, loss: 5.3429]\n",
            "Epoch [15/15], batch: [58918/59184, loss: 4.9174]\n",
            "Epoch [15/15], batch: [58919/59184, loss: 5.0786]\n",
            "Epoch [15/15], batch: [58920/59184, loss: 4.8121]\n",
            "Epoch [15/15], batch: [58921/59184, loss: 5.3001]\n",
            "Epoch [15/15], batch: [58922/59184, loss: 4.9680]\n",
            "Epoch [15/15], batch: [58923/59184, loss: 5.9750]\n",
            "Epoch [15/15], batch: [58924/59184, loss: 5.6974]\n",
            "Epoch [15/15], batch: [58925/59184, loss: 6.1787]\n",
            "Epoch [15/15], batch: [58926/59184, loss: 5.7256]\n",
            "Epoch [15/15], batch: [58927/59184, loss: 6.3297]\n",
            "Epoch [15/15], batch: [58928/59184, loss: 5.8533]\n",
            "Epoch [15/15], batch: [58929/59184, loss: 5.0915]\n",
            "Epoch [15/15], batch: [58930/59184, loss: 6.1263]\n",
            "Epoch [15/15], batch: [58931/59184, loss: 6.9092]\n",
            "Epoch [15/15], batch: [58932/59184, loss: 6.7100]\n",
            "Epoch [15/15], batch: [58933/59184, loss: 5.4350]\n",
            "Epoch [15/15], batch: [58934/59184, loss: 6.0287]\n",
            "Epoch [15/15], batch: [58935/59184, loss: 6.2019]\n",
            "Epoch [15/15], batch: [58936/59184, loss: 7.0643]\n",
            "Epoch [15/15], batch: [58937/59184, loss: 6.3549]\n",
            "Epoch [15/15], batch: [58938/59184, loss: 5.9248]\n",
            "Epoch [15/15], batch: [58939/59184, loss: 5.7167]\n",
            "Epoch [15/15], batch: [58940/59184, loss: 5.5863]\n",
            "Epoch [15/15], batch: [58941/59184, loss: 7.0330]\n",
            "Epoch [15/15], batch: [58942/59184, loss: 6.0835]\n",
            "Epoch [15/15], batch: [58943/59184, loss: 5.2122]\n",
            "Epoch [15/15], batch: [58944/59184, loss: 4.5867]\n",
            "Epoch [15/15], batch: [58945/59184, loss: 3.6125]\n",
            "Epoch [15/15], batch: [58946/59184, loss: 4.6766]\n",
            "Epoch [15/15], batch: [58947/59184, loss: 4.1078]\n",
            "Epoch [15/15], batch: [58948/59184, loss: 5.8425]\n",
            "Epoch [15/15], batch: [58949/59184, loss: 5.0620]\n",
            "Epoch [15/15], batch: [58950/59184, loss: 5.1152]\n",
            "Epoch [15/15], batch: [58951/59184, loss: 5.1244]\n",
            "Epoch [15/15], batch: [58952/59184, loss: 5.1292]\n",
            "Epoch [15/15], batch: [58953/59184, loss: 3.0630]\n",
            "Epoch [15/15], batch: [58954/59184, loss: 4.3551]\n",
            "Epoch [15/15], batch: [58955/59184, loss: 4.0711]\n",
            "Epoch [15/15], batch: [58956/59184, loss: 7.1410]\n",
            "Epoch [15/15], batch: [58957/59184, loss: 5.7005]\n",
            "Epoch [15/15], batch: [58958/59184, loss: 5.4415]\n",
            "Epoch [15/15], batch: [58959/59184, loss: 6.9778]\n",
            "Epoch [15/15], batch: [58960/59184, loss: 7.0746]\n",
            "Epoch [15/15], batch: [58961/59184, loss: 7.2063]\n",
            "Epoch [15/15], batch: [58962/59184, loss: 5.8390]\n",
            "Epoch [15/15], batch: [58963/59184, loss: 6.5116]\n",
            "Epoch [15/15], batch: [58964/59184, loss: 5.9243]\n",
            "Epoch [15/15], batch: [58965/59184, loss: 7.2979]\n",
            "Epoch [15/15], batch: [58966/59184, loss: 6.0531]\n",
            "Epoch [15/15], batch: [58967/59184, loss: 5.4451]\n",
            "Epoch [15/15], batch: [58968/59184, loss: 5.7856]\n",
            "Epoch [15/15], batch: [58969/59184, loss: 5.7315]\n",
            "Epoch [15/15], batch: [58970/59184, loss: 3.5298]\n",
            "Epoch [15/15], batch: [58971/59184, loss: 4.3337]\n",
            "Epoch [15/15], batch: [58972/59184, loss: 6.1127]\n",
            "Epoch [15/15], batch: [58973/59184, loss: 5.7482]\n",
            "Epoch [15/15], batch: [58974/59184, loss: 6.0674]\n",
            "Epoch [15/15], batch: [58975/59184, loss: 4.9485]\n",
            "Epoch [15/15], batch: [58976/59184, loss: 5.0455]\n",
            "Epoch [15/15], batch: [58977/59184, loss: 4.7192]\n",
            "Epoch [15/15], batch: [58978/59184, loss: 5.5649]\n",
            "Epoch [15/15], batch: [58979/59184, loss: 6.2266]\n",
            "Epoch [15/15], batch: [58980/59184, loss: 5.1808]\n",
            "Epoch [15/15], batch: [58981/59184, loss: 5.1173]\n",
            "Epoch [15/15], batch: [58982/59184, loss: 6.9062]\n",
            "Epoch [15/15], batch: [58983/59184, loss: 5.9950]\n",
            "Epoch [15/15], batch: [58984/59184, loss: 6.8915]\n",
            "Epoch [15/15], batch: [58985/59184, loss: 7.5888]\n",
            "Epoch [15/15], batch: [58986/59184, loss: 5.4872]\n",
            "Epoch [15/15], batch: [58987/59184, loss: 5.0817]\n",
            "Epoch [15/15], batch: [58988/59184, loss: 4.1986]\n",
            "Epoch [15/15], batch: [58989/59184, loss: 5.0584]\n",
            "Epoch [15/15], batch: [58990/59184, loss: 5.1371]\n",
            "Epoch [15/15], batch: [58991/59184, loss: 6.6575]\n",
            "Epoch [15/15], batch: [58992/59184, loss: 5.2861]\n",
            "Epoch [15/15], batch: [58993/59184, loss: 4.0902]\n",
            "Epoch [15/15], batch: [58994/59184, loss: 3.9239]\n",
            "Epoch [15/15], batch: [58995/59184, loss: 5.6291]\n",
            "Epoch [15/15], batch: [58996/59184, loss: 6.0628]\n",
            "Epoch [15/15], batch: [58997/59184, loss: 7.2309]\n",
            "Epoch [15/15], batch: [58998/59184, loss: 5.0667]\n",
            "Epoch [15/15], batch: [58999/59184, loss: 4.8044]\n",
            "Epoch [15/15], batch: [59000/59184, loss: 7.4259]\n",
            "Epoch [15/15], batch: [59001/59184, loss: 5.7973]\n",
            "Epoch [15/15], batch: [59002/59184, loss: 4.3365]\n",
            "Epoch [15/15], batch: [59003/59184, loss: 5.1365]\n",
            "Epoch [15/15], batch: [59004/59184, loss: 6.1566]\n",
            "Epoch [15/15], batch: [59005/59184, loss: 5.7605]\n",
            "Epoch [15/15], batch: [59006/59184, loss: 6.0903]\n",
            "Epoch [15/15], batch: [59007/59184, loss: 6.6698]\n",
            "Epoch [15/15], batch: [59008/59184, loss: 4.3035]\n",
            "Epoch [15/15], batch: [59009/59184, loss: 5.2985]\n",
            "Epoch [15/15], batch: [59010/59184, loss: 6.1491]\n",
            "Epoch [15/15], batch: [59011/59184, loss: 7.3583]\n",
            "Epoch [15/15], batch: [59012/59184, loss: 7.6586]\n",
            "Epoch [15/15], batch: [59013/59184, loss: 5.9674]\n",
            "Epoch [15/15], batch: [59014/59184, loss: 7.1365]\n",
            "Epoch [15/15], batch: [59015/59184, loss: 6.9904]\n",
            "Epoch [15/15], batch: [59016/59184, loss: 5.8390]\n",
            "Epoch [15/15], batch: [59017/59184, loss: 6.9434]\n",
            "Epoch [15/15], batch: [59018/59184, loss: 5.4842]\n",
            "Epoch [15/15], batch: [59019/59184, loss: 4.6905]\n",
            "Epoch [15/15], batch: [59020/59184, loss: 5.0361]\n",
            "Epoch [15/15], batch: [59021/59184, loss: 5.7738]\n",
            "Epoch [15/15], batch: [59022/59184, loss: 4.8158]\n",
            "Epoch [15/15], batch: [59023/59184, loss: 4.5126]\n",
            "Epoch [15/15], batch: [59024/59184, loss: 5.0241]\n",
            "Epoch [15/15], batch: [59025/59184, loss: 6.3932]\n",
            "Epoch [15/15], batch: [59026/59184, loss: 4.5162]\n",
            "Epoch [15/15], batch: [59027/59184, loss: 5.3775]\n",
            "Epoch [15/15], batch: [59028/59184, loss: 4.0479]\n",
            "Epoch [15/15], batch: [59029/59184, loss: 5.7689]\n",
            "Epoch [15/15], batch: [59030/59184, loss: 6.0370]\n",
            "Epoch [15/15], batch: [59031/59184, loss: 5.2540]\n",
            "Epoch [15/15], batch: [59032/59184, loss: 8.2968]\n",
            "Epoch [15/15], batch: [59033/59184, loss: 6.1884]\n",
            "Epoch [15/15], batch: [59034/59184, loss: 5.9092]\n",
            "Epoch [15/15], batch: [59035/59184, loss: 5.7099]\n",
            "Epoch [15/15], batch: [59036/59184, loss: 4.3884]\n",
            "Epoch [15/15], batch: [59037/59184, loss: 5.9011]\n",
            "Epoch [15/15], batch: [59038/59184, loss: 3.5141]\n",
            "Epoch [15/15], batch: [59039/59184, loss: 5.0927]\n",
            "Epoch [15/15], batch: [59040/59184, loss: 4.6413]\n",
            "Epoch [15/15], batch: [59041/59184, loss: 5.1612]\n",
            "Epoch [15/15], batch: [59042/59184, loss: 5.0520]\n",
            "Epoch [15/15], batch: [59043/59184, loss: 6.2015]\n",
            "Epoch [15/15], batch: [59044/59184, loss: 6.2047]\n",
            "Epoch [15/15], batch: [59045/59184, loss: 5.5704]\n",
            "Epoch [15/15], batch: [59046/59184, loss: 6.8215]\n",
            "Epoch [15/15], batch: [59047/59184, loss: 4.9328]\n",
            "Epoch [15/15], batch: [59048/59184, loss: 4.6534]\n",
            "Epoch [15/15], batch: [59049/59184, loss: 3.2134]\n",
            "Epoch [15/15], batch: [59050/59184, loss: 5.1506]\n",
            "Epoch [15/15], batch: [59051/59184, loss: 4.2499]\n",
            "Epoch [15/15], batch: [59052/59184, loss: 5.5456]\n",
            "Epoch [15/15], batch: [59053/59184, loss: 5.4215]\n",
            "Epoch [15/15], batch: [59054/59184, loss: 6.2961]\n",
            "Epoch [15/15], batch: [59055/59184, loss: 6.6062]\n",
            "Epoch [15/15], batch: [59056/59184, loss: 6.5452]\n",
            "Epoch [15/15], batch: [59057/59184, loss: 4.5493]\n",
            "Epoch [15/15], batch: [59058/59184, loss: 4.9936]\n",
            "Epoch [15/15], batch: [59059/59184, loss: 5.3824]\n",
            "Epoch [15/15], batch: [59060/59184, loss: 5.6829]\n",
            "Epoch [15/15], batch: [59061/59184, loss: 4.8508]\n",
            "Epoch [15/15], batch: [59062/59184, loss: 4.5687]\n",
            "Epoch [15/15], batch: [59063/59184, loss: 6.0364]\n",
            "Epoch [15/15], batch: [59064/59184, loss: 5.3932]\n",
            "Epoch [15/15], batch: [59065/59184, loss: 3.6062]\n",
            "Epoch [15/15], batch: [59066/59184, loss: 4.2949]\n",
            "Epoch [15/15], batch: [59067/59184, loss: 6.2363]\n",
            "Epoch [15/15], batch: [59068/59184, loss: 6.3053]\n",
            "Epoch [15/15], batch: [59069/59184, loss: 6.8321]\n",
            "Epoch [15/15], batch: [59070/59184, loss: 4.9820]\n",
            "Epoch [15/15], batch: [59071/59184, loss: 4.7475]\n",
            "Epoch [15/15], batch: [59072/59184, loss: 7.5631]\n",
            "Epoch [15/15], batch: [59073/59184, loss: 8.3287]\n",
            "Epoch [15/15], batch: [59074/59184, loss: 5.9480]\n",
            "Epoch [15/15], batch: [59075/59184, loss: 4.9010]\n",
            "Epoch [15/15], batch: [59076/59184, loss: 5.9110]\n",
            "Epoch [15/15], batch: [59077/59184, loss: 5.5695]\n",
            "Epoch [15/15], batch: [59078/59184, loss: 5.7865]\n",
            "Epoch [15/15], batch: [59079/59184, loss: 5.2751]\n",
            "Epoch [15/15], batch: [59080/59184, loss: 5.4564]\n",
            "Epoch [15/15], batch: [59081/59184, loss: 5.0691]\n",
            "Epoch [15/15], batch: [59082/59184, loss: 4.5898]\n",
            "Epoch [15/15], batch: [59083/59184, loss: 5.5805]\n",
            "Epoch [15/15], batch: [59084/59184, loss: 6.2740]\n",
            "Epoch [15/15], batch: [59085/59184, loss: 6.1753]\n",
            "Epoch [15/15], batch: [59086/59184, loss: 5.2095]\n",
            "Epoch [15/15], batch: [59087/59184, loss: 6.2384]\n",
            "Epoch [15/15], batch: [59088/59184, loss: 7.0645]\n",
            "Epoch [15/15], batch: [59089/59184, loss: 6.3251]\n",
            "Epoch [15/15], batch: [59090/59184, loss: 7.4861]\n",
            "Epoch [15/15], batch: [59091/59184, loss: 6.2456]\n",
            "Epoch [15/15], batch: [59092/59184, loss: 4.2445]\n",
            "Epoch [15/15], batch: [59093/59184, loss: 4.8323]\n",
            "Epoch [15/15], batch: [59094/59184, loss: 5.2403]\n",
            "Epoch [15/15], batch: [59095/59184, loss: 4.3456]\n",
            "Epoch [15/15], batch: [59096/59184, loss: 5.3977]\n",
            "Epoch [15/15], batch: [59097/59184, loss: 5.3765]\n",
            "Epoch [15/15], batch: [59098/59184, loss: 4.8214]\n",
            "Epoch [15/15], batch: [59099/59184, loss: 6.3338]\n",
            "Epoch [15/15], batch: [59100/59184, loss: 5.4595]\n",
            "Epoch [15/15], batch: [59101/59184, loss: 6.9015]\n",
            "Epoch [15/15], batch: [59102/59184, loss: 4.9720]\n",
            "Epoch [15/15], batch: [59103/59184, loss: 7.1436]\n",
            "Epoch [15/15], batch: [59104/59184, loss: 5.2468]\n",
            "Epoch [15/15], batch: [59105/59184, loss: 5.4571]\n",
            "Epoch [15/15], batch: [59106/59184, loss: 6.9628]\n",
            "Epoch [15/15], batch: [59107/59184, loss: 6.0158]\n",
            "Epoch [15/15], batch: [59108/59184, loss: 6.3072]\n",
            "Epoch [15/15], batch: [59109/59184, loss: 5.2936]\n",
            "Epoch [15/15], batch: [59110/59184, loss: 6.9024]\n",
            "Epoch [15/15], batch: [59111/59184, loss: 6.8084]\n",
            "Epoch [15/15], batch: [59112/59184, loss: 5.5716]\n",
            "Epoch [15/15], batch: [59113/59184, loss: 5.9153]\n",
            "Epoch [15/15], batch: [59114/59184, loss: 4.5060]\n",
            "Epoch [15/15], batch: [59115/59184, loss: 6.7764]\n",
            "Epoch [15/15], batch: [59116/59184, loss: 5.9996]\n",
            "Epoch [15/15], batch: [59117/59184, loss: 4.3699]\n",
            "Epoch [15/15], batch: [59118/59184, loss: 6.7542]\n",
            "Epoch [15/15], batch: [59119/59184, loss: 6.7539]\n",
            "Epoch [15/15], batch: [59120/59184, loss: 5.4121]\n",
            "Epoch [15/15], batch: [59121/59184, loss: 5.0655]\n",
            "Epoch [15/15], batch: [59122/59184, loss: 7.1739]\n",
            "Epoch [15/15], batch: [59123/59184, loss: 5.0877]\n",
            "Epoch [15/15], batch: [59124/59184, loss: 5.9253]\n",
            "Epoch [15/15], batch: [59125/59184, loss: 4.8029]\n",
            "Epoch [15/15], batch: [59126/59184, loss: 6.0608]\n",
            "Epoch [15/15], batch: [59127/59184, loss: 6.4914]\n",
            "Epoch [15/15], batch: [59128/59184, loss: 5.4548]\n",
            "Epoch [15/15], batch: [59129/59184, loss: 4.9581]\n",
            "Epoch [15/15], batch: [59130/59184, loss: 5.5678]\n",
            "Epoch [15/15], batch: [59131/59184, loss: 6.3850]\n",
            "Epoch [15/15], batch: [59132/59184, loss: 4.5932]\n",
            "Epoch [15/15], batch: [59133/59184, loss: 5.2201]\n",
            "Epoch [15/15], batch: [59134/59184, loss: 4.3641]\n",
            "Epoch [15/15], batch: [59135/59184, loss: 5.6933]\n",
            "Epoch [15/15], batch: [59136/59184, loss: 7.3854]\n",
            "Epoch [15/15], batch: [59137/59184, loss: 5.6619]\n",
            "Epoch [15/15], batch: [59138/59184, loss: 3.4024]\n",
            "Epoch [15/15], batch: [59139/59184, loss: 5.2596]\n",
            "Epoch [15/15], batch: [59140/59184, loss: 5.1287]\n",
            "Epoch [15/15], batch: [59141/59184, loss: 7.4839]\n",
            "Epoch [15/15], batch: [59142/59184, loss: 4.4155]\n",
            "Epoch [15/15], batch: [59143/59184, loss: 7.0415]\n",
            "Epoch [15/15], batch: [59144/59184, loss: 5.8611]\n",
            "Epoch [15/15], batch: [59145/59184, loss: 5.2693]\n",
            "Epoch [15/15], batch: [59146/59184, loss: 5.4697]\n",
            "Epoch [15/15], batch: [59147/59184, loss: 5.9572]\n",
            "Epoch [15/15], batch: [59148/59184, loss: 7.8102]\n",
            "Epoch [15/15], batch: [59149/59184, loss: 5.4889]\n",
            "Epoch [15/15], batch: [59150/59184, loss: 5.6272]\n",
            "Epoch [15/15], batch: [59151/59184, loss: 5.9614]\n",
            "Epoch [15/15], batch: [59152/59184, loss: 6.8130]\n",
            "Epoch [15/15], batch: [59153/59184, loss: 6.9107]\n",
            "Epoch [15/15], batch: [59154/59184, loss: 4.5626]\n",
            "Epoch [15/15], batch: [59155/59184, loss: 5.7614]\n",
            "Epoch [15/15], batch: [59156/59184, loss: 4.4183]\n",
            "Epoch [15/15], batch: [59157/59184, loss: 4.8391]\n",
            "Epoch [15/15], batch: [59158/59184, loss: 5.6572]\n",
            "Epoch [15/15], batch: [59159/59184, loss: 5.8182]\n",
            "Epoch [15/15], batch: [59160/59184, loss: 5.8356]\n",
            "Epoch [15/15], batch: [59161/59184, loss: 6.2059]\n",
            "Epoch [15/15], batch: [59162/59184, loss: 5.9682]\n",
            "Epoch [15/15], batch: [59163/59184, loss: 6.6012]\n",
            "Epoch [15/15], batch: [59164/59184, loss: 5.2916]\n",
            "Epoch [15/15], batch: [59165/59184, loss: 4.5804]\n",
            "Epoch [15/15], batch: [59166/59184, loss: 6.0414]\n",
            "Epoch [15/15], batch: [59167/59184, loss: 5.7969]\n",
            "Epoch [15/15], batch: [59168/59184, loss: 6.3411]\n",
            "Epoch [15/15], batch: [59169/59184, loss: 5.4555]\n",
            "Epoch [15/15], batch: [59170/59184, loss: 4.1429]\n",
            "Epoch [15/15], batch: [59171/59184, loss: 5.9556]\n",
            "Epoch [15/15], batch: [59172/59184, loss: 7.6028]\n",
            "Epoch [15/15], batch: [59173/59184, loss: 7.0374]\n",
            "Epoch [15/15], batch: [59174/59184, loss: 4.4133]\n",
            "Epoch [15/15], batch: [59175/59184, loss: 5.4560]\n",
            "Epoch [15/15], batch: [59176/59184, loss: 4.5876]\n",
            "Epoch [15/15], batch: [59177/59184, loss: 6.7164]\n",
            "Epoch [15/15], batch: [59178/59184, loss: 6.5070]\n",
            "Epoch [15/15], batch: [59179/59184, loss: 5.2684]\n",
            "Epoch [15/15], batch: [59180/59184, loss: 5.3995]\n",
            "Epoch [15/15], batch: [59181/59184, loss: 5.7718]\n",
            "Epoch [15/15], batch: [59182/59184, loss: 5.4815]\n",
            "Epoch [15/15], batch: [59183/59184, loss: 6.3794]\n",
            "Epoch [15/15], batch: [59184/59184, loss: 6.7275]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify a path\n",
        "PATH = \"CBOW2.pt\"\n",
        "\n",
        "# Save\n",
        "torch.save(model, PATH)\n",
        "\n",
        "# Load\n",
        "# model = torch.load(PATH)\n",
        "# model.eval()"
      ],
      "metadata": {
        "id": "8PXUFRjeHZV1"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(PATH)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "KVCdGXMGJD--",
        "outputId": "81942327-bc1a-4bd1-98f2-7c73384cf7ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-e3a724de3f11>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model = torch.load(PATH)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CBOW(\n",
              "  (embeddings): Embedding(36872, 50)\n",
              "  (linear1): Linear(in_features=200, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=36872, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "def get_closest_word(word, topn=5):\n",
        "    index_to_word = {value: key for key, value in word_to_ix.items()}   # reversed dictonair to find tokens by their index in the vocab\n",
        "    word_distance = []\n",
        "    model.eval()\n",
        "    emb = model.embeddings\n",
        "    pdist = nn.PairwiseDistance()\n",
        "    i = word_to_ix[word]\n",
        "\n",
        "    lookup_tensor_i = torch.tensor([i], dtype=torch.long).to(device)\n",
        "    #print(lookup_tensor_i)\n",
        "    v_i = emb(lookup_tensor_i)\n",
        "    #print(i, lookup_tensor_i, v_i)\n",
        "    for j in range(1, len(vocab)):\n",
        "      if j != i:\n",
        "          lookup_tensor_j = torch.tensor([j], dtype=torch.long).to(device)\n",
        "          v_j = emb(lookup_tensor_j)\n",
        "          #print(j, lookup_tensor_j, v_j)\n",
        "          word_distance.append((index_to_word[j], float(pdist(v_i, v_j))))\n",
        "    word_distance.sort(key=lambda x: x[1])\n",
        "    return word_distance[:topn]"
      ],
      "metadata": {
        "id": "pnMAbYUI9wtI"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_closest_word('hotel')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T34g5DNn4Lz-",
        "outputId": "1c3199e6-7fac-4d7c-ac95-bc72c0f5f512"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('resort', 3.125905752182007),\n",
              " ('rooms', 3.7057602405548096),\n",
              " ('great', 3.832054376602173),\n",
              " ('excellent', 3.9706552028656006),\n",
              " ('room', 4.023690700531006)]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_closest_word('room'))\n",
        "print(get_closest_word('atlantic'))\n",
        "print(get_closest_word('beautiful'))\n",
        "print(get_closest_word('great'))\n",
        "print(get_closest_word('did'))\n",
        "print(get_closest_word('stay'))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "EUjn_u6WBrYL",
        "outputId": "22a52a3d-7c9d-4901-91fc-8c48cd3e0abc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('rooms', 2.089414358139038), ('hotel', 4.023687362670898), ('bathroom', 4.101468086242676), ('suite', 4.250602722167969), ('floor', 4.554897785186768)]\n",
            "[('nb', 5.9741644859313965), ('place', 6.12546443939209), ('notices', 6.195394992828369), ('carme', 6.19688606262207), ('days', 6.261256217956543)]\n",
            "[('nice', 3.7269740104675293), ('amazing', 3.8383333683013916), ('clean', 3.928826332092285), ('great', 4.006716251373291), ('lovely', 4.092239856719971)]\n",
            "[('good', 2.28143310546875), ('excellent', 2.3379077911376953), ('wonderful', 2.5288219451904297), ('nice', 2.9609107971191406), ('lovely', 3.273216485977173)]\n",
            "[('does', 3.630962371826172), ('went', 4.198888301849365), ('not', 4.366249084472656), ('got', 4.486250877380371), ('think', 4.57169246673584)]\n",
            "[('visit', 4.014122486114502), ('think', 4.113770484924316), ('hotel', 4.233322620391846), ('staying', 4.359683990478516), ('experience', 4.486968994140625)]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'well-furnished'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-966c044fba16>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_closest_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'did'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_closest_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stay'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_closest_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'well-furnished'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_closest_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ineffective'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_closest_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'copley'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-f20b7a507c63>\u001b[0m in \u001b[0;36mget_closest_word\u001b[0;34m(word, topn)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPairwiseDistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_to_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlookup_tensor_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'well-furnished'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_closest_word('ineffective'))\n",
        "print(get_closest_word('copley'))\n",
        "print(get_closest_word('cracked'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsA6z6ReITPp",
        "outputId": "968aac21-61a8-4222-8b85-0b8d5375a9f0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('coordinators', 7.205868721008301), ('cynicism', 7.256261348724365), ('sophisticated', 7.271458625793457), ('deters', 7.288957595825195), ('911', 7.342331409454346)]\n",
            "[('clean', 6.673245906829834), ('diva', 6.845100402832031), ('franglish', 6.883596897125244), ('handwritten', 6.986283779144287), ('recommend', 7.025819778442383)]\n",
            "[('trian', 6.5322346687316895), ('spacous', 6.660488128662109), ('faux', 6.74277400970459), ('crossisants', 6.7488861083984375), ('knocking', 6.758415222167969)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['hotel', 'room', 'copley', 'did', 'stay', 'beautiful', 'ineffective', 'cracked']"
      ],
      "metadata": {
        "id": "SEuli591FFkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "to figure out what are mor frequent and less frequent words, we could use the index numbers in the vocab. I think the higher the index number the rare more rare, as they only get added if not already in the vocab? but i am not sure as we create a set from it, and they are not ordered\n"
      ],
      "metadata": {
        "id": "2-BGSpVrCH6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONTEXT_SIZE = 5\n",
        "train_loader, test_loader, vocab, word_to_ix = create_dataloader(df, 'Review')"
      ],
      "metadata": {
        "id": "IeOX2qC3_3NP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 50\n",
        "HIDDEN_DIM = 128\n",
        "model = CBOW(len(vocab), EMBEDDING_DIM, HIDDEN_DIM, CONTEXT_SIZE)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.95)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "num_epochs = 15\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "model.to(device)\n",
        "trainig_loop(model, train_loader, optimizer, loss_func, num_epochs, device)\n",
        "\n",
        "PATH = \"CBOW5.pt\"\n",
        "\n",
        "# Save\n",
        "torch.save(model, PATH)\n",
        "\n"
      ],
      "metadata": {
        "id": "y0j14nsVAB8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_closest_word('hotel')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1IlFTRu13ai",
        "outputId": "aa05323d-4c7c-4cf1-ceda-36fcb8086311"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('wak', 6.224923610687256),\n",
              " ('masterpieces', 6.45383358001709),\n",
              " ('muy', 6.520915985107422),\n",
              " ('agno', 6.52716588973999),\n",
              " ('reaked', 6.556485652923584)]"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 For the hotel reviews dataset, choose 3 nouns, 3 verbs, and 3 adjectives. (CBOW2 and optionally for CBOW5)\n",
        "Make sure that some nouns/verbs/adjectives occur frequently in the corpus and that others are rare. For each of the 9 chosen words, retrieve the 5 closest words according to your trained CBOW2 model.    \n",
        "\n",
        "ðŸ—’â“ List them in your report (at the end of this notebook) and comment on the performance of your model: do the neighbours the model provides make sense? Discuss.   \n"
      ],
      "metadata": {
        "id": "ulqFt2nc_Oq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.6 Train CBOW2 with a context width of 2 (in both directions) for the Sci-Fi story dataset"
      ],
      "metadata": {
        "id": "AXmEddYd-FSr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "050OoM_rx4qe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('scifi_reduced.txt', 'r') as file:\n",
        "    text = file.read().split(\".\")\n",
        "\n",
        "print(text[:10])\n"
      ],
      "metadata": {
        "id": "2U1S_5Hx-Jku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8702de0e-7bdf-414a-9116-ab9a1aba75af"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' A chat with the editor  i #  science fiction magazine called IF', ' The title was selected after much thought because of its brevity and on the theory it is indicative of the field and will be easy to remember', \" The tentative title that just morning and couldn't remember it until we'd had a cup of coffee, it was summarily discarded\", ' A great deal of thought and effort lias gone into the formation of this magazine', ' We have had the aid of several very talented and generous people, for which we are most grateful', ' Much is due them for their warmhearted assistance', ' And now that the bulk of the formative work is done, we will try to maintain IF as one of the finest books on the market', '  t a great public demand for our magazine', ' In short, why will you buy IF? We cannot, in honesty, say we will publish at all times the best science fiction in the field', ' That would not be true']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sci_df = pd.DataFrame(text, columns=['Sentence'])\n",
        "sci_df.head()"
      ],
      "metadata": {
        "id": "WwFTBToC0ylA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "dd67e648-f9fd-4f9e-d22e-125e0b77df72"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Sentence\n",
              "0   A chat with the editor  i #  science fiction ...\n",
              "1   The title was selected after much thought bec...\n",
              "2   The tentative title that just morning and cou...\n",
              "3   A great deal of thought and effort lias gone ...\n",
              "4   We have had the aid of several very talented ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-767013b8-1943-43b0-b2a7-2319fde8958f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A chat with the editor  i #  science fiction ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The title was selected after much thought bec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The tentative title that just morning and cou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A great deal of thought and effort lias gone ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>We have had the aid of several very talented ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-767013b8-1943-43b0-b2a7-2319fde8958f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-767013b8-1943-43b0-b2a7-2319fde8958f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-767013b8-1943-43b0-b2a7-2319fde8958f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-35085c85-2c1d-437b-8416-6579bb187da8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35085c85-2c1d-437b-8416-6579bb187da8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-35085c85-2c1d-437b-8416-6579bb187da8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sci_df"
            }
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CONTEXT_SIZE = 2\n",
        "train_loader, test_loader, vocab, word_to_ix = create_dataloader(sci_df, 'Sentence')"
      ],
      "metadata": {
        "id": "u7fDja7i1obc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbea080d-a069-4291-cab9-d2a8ada0bc25"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([90, 4])\n",
            "torch.Size([90, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 50\n",
        "HIDDEN_DIM = 128\n",
        "model = CBOW(len(vocab), EMBEDDING_DIM, HIDDEN_DIM, CONTEXT_SIZE)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.95)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "num_epochs = 3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "model.to(device)\n",
        "trainig_loop(model, train_loader, optimizer, loss_func, num_epochs, device)\n",
        "\n",
        "PATH = \"CBOW2_scifi.pt\"\n",
        "\n",
        "# Save\n",
        "torch.save(model, PATH)"
      ],
      "metadata": {
        "id": "uYW7XqTL1-sg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "3fa89e49-8d9f-4d1a-dbe9-5317019b35f7"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "Epoch [1/10], batch: [1/6, loss: 11.6258]\n",
            "Epoch [1/10], batch: [2/6, loss: 11.5951]\n",
            "Epoch [1/10], batch: [3/6, loss: 11.5470]\n",
            "Epoch [1/10], batch: [4/6, loss: 11.6658]\n",
            "Epoch [1/10], batch: [5/6, loss: 11.5902]\n",
            "Epoch [1/10], batch: [6/6, loss: 11.7499]\n",
            "Epoch [2/10], batch: [1/6, loss: 11.4614]\n",
            "Epoch [2/10], batch: [2/6, loss: 11.3817]\n",
            "Epoch [2/10], batch: [3/6, loss: 11.3307]\n",
            "Epoch [2/10], batch: [4/6, loss: 11.4092]\n",
            "Epoch [2/10], batch: [5/6, loss: 11.3747]\n",
            "Epoch [2/10], batch: [6/6, loss: 11.4353]\n",
            "Epoch [3/10], batch: [1/6, loss: 11.1751]\n",
            "Epoch [3/10], batch: [2/6, loss: 10.9996]\n",
            "Epoch [3/10], batch: [3/6, loss: 10.9563]\n",
            "Epoch [3/10], batch: [4/6, loss: 10.9686]\n",
            "Epoch [3/10], batch: [5/6, loss: 11.0097]\n",
            "Epoch [3/10], batch: [6/6, loss: 10.9091]\n",
            "Epoch [4/10], batch: [1/6, loss: 10.7966]\n",
            "Epoch [4/10], batch: [2/6, loss: 10.4642]\n",
            "Epoch [4/10], batch: [3/6, loss: 10.4513]\n",
            "Epoch [4/10], batch: [4/6, loss: 10.3524]\n",
            "Epoch [4/10], batch: [5/6, loss: 10.5156]\n",
            "Epoch [4/10], batch: [6/6, loss: 10.1593]\n",
            "Epoch [5/10], batch: [1/6, loss: 10.3141]\n",
            "Epoch [5/10], batch: [2/6, loss: 9.7099]\n",
            "Epoch [5/10], batch: [3/6, loss: 9.7908]\n",
            "Epoch [5/10], batch: [4/6, loss: 9.4697]\n",
            "Epoch [5/10], batch: [5/6, loss: 9.8502]\n",
            "Epoch [5/10], batch: [6/6, loss: 9.0362]\n",
            "Epoch [6/10], batch: [1/6, loss: 9.6716]\n",
            "Epoch [6/10], batch: [2/6, loss: 8.5780]\n",
            "Epoch [6/10], batch: [3/6, loss: 8.8790]\n",
            "Epoch [6/10], batch: [4/6, loss: 8.1142]\n",
            "Epoch [6/10], batch: [5/6, loss: 8.9077]\n",
            "Epoch [6/10], batch: [6/6, loss: 7.2413]\n",
            "Epoch [7/10], batch: [1/6, loss: 8.7698]\n",
            "Epoch [7/10], batch: [2/6, loss: 6.8127]\n",
            "Epoch [7/10], batch: [3/6, loss: 7.5682]\n",
            "Epoch [7/10], batch: [4/6, loss: 6.1965]\n",
            "Epoch [7/10], batch: [5/6, loss: 7.6053]\n",
            "Epoch [7/10], batch: [6/6, loss: 5.2112]\n",
            "Epoch [8/10], batch: [1/6, loss: 7.6772]\n",
            "Epoch [8/10], batch: [2/6, loss: 5.0543]\n",
            "Epoch [8/10], batch: [3/6, loss: 6.1099]\n",
            "Epoch [8/10], batch: [4/6, loss: 4.7843]\n",
            "Epoch [8/10], batch: [5/6, loss: 6.2389]\n",
            "Epoch [8/10], batch: [6/6, loss: 3.7032]\n",
            "Epoch [9/10], batch: [1/6, loss: 6.8666]\n",
            "Epoch [9/10], batch: [2/6, loss: 3.8389]\n",
            "Epoch [9/10], batch: [3/6, loss: 4.3366]\n",
            "Epoch [9/10], batch: [4/6, loss: 3.5896]\n",
            "Epoch [9/10], batch: [5/6, loss: 4.6023]\n",
            "Epoch [9/10], batch: [6/6, loss: 1.4551]\n",
            "Epoch [10/10], batch: [1/6, loss: 5.1434]\n",
            "Epoch [10/10], batch: [2/6, loss: 2.1957]\n",
            "Epoch [10/10], batch: [3/6, loss: 2.5574]\n",
            "Epoch [10/10], batch: [4/6, loss: 2.2145]\n",
            "Epoch [10/10], batch: [5/6, loss: 2.8774]\n",
            "Epoch [10/10], batch: [6/6, loss: 0.1769]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_closest_word('alien')"
      ],
      "metadata": {
        "id": "9IZ4t24G1_Dz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0040a7b5-51b2-44f1-f81f-45e6a8df3524"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('soory', 6.2498250007629395),\n",
              " ('destandard', 6.413937091827393),\n",
              " ('gels', 6.474977493286133),\n",
              " ('philosophically', 6.499139785766602),\n",
              " ('jcould', 6.626455307006836)]"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Q-N9jEOW9pJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sci_words = ['']"
      ],
      "metadata": {
        "id": "PRhW1MSU_byy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Repeat 2.1 for SciFi Dataset\n",
        "\n",
        "ðŸ—’â“ List your findings for SciFi Dataset as well, similarly to 2.1"
      ],
      "metadata": {
        "id": "njWN32I2ADn9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h3Uyn_VpAWa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 ðŸ—’â“ How does the quality of the hotel review-based embeddings compare with the Sci-fi-based embeddings? Elaborate."
      ],
      "metadata": {
        "id": "E2yqWM5oAhzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oQrywIKgA1Ct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 Choose 2 words and retrieve their 5 closest neighbours according to hotel review-based embeddings and the Sci-fi-based embeddings.\n",
        "\n",
        "ðŸ—’â“ Do they have different neighbours? If yes, can you reason why?"
      ],
      "metadata": {
        "id": "Ivwn8YCgA4GX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4J_xUKzgA3gU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.5 ðŸ—’â“ What are the differences between CBOW2 and CBOW5 ? Can you \"describe\" them?    "
      ],
      "metadata": {
        "id": "DD09lU02Cw7e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "L9SZlUPM4mZr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Report\n",
        "The lab report should contain a detailed description of the approaches you have used to solve this exercise. Please also include results.\n",
        "\n",
        "Answers for the questions marked ðŸ—’â“ goes here as well"
      ],
      "metadata": {
        "id": "RdgWLLHJC24h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eLWqDG2GFV69"
      }
    }
  ]
}